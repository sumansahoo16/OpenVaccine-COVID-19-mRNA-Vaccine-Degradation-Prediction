{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012871,
     "end_time": "2020-09-30T12:36:12.469461",
     "exception": false,
     "start_time": "2020-09-30T12:36:12.456590",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Pytorch Implementation.\n",
    "\n",
    "Model: Convolution + Transfomer + GRU.\n",
    "\n",
    "Training: Bert-Like Pretraining. Then Fine Tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-30T12:36:12.496713Z",
     "iopub.status.busy": "2020-09-30T12:36:12.495930Z",
     "iopub.status.idle": "2020-09-30T12:36:14.107393Z",
     "shell.execute_reply": "2020-09-30T12:36:14.106602Z"
    },
    "papermill": {
     "duration": 1.626987,
     "end_time": "2020-09-30T12:36:14.107557",
     "exception": false,
     "start_time": "2020-09-30T12:36:12.480570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/openwaccineaugdata/aug_df2.json\n",
      "/kaggle/input/stanford-covid-vaccine/test.json\n",
      "/kaggle/input/stanford-covid-vaccine/train.json\n",
      "/kaggle/input/stanford-covid-vaccine/sample_submission.csv\n",
      "/kaggle/input/stanford-covid-vaccine/bpps/id_7adcb8c5d.npy\n",
      "/kaggle/input/stanford-covid-vaccine/bpps/id_1874dad2f.npy\n",
      "/kaggle/input/stanford-covid-vaccine/bpps/id_2e5c35220.npy\n",
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T12:36:14.175300Z",
     "iopub.status.busy": "2020-09-30T12:36:14.174289Z",
     "iopub.status.idle": "2020-09-30T12:36:16.477197Z",
     "shell.execute_reply": "2020-09-30T12:36:16.475778Z"
    },
    "papermill": {
     "duration": 2.334134,
     "end_time": "2020-09-30T12:36:16.477309",
     "exception": false,
     "start_time": "2020-09-30T12:36:14.143175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from fastprogress import progress_bar\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import functools\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n",
    "input_cols = ['sequence', 'structure', 'predicted_loop_type']\n",
    "error_cols = ['reactivity_error', 'deg_error_Mg_pH10', 'deg_error_Mg_50C', 'deg_error_pH10', 'deg_error_50C']\n",
    "\n",
    "token_dicts = {\n",
    "    \"sequence\": {x: i for i, x in enumerate(\"ACGU\")},\n",
    "    \"structure\": {x: i for i, x in enumerate('().')},\n",
    "    \"predicted_loop_type\": {x: i for i, x in enumerate(\"BEHIMSX\")}\n",
    "}\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019169,
     "end_time": "2020-09-30T12:36:16.516541",
     "exception": false,
     "start_time": "2020-09-30T12:36:16.497372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-09-30T12:36:16.571401Z",
     "iopub.status.busy": "2020-09-30T12:36:16.569848Z",
     "iopub.status.idle": "2020-09-30T12:36:16.611960Z",
     "shell.execute_reply": "2020-09-30T12:36:16.612590Z"
    },
    "papermill": {
     "duration": 0.076828,
     "end_time": "2020-09-30T12:36:16.612712",
     "exception": false,
     "start_time": "2020-09-30T12:36:16.535884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import functools\n",
    "\n",
    "\n",
    "BASE_PATH = \"/kaggle/input/stanford-covid-vaccine\"\n",
    "MODEL_SAVE_PATH = \"/kaggle/model\"\n",
    "\n",
    "\n",
    "def preprocess_inputs(df, cols):\n",
    "    return np.concatenate([preprocess_feature_col(df, col) for col in cols], axis=2)\n",
    "\n",
    "\n",
    "def preprocess_feature_col(df, col):\n",
    "    dic = token_dicts[col]\n",
    "    dic_len = len(dic)\n",
    "    seq_length = len(df[col][0])\n",
    "    ident = np.identity(dic_len)\n",
    "    # convert to one hot\n",
    "    arr = np.array(\n",
    "        df[[col]].applymap(lambda seq: [ident[dic[x]] for x in seq]).values.tolist()\n",
    "    ).squeeze(1)\n",
    "    # shape: data_size x seq_length x dic_length\n",
    "    assert arr.shape == (len(df), seq_length, dic_len)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def preprocess(base_data, is_test=False):\n",
    "    inputs = preprocess_inputs(base_data, input_cols)\n",
    "    if is_test:\n",
    "        labels = None\n",
    "    else:\n",
    "        labels = np.array(base_data[target_cols].values.tolist()).transpose((0, 2, 1))\n",
    "        assert labels.shape[2] == len(target_cols)\n",
    "    assert inputs.shape[2] == 14\n",
    "    return inputs, labels\n",
    "\n",
    "\n",
    "def get_bpp_feature(bpp):\n",
    "    bpp_nb_mean = 0.077522  # mean of bpps_nb across all training data\n",
    "    bpp_nb_std = 0.08914  # std of bpps_nb across all training data\n",
    "    bpp_max = bpp.max(-1)[0]\n",
    "    bpp_sum = bpp.sum(-1)\n",
    "    bpp_nb = torch.true_divide((bpp > 0).sum(dim=1), bpp.shape[1])\n",
    "    bpp_nb = torch.true_divide(bpp_nb - bpp_nb_mean, bpp_nb_std)\n",
    "    return [bpp_max.unsqueeze(2), bpp_sum.unsqueeze(2), bpp_nb.unsqueeze(2)]\n",
    "\n",
    "\n",
    "@functools.lru_cache(5000)\n",
    "def load_from_id(id_):\n",
    "    path = Path(BASE_PATH) / f\"bpps/{id_}.npy\"\n",
    "    data = np.load(str(path))\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_distance_matrix(leng):\n",
    "    idx = np.arange(leng)\n",
    "    Ds = []\n",
    "    for i in range(len(idx)):\n",
    "        d = np.abs(idx[i] - idx)\n",
    "        Ds.append(d)\n",
    "\n",
    "    Ds = np.array(Ds) + 1\n",
    "    Ds = 1 / Ds\n",
    "    Ds = Ds[None, :, :]\n",
    "    Ds = np.repeat(Ds, 1, axis=0)\n",
    "\n",
    "    Dss = []\n",
    "    for i in [1, 2, 4]:\n",
    "        Dss.append(Ds ** i)\n",
    "    Ds = np.stack(Dss, axis=3)\n",
    "    print(Ds.shape)\n",
    "    return Ds\n",
    "\n",
    "\n",
    "def get_structure_adj(df):\n",
    "    Ss = []\n",
    "    for i in range(len(df)):\n",
    "        seq_length = df[\"seq_length\"].iloc[i]\n",
    "        structure = df[\"structure\"].iloc[i]\n",
    "        sequence = df[\"sequence\"].iloc[i]\n",
    "\n",
    "        cue = []\n",
    "        a_structures = OrderedDict([\n",
    "            ((\"A\", \"U\"), np.zeros([seq_length, seq_length])),\n",
    "            ((\"C\", \"G\"), np.zeros([seq_length, seq_length])),\n",
    "            ((\"U\", \"G\"), np.zeros([seq_length, seq_length])),\n",
    "            ((\"U\", \"A\"), np.zeros([seq_length, seq_length])),\n",
    "            ((\"G\", \"C\"), np.zeros([seq_length, seq_length])),\n",
    "            ((\"G\", \"U\"), np.zeros([seq_length, seq_length])),\n",
    "        ])\n",
    "        for j in range(seq_length):\n",
    "            if structure[j] == \"(\":\n",
    "                cue.append(j)\n",
    "            elif structure[j] == \")\":\n",
    "                start = cue.pop()\n",
    "                a_structures[(sequence[start], sequence[j])][start, j] = 1\n",
    "                a_structures[(sequence[j], sequence[start])][j, start] = 1\n",
    "\n",
    "        a_strc = np.stack([a for a in a_structures.values()], axis=2)\n",
    "        a_strc = np.sum(a_strc, axis=2, keepdims=True)\n",
    "        Ss.append(a_strc)\n",
    "\n",
    "    Ss = np.array(Ss)\n",
    "    return Ss\n",
    "\n",
    "\n",
    "def create_loader(df, batch_size=1, is_test=False):\n",
    "    features, labels = preprocess(df, is_test)\n",
    "    features_tensor = torch.from_numpy(features)\n",
    "    if labels is not None:\n",
    "        labels_tensor = torch.from_numpy(labels)\n",
    "        dataset = VacDataset(features_tensor, df, labels_tensor)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True, drop_last=False)\n",
    "    else:\n",
    "        dataset = VacDataset(features_tensor, df, None)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size, shuffle=False, drop_last=False)\n",
    "    return loader\n",
    "\n",
    "\n",
    "class VacDataset(Dataset):\n",
    "    def __init__(self, features, df, labels=None):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.test = labels is None\n",
    "        self.ids = df[\"id\"]\n",
    "        self.score = None\n",
    "        self.structure_adj = get_structure_adj(df)\n",
    "        self.distance_matrix = get_distance_matrix(self.structure_adj.shape[1])\n",
    "        if \"score\" in df.columns:\n",
    "            self.score = df[\"score\"]\n",
    "        else:\n",
    "            df[\"score\"] = 1.0\n",
    "            self.score = df[\"score\"]\n",
    "        self.signal_to_noise = None\n",
    "        if not self.test:\n",
    "            self.signal_to_noise = df[\"signal_to_noise\"]\n",
    "            assert self.features.shape[0] == self.labels.shape[0]\n",
    "        else:\n",
    "            assert self.ids is not None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        bpp = torch.from_numpy(load_from_id(self.ids[index]).copy()).float()\n",
    "        adj = self.structure_adj[index]\n",
    "        distance = self.distance_matrix[0]\n",
    "        bpp = np.concatenate([bpp[:, :, None], adj, distance], axis=2)\n",
    "        if self.test:\n",
    "            return dict(sequence=self.features[index].float(), bpp=bpp, ids=self.ids[index])\n",
    "        else:\n",
    "            return dict(sequence=self.features[index].float(), bpp=bpp,\n",
    "                        label=self.labels[index], ids=self.ids[index],\n",
    "                        signal_to_noise=self.signal_to_noise[index],\n",
    "                        score=self.score[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019337,
     "end_time": "2020-09-30T12:36:16.651876",
     "exception": false,
     "start_time": "2020-09-30T12:36:16.632539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T12:36:16.716206Z",
     "iopub.status.busy": "2020-09-30T12:36:16.695375Z",
     "iopub.status.idle": "2020-09-30T12:36:16.751968Z",
     "shell.execute_reply": "2020-09-30T12:36:16.751562Z"
    },
    "papermill": {
     "duration": 0.079358,
     "end_time": "2020-09-30T12:36:16.752074",
     "exception": false,
     "start_time": "2020-09-30T12:36:16.672716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "class Conv1dStack(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, kernel_size=3, padding=1, dilation=1):\n",
    "        super(Conv1dStack, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_dim, out_dim, kernel_size=kernel_size, padding=padding, dilation=dilation, bias=False),\n",
    "            nn.BatchNorm1d(out_dim),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.res = nn.Sequential(\n",
    "            nn.Conv1d(out_dim, out_dim, kernel_size=kernel_size, padding=padding, dilation=dilation, bias=False),\n",
    "            nn.BatchNorm1d(out_dim),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        h = self.res(x)\n",
    "        return x + h\n",
    "\n",
    "\n",
    "class Conv2dStack(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, kernel_size=3, padding=1, dilation=1):\n",
    "        super(Conv2dStack, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, out_dim, kernel_size=kernel_size, padding=padding, dilation=dilation, bias=False),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.res = nn.Sequential(\n",
    "            nn.Conv2d(out_dim, out_dim, kernel_size=kernel_size, padding=padding, dilation=dilation, bias=False),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        h = self.res(x)\n",
    "        return x + h\n",
    "\n",
    "\n",
    "class SeqEncoder(nn.Module):\n",
    "    def __init__(self, in_dim: int):\n",
    "        super(SeqEncoder, self).__init__()\n",
    "        self.conv0 = Conv1dStack(in_dim, 128, 3, padding=1)\n",
    "        self.conv1 = Conv1dStack(128, 64, 6, padding=5, dilation=2)\n",
    "        self.conv2 = Conv1dStack(64, 32, 15, padding=7, dilation=1)\n",
    "        self.conv3 = Conv1dStack(32, 32, 30, padding=29, dilation=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.conv1(x1)\n",
    "        x3 = self.conv2(x2)\n",
    "        x4 = self.conv3(x3)\n",
    "        x = torch.cat([x1, x2, x3, x4], dim=1)\n",
    "        # x = x.permute(0, 2, 1).contiguous()\n",
    "        # BATCH x 256 x seq_length\n",
    "        return x\n",
    "\n",
    "\n",
    "class BppAttn(nn.Module):\n",
    "    def __init__(self, in_channel: int, out_channel: int):\n",
    "        super(BppAttn, self).__init__()\n",
    "        self.conv0 = Conv1dStack(in_channel, out_channel, 3, padding=1)\n",
    "        self.bpp_conv = Conv2dStack(5, out_channel)\n",
    "\n",
    "    def forward(self, x, bpp):\n",
    "        x = self.conv0(x)\n",
    "        bpp = self.bpp_conv(bpp)\n",
    "        # BATCH x C x SEQ x SEQ\n",
    "        # BATCH x C x SEQ\n",
    "        x = torch.matmul(bpp, x.unsqueeze(-1))\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerWrapper(nn.Module):\n",
    "    def __init__(self, dmodel=256, nhead=8, num_layers=2):\n",
    "        super(TransformerWrapper, self).__init__()\n",
    "        self.pos_encoder = PositionalEncoding(256)\n",
    "        encoder_layer = TransformerEncoderLayer(d_model=dmodel, nhead=nhead)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.pos_emb = PositionalEncoding(dmodel)\n",
    "\n",
    "    def flatten_parameters(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute((1, 0, 2)).contiguous()\n",
    "        x = self.pos_emb(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.permute((1, 0, 2)).contiguous()\n",
    "        return x, None\n",
    "\n",
    "\n",
    "class RnnLayers(nn.Module):\n",
    "    def __init__(self, dmodel, dropout=0.3, transformer_layers: int = 2):\n",
    "        super(RnnLayers, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.rnn0 = TransformerWrapper(dmodel, nhead=8, num_layers=transformer_layers)\n",
    "        self.rnn1 = nn.LSTM(dmodel, dmodel // 2, batch_first=True, num_layers=1, bidirectional=True)\n",
    "        self.rnn2 = nn.GRU(dmodel, dmodel // 2, batch_first=True, num_layers=1, bidirectional=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.rnn0.flatten_parameters()\n",
    "        x, _ = self.rnn0(x)\n",
    "        if self.rnn1 is not None:\n",
    "            self.rnn1.flatten_parameters()\n",
    "            x = self.dropout(x)\n",
    "            x, _ = self.rnn1(x)\n",
    "        if self.rnn2 is not None:\n",
    "            self.rnn2.flatten_parameters()\n",
    "            x = self.dropout(x)\n",
    "            x, _ = self.rnn2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class BaseAttnModel(nn.Module):\n",
    "    def __init__(self, transformer_layers: int = 2):\n",
    "        super(BaseAttnModel, self).__init__()\n",
    "        self.linear0 = nn.Linear(14 + 3, 1)\n",
    "        self.seq_encoder_x = SeqEncoder(18)\n",
    "        self.attn = BppAttn(256, 128)\n",
    "        self.seq_encoder_bpp = SeqEncoder(128)\n",
    "        self.seq = RnnLayers(256 * 2, dropout=0.3,\n",
    "                             transformer_layers=transformer_layers)\n",
    "\n",
    "    def forward(self, x, bpp):\n",
    "        bpp_features = get_bpp_feature(bpp[:, :, :, 0].float())\n",
    "        x = torch.cat([x] + bpp_features, dim=-1)\n",
    "        learned = self.linear0(x)\n",
    "        x = torch.cat([x, learned], dim=-1)\n",
    "        x = x.permute(0, 2, 1).contiguous().float()\n",
    "        # BATCH x 18 x seq_len\n",
    "        bpp = bpp.permute([0, 3, 1, 2]).contiguous().float()\n",
    "        # BATCH x 5 x seq_len x seq_len\n",
    "        x = self.seq_encoder_x(x)\n",
    "        # BATCH x 256 x seq_len\n",
    "        bpp = self.attn(x, bpp)\n",
    "        bpp = self.seq_encoder_bpp(bpp)\n",
    "        # BATCH x 256 x seq_len\n",
    "        x = x.permute(0, 2, 1).contiguous()\n",
    "        # BATCH x seq_len x 256\n",
    "        bpp = bpp.permute(0, 2, 1).contiguous()\n",
    "        # BATCH x seq_len x 256\n",
    "        x = torch.cat([x, bpp], dim=2)\n",
    "        # BATCH x seq_len x 512\n",
    "        x = self.seq(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AEModel(nn.Module):\n",
    "    def __init__(self, transformer_layers: int = 2):\n",
    "        super(AEModel, self).__init__()\n",
    "        self.seq = BaseAttnModel(transformer_layers=transformer_layers)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(256 * 2, 14),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, bpp):\n",
    "        x = self.seq(x, bpp)\n",
    "        x = F.dropout(x, p=0.3)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FromAeModel(nn.Module):\n",
    "    def __init__(self, seq, pred_len=68, dmodel: int = 256):\n",
    "        super(FromAeModel, self).__init__()\n",
    "        self.seq = seq\n",
    "        self.pred_len = pred_len\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(dmodel * 2, len(target_cols)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, bpp):\n",
    "        x = self.seq(x, bpp)\n",
    "        x = self.linear(x)\n",
    "        x = x[:, :self.pred_len]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "papermill": {
     "duration": 0.019297,
     "end_time": "2020-09-30T12:36:16.790717",
     "exception": false,
     "start_time": "2020-09-30T12:36:16.771420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "create loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-09-30T12:36:16.840958Z",
     "iopub.status.busy": "2020-09-30T12:36:16.840426Z",
     "iopub.status.idle": "2020-09-30T12:36:24.115205Z",
     "shell.execute_reply": "2020-09-30T12:36:24.115724Z"
    },
    "papermill": {
     "duration": 7.305624,
     "end_time": "2020-09-30T12:36:24.115869",
     "exception": false,
     "start_time": "2020-09-30T12:36:16.810245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public_df: (629, 7)\n",
      "private_df: (3005, 7)\n",
      "(1, 107, 107, 3)\n",
      "(1, 107, 107, 3)\n",
      "(1, 130, 130, 3)\n"
     ]
    }
   ],
   "source": [
    "base_train_data = pd.read_json(str(Path(BASE_PATH) / 'train.json'), lines=True)\n",
    "base_train_data.head()\n",
    "\n",
    "device = torch.device('cuda')\n",
    "BATCH_SIZE = 64\n",
    "base_train_data = pd.read_json(str(Path(BASE_PATH) / 'train.json'), lines=True)\n",
    "base_test_data = pd.read_json(str(Path(BASE_PATH) / 'test.json'), lines=True)\n",
    "public_df = base_test_data.query(\"seq_length == 107\").copy()\n",
    "private_df = base_test_data.query(\"seq_length == 130\").copy()\n",
    "print(f\"public_df: {public_df.shape}\")\n",
    "print(f\"private_df: {private_df.shape}\")\n",
    "public_df = public_df.reset_index()\n",
    "private_df = private_df.reset_index()\n",
    "\n",
    "features, _ = preprocess(base_train_data, True)\n",
    "features_tensor = torch.from_numpy(features)\n",
    "dataset0 = VacDataset(features_tensor, base_train_data, None)\n",
    "features, _ = preprocess(public_df, True)\n",
    "features_tensor = torch.from_numpy(features)\n",
    "dataset1 = VacDataset(features_tensor, public_df, None)\n",
    "features, _ = preprocess(private_df, True)\n",
    "features_tensor = torch.from_numpy(features)\n",
    "dataset2 = VacDataset(features_tensor, private_df, None)\n",
    "\n",
    "loader0 = torch.utils.data.DataLoader(dataset0, BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "loader1 = torch.utils.data.DataLoader(dataset1, BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "loader2 = torch.utils.data.DataLoader(dataset2, BATCH_SIZE, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020894,
     "end_time": "2020-09-30T12:36:24.158184",
     "exception": false,
     "start_time": "2020-09-30T12:36:24.137290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T12:36:24.216075Z",
     "iopub.status.busy": "2020-09-30T12:36:24.215278Z",
     "iopub.status.idle": "2020-09-30T12:36:24.217924Z",
     "shell.execute_reply": "2020-09-30T12:36:24.217517Z"
    },
    "papermill": {
     "duration": 0.039005,
     "end_time": "2020-09-30T12:36:24.218025",
     "exception": false,
     "start_time": "2020-09-30T12:36:24.179020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def learn_from_batch_ae(model, data, device):\n",
    "    seq = data[\"sequence\"].clone()\n",
    "    seq[:, :, :14] = F.dropout2d(seq[:, :, :14], p=0.3)\n",
    "    target = data[\"sequence\"][:, :, :14]\n",
    "    out = model(seq.to(device), data[\"bpp\"].to(device))\n",
    "    loss = F.binary_cross_entropy(out, target.to(device))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_ae(model, train_data, optimizer, lr_scheduler, epochs=10, device=\"cpu\",\n",
    "             start_epoch: int = 0, start_it: int = 0, log_path: str = \"./logs\"):\n",
    "    print(f\"device: {device}\")\n",
    "    losses = []\n",
    "    it = start_it\n",
    "    model_save_path = Path(MODEL_SAVE_PATH)\n",
    "    start_epoch = start_epoch\n",
    "    end_epoch = start_epoch + epochs\n",
    "    min_loss = 10.0\n",
    "    min_loss_epoch = 0\n",
    "    if not model_save_path.exists():\n",
    "        model_save_path.mkdir(parents=True)\n",
    "    for epoch in progress_bar(range(start_epoch, end_epoch)):\n",
    "        print(f\"epoch: {epoch}\")\n",
    "        model.train()\n",
    "        for i, data in enumerate(train_data):\n",
    "            optimizer.zero_grad()\n",
    "            loss = learn_from_batch_ae(model, data, device)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "            if lr_scheduler:\n",
    "                lr_scheduler.step()\n",
    "            loss_v = loss.item()\n",
    "            losses.append(loss_v)\n",
    "            it += 1\n",
    "        loss_m = np.mean(losses)\n",
    "        if loss_m < min_loss:\n",
    "            min_loss_epoch = epoch\n",
    "            min_loss = loss_m\n",
    "        print(f'epoch: {epoch} loss: {loss_m}')\n",
    "        losses = []\n",
    "        torch.save(optimizer.state_dict(), str(model_save_path / \"optimizer.pt\"))\n",
    "        torch.save(model.state_dict(), str(model_save_path / f\"model-{epoch}.pt\"))\n",
    "    return dict(end_epoch=end_epoch, it=it, min_loss_epoch=min_loss_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T12:36:24.270484Z",
     "iopub.status.busy": "2020-09-30T12:36:24.269940Z",
     "iopub.status.idle": "2020-09-30T12:47:01.847570Z",
     "shell.execute_reply": "2020-09-30T12:47:01.847957Z"
    },
    "papermill": {
     "duration": 637.609321,
     "end_time": "2020-09-30T12:47:01.848131",
     "exception": false,
     "start_time": "2020-09-30T12:36:24.238810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:55<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 0 loss: 0.32869393104001093\n",
      "epoch: 1\n",
      "epoch: 1 loss: 0.1732125850884538\n",
      "epoch: 2\n",
      "epoch: 2 loss: 0.13422635079998718\n",
      "epoch: 3\n",
      "epoch: 3 loss: 0.10131922070133059\n",
      "epoch: 4\n",
      "epoch: 4 loss: 0.07272145544227801\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:15<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n",
      "epoch: 5 loss: 0.046084293723106386\n",
      "epoch: 6\n",
      "epoch: 6 loss: 0.03665613271296024\n",
      "epoch: 7\n",
      "epoch: 7 loss: 0.03188155796378851\n",
      "epoch: 8\n",
      "epoch: 8 loss: 0.02604033052921295\n",
      "epoch: 9\n",
      "epoch: 9 loss: 0.02375647071748972\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 01:30<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10\n",
      "epoch: 10 loss: 0.026184827287463432\n",
      "epoch: 11\n",
      "epoch: 11 loss: 0.020211882057025076\n",
      "epoch: 12\n",
      "epoch: 12 loss: 0.01779099320002059\n",
      "epoch: 13\n",
      "epoch: 13 loss: 0.016356333277802518\n",
      "epoch: 14\n",
      "epoch: 14 loss: 0.01535436885550301\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:51<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15\n",
      "epoch: 15 loss: 0.011690631263742321\n",
      "epoch: 16\n",
      "epoch: 16 loss: 0.009787665140864096\n",
      "epoch: 17\n",
      "epoch: 17 loss: 0.009324878490971108\n",
      "epoch: 18\n",
      "epoch: 18 loss: 0.008570758307254627\n",
      "epoch: 19\n",
      "epoch: 19 loss: 0.00801830681187934\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:15<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20\n",
      "epoch: 20 loss: 0.00819207332096994\n",
      "epoch: 21\n",
      "epoch: 21 loss: 0.4638607569038868\n",
      "epoch: 22\n",
      "epoch: 22 loss: 0.35851570665836335\n",
      "epoch: 23\n",
      "epoch: 23 loss: 0.11958920583128929\n",
      "epoch: 24\n",
      "epoch: 24 loss: 0.05920590534806251\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 01:28<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25\n",
      "epoch: 25 loss: 0.03760314221553346\n",
      "epoch: 26\n",
      "epoch: 26 loss: 0.023537744431102528\n",
      "epoch: 27\n",
      "epoch: 27 loss: 0.019652938826921137\n",
      "epoch: 28\n",
      "epoch: 28 loss: 0.017874228470820062\n",
      "epoch: 29\n",
      "epoch: 29 loss: 0.01647352108216666\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:53<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30\n",
      "epoch: 30 loss: 0.019495187817435516\n",
      "epoch: 31\n",
      "epoch: 31 loss: 0.019199474959781294\n",
      "epoch: 32\n",
      "epoch: 32 loss: 0.01410514758409638\n",
      "epoch: 33\n",
      "epoch: 33 loss: 0.011959947866240614\n",
      "epoch: 34\n",
      "epoch: 34 loss: 0.010838325331477742\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:15<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35\n",
      "epoch: 35 loss: 0.00836763447150588\n",
      "epoch: 36\n",
      "epoch: 36 loss: 0.00904910620301962\n",
      "epoch: 37\n",
      "epoch: 37 loss: 0.008199074491858482\n",
      "epoch: 38\n",
      "epoch: 38 loss: 0.007931514643132687\n",
      "epoch: 39\n",
      "epoch: 39 loss: 0.007853986928239465\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 01:29<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40\n",
      "epoch: 40 loss: 0.01586846937920819\n",
      "epoch: 41\n",
      "epoch: 41 loss: 0.014356984340764106\n",
      "epoch: 42\n",
      "epoch: 42 loss: 0.014078114280833843\n",
      "epoch: 43\n",
      "epoch: 43 loss: 0.01336363286889614\n",
      "epoch: 44\n",
      "epoch: 44 loss: 0.012917424730480985\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:52<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45\n",
      "epoch: 45 loss: 0.008213160559535027\n",
      "epoch: 46\n",
      "epoch: 46 loss: 0.007687914822446673\n",
      "epoch: 47\n",
      "epoch: 47 loss: 0.007608285014468588\n",
      "epoch: 48\n",
      "epoch: 48 loss: 0.007619376208535151\n",
      "epoch: 49\n",
      "epoch: 49 loss: 0.007356812773076327\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:16<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50\n",
      "epoch: 50 loss: 0.006053892336785794\n",
      "epoch: 51\n",
      "epoch: 51 loss: 0.006183118699118495\n",
      "epoch: 52\n",
      "epoch: 52 loss: 0.005673004221171141\n",
      "epoch: 53\n",
      "epoch: 53 loss: 0.005450429720804095\n",
      "epoch: 54\n",
      "epoch: 54 loss: 0.0056069723796099424\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 01:27<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 55\n",
      "epoch: 55 loss: 0.012586911129666136\n",
      "epoch: 56\n",
      "epoch: 56 loss: 0.011855349380602228\n",
      "epoch: 57\n",
      "epoch: 57 loss: 0.011501792600338763\n",
      "epoch: 58\n",
      "epoch: 58 loss: 0.011094992088669159\n",
      "epoch: 59\n",
      "epoch: 59 loss: 0.011110003879095645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ae-model.pt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "set_seed(123)\n",
    "shutil.rmtree(\"./model\", True)\n",
    "shutil.rmtree(\"./logs\", True)\n",
    "save_path = Path(\"./model_prediction\")\n",
    "if not save_path.exists():\n",
    "    save_path.mkdir(parents=True)\n",
    "\n",
    "lr_scheduler = None\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AEModel()\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "res = dict(end_epoch=0, it=0, min_loss_epoch=0)\n",
    "epochs = [5, 5, 5, 5]\n",
    "for e in epochs:\n",
    "    res = train_ae(model, loader0, optimizer, lr_scheduler, e, device=device,\n",
    "                   start_epoch=res[\"end_epoch\"], start_it=res[\"it\"])\n",
    "    res = train_ae(model, loader1, optimizer, lr_scheduler, e, device=device,\n",
    "                   start_epoch=res[\"end_epoch\"], start_it=res[\"it\"])\n",
    "    res = train_ae(model, loader2, optimizer, lr_scheduler, e, device=device,\n",
    "                   start_epoch=res[\"end_epoch\"], start_it=res[\"it\"])\n",
    "\n",
    "epoch = res[\"min_loss_epoch\"]\n",
    "shutil.copyfile(str(Path(MODEL_SAVE_PATH) / f\"model-{epoch}.pt\"), \"ae-model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.062532,
     "end_time": "2020-09-30T12:47:01.974908",
     "exception": false,
     "start_time": "2020-09-30T12:47:01.912376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-09-30T12:47:02.125616Z",
     "iopub.status.busy": "2020-09-30T12:47:02.118278Z",
     "iopub.status.idle": "2020-09-30T12:47:02.127704Z",
     "shell.execute_reply": "2020-09-30T12:47:02.128135Z"
    },
    "papermill": {
     "duration": 0.090884,
     "end_time": "2020-09-30T12:47:02.128242",
     "exception": false,
     "start_time": "2020-09-30T12:47:02.037358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MCRMSE(y_true, y_pred):\n",
    "    colwise_mse = torch.mean(torch.square(y_true - y_pred), dim=1)\n",
    "    return torch.mean(torch.sqrt(colwise_mse), dim=1)\n",
    "\n",
    "\n",
    "def sn_mcrmse_loss(predict, target, signal_to_noise):\n",
    "    loss = MCRMSE(target, predict)\n",
    "    weight = 0.5 * torch.log(signal_to_noise + 1.01)\n",
    "    loss = (loss * weight).mean()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def learn_from_batch(model, data, optimizer, lr_scheduler, device):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data[\"sequence\"].to(device), data[\"bpp\"].to(device))\n",
    "    signal_to_noise = data[\"signal_to_noise\"] * data[\"score\"]\n",
    "    loss = sn_mcrmse_loss(out, data[\"label\"].to(device), signal_to_noise.to(device))\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "    optimizer.step()\n",
    "    if lr_scheduler:\n",
    "        lr_scheduler.step()\n",
    "    return out, loss\n",
    "\n",
    "\n",
    "def evaluate(model, valid_data, device):\n",
    "    model.eval()\n",
    "    loss_list = []\n",
    "    mcrmse = []\n",
    "    for i, data in enumerate(valid_data):\n",
    "        with torch.no_grad():\n",
    "            y = model(data[\"sequence\"].to(device), data[\"bpp\"].to(device))\n",
    "            mcrmse_ = MCRMSE(data[\"label\"].to(device), y)[data[\"signal_to_noise\"] > 1]\n",
    "            mcrmse.append(mcrmse_.mean().item())\n",
    "            loss = sn_mcrmse_loss(y, data[\"label\"].to(device), data[\"signal_to_noise\"].to(device))\n",
    "            loss_list.append(loss.item())\n",
    "    model.train()\n",
    "    return dict(loss=np.mean(loss_list), mcmse=np.mean(mcrmse))\n",
    "\n",
    "\n",
    "def train(model, train_data, valid_data, optimizer, lr_scheduler, epochs=10, device=\"cpu\",\n",
    "          start_epoch: int = 0, log_path: str = \"./logs\"):\n",
    "    print(f\"device: {device}\")\n",
    "    losses = []\n",
    "    writer = SummaryWriter(log_path)\n",
    "    it = 0\n",
    "    model_save_path = Path(MODEL_SAVE_PATH)\n",
    "    start_epoch = start_epoch\n",
    "    end_epoch = start_epoch + epochs\n",
    "    if not model_save_path.exists():\n",
    "        model_save_path.mkdir(parents=True)\n",
    "    min_eval_loss = 10.0\n",
    "    min_eval_epoch = None\n",
    "    for epoch in progress_bar(range(start_epoch, end_epoch)):\n",
    "        print(f\"epoch: {epoch}\")\n",
    "        model.train()\n",
    "        for i, data in enumerate(train_data):\n",
    "            _, loss = learn_from_batch(model, data, optimizer, lr_scheduler, device)\n",
    "            loss_v = loss.item()\n",
    "            writer.add_scalar('loss', loss_v, it)\n",
    "            losses.append(loss_v)\n",
    "            it += 1\n",
    "        print(f'epoch: {epoch} loss: {np.mean(losses)}')\n",
    "        losses = []\n",
    "\n",
    "        eval_result = evaluate(model, valid_data, device)\n",
    "        eval_loss = eval_result[\"loss\"]\n",
    "        if eval_loss <= min_eval_loss:\n",
    "            min_eval_epoch = epoch\n",
    "            min_eval_loss = eval_loss\n",
    "\n",
    "        print(f\"eval loss: {eval_loss} {eval_result['mcmse']}\")\n",
    "        writer.add_scalar(f\"evaluate/loss\", eval_loss, epoch)\n",
    "        writer.add_scalar(f\"evaluate/mcmse\", eval_result[\"mcmse\"], epoch)\n",
    "        model.train()\n",
    "        torch.save(optimizer.state_dict(), str(model_save_path / \"optimizer.pt\"))\n",
    "        torch.save(model.state_dict(), str(model_save_path / f\"model-{epoch}.pt\"))\n",
    "    print(f'min eval loss: {min_eval_loss} epoch {min_eval_epoch}')\n",
    "    return min_eval_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T12:47:02.265590Z",
     "iopub.status.busy": "2020-09-30T12:47:02.265083Z",
     "iopub.status.idle": "2020-09-30T15:29:21.408773Z",
     "shell.execute_reply": "2020-09-30T15:29:21.407382Z"
    },
    "papermill": {
     "duration": 9739.217718,
     "end_time": "2020-09-30T15:29:21.408884",
     "exception": false,
     "start_time": "2020-09-30T12:47:02.191166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "(1, 107, 107, 3)\n",
      "(1, 107, 107, 3)\n",
      "(2160, 21) (240, 21)\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='200' class='' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [200/200 32:39<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 0 loss: 0.30934015436833917\n",
      "eval loss: 0.2508997617694583 0.3282543899614309\n",
      "epoch: 1\n",
      "epoch: 1 loss: 0.2476099410579828\n",
      "eval loss: 0.23337266998381026 0.30648029106895425\n",
      "epoch: 2\n",
      "epoch: 2 loss: 0.23316761807885045\n",
      "eval loss: 0.2228317124173043 0.2908900974060071\n",
      "epoch: 3\n",
      "epoch: 3 loss: 0.22396023264046389\n",
      "eval loss: 0.21687749565749395 0.2850249169795995\n",
      "epoch: 4\n",
      "epoch: 4 loss: 0.21663490634241542\n",
      "eval loss: 0.2118985770544521 0.27772005366803215\n",
      "epoch: 5\n",
      "epoch: 5 loss: 0.21045051532343004\n",
      "eval loss: 0.21268776765474015 0.27977675986057987\n",
      "epoch: 6\n",
      "epoch: 6 loss: 0.20551812826577995\n",
      "eval loss: 0.20169907032615175 0.2638220160567483\n",
      "epoch: 7\n",
      "epoch: 7 loss: 0.20020086067443835\n",
      "eval loss: 0.19342048233571613 0.2545356928525894\n",
      "epoch: 8\n",
      "epoch: 8 loss: 0.19605179819745666\n",
      "eval loss: 0.19164833061543474 0.25193553740342206\n",
      "epoch: 9\n",
      "epoch: 9 loss: 0.19269512084136983\n",
      "eval loss: 0.18696400020196963 0.24534158470987075\n",
      "epoch: 10\n",
      "epoch: 10 loss: 0.18878044318964257\n",
      "eval loss: 0.18632510348630968 0.24364149173039312\n",
      "epoch: 11\n",
      "epoch: 11 loss: 0.184875317911183\n",
      "eval loss: 0.1859074079228304 0.24420727206525167\n",
      "epoch: 12\n",
      "epoch: 12 loss: 0.18450526533613693\n",
      "eval loss: 0.1810376647311932 0.23690557036226584\n",
      "epoch: 13\n",
      "epoch: 13 loss: 0.18026081298342178\n",
      "eval loss: 0.17869810263741198 0.23415586139118288\n",
      "epoch: 14\n",
      "epoch: 14 loss: 0.17844327566034912\n",
      "eval loss: 0.17817294597013128 0.23408059416897878\n",
      "epoch: 15\n",
      "epoch: 15 loss: 0.17686457168967618\n",
      "eval loss: 0.1778331754453079 0.23282184491980226\n",
      "epoch: 16\n",
      "epoch: 16 loss: 0.17520249975559762\n",
      "eval loss: 0.1741015199381578 0.2272520738245401\n",
      "epoch: 17\n",
      "epoch: 17 loss: 0.17093962256783835\n",
      "eval loss: 0.17512909539540358 0.22894949931179756\n",
      "epoch: 18\n",
      "epoch: 18 loss: 0.17157980289409974\n",
      "eval loss: 0.17396224293563167 0.22652090040730455\n",
      "epoch: 19\n",
      "epoch: 19 loss: 0.16974125464922574\n",
      "eval loss: 0.1750993238425908 0.2276515869409156\n",
      "epoch: 20\n",
      "epoch: 20 loss: 0.16856333327680528\n",
      "eval loss: 0.17162241265019157 0.22764356282520654\n",
      "epoch: 21\n",
      "epoch: 21 loss: 0.16547332358020012\n",
      "eval loss: 0.16852821022367234 0.22106799683923067\n",
      "epoch: 22\n",
      "epoch: 22 loss: 0.1635891259381773\n",
      "eval loss: 0.16928298382278356 0.2219287142035376\n",
      "epoch: 23\n",
      "epoch: 23 loss: 0.16277417958219445\n",
      "eval loss: 0.16906209955256393 0.22248934370407175\n",
      "epoch: 24\n",
      "epoch: 24 loss: 0.16265052648320721\n",
      "eval loss: 0.17056128353864047 0.22388576905950916\n",
      "epoch: 25\n",
      "epoch: 25 loss: 0.16166517187944887\n",
      "eval loss: 0.17124460006456999 0.22444277965799103\n",
      "epoch: 26\n",
      "epoch: 26 loss: 0.1588648059318195\n",
      "eval loss: 0.17088184479357174 0.22257931893430546\n",
      "epoch: 27\n",
      "epoch: 27 loss: 0.1585698161829653\n",
      "eval loss: 0.17360334214765907 0.22626865792161363\n",
      "epoch: 28\n",
      "epoch: 28 loss: 0.15725329965763762\n",
      "eval loss: 0.16730100588384794 0.2185839111623405\n",
      "epoch: 29\n",
      "epoch: 29 loss: 0.15644691046836723\n",
      "eval loss: 0.16906392702831455 0.22154689556594745\n",
      "epoch: 30\n",
      "epoch: 30 loss: 0.1568889394396168\n",
      "eval loss: 0.1682185071254384 0.22111504172099772\n",
      "epoch: 31\n",
      "epoch: 31 loss: 0.15469991259408272\n",
      "eval loss: 0.1669630636238098 0.2184784508003798\n",
      "epoch: 32\n",
      "epoch: 32 loss: 0.1516775659829557\n",
      "eval loss: 0.16344958268280863 0.21441633467328516\n",
      "epoch: 33\n",
      "epoch: 33 loss: 0.15118761986844667\n",
      "eval loss: 0.16310021759056265 0.2139339582875213\n",
      "epoch: 34\n",
      "epoch: 34 loss: 0.15001723941438408\n",
      "eval loss: 0.16585092420106556 0.21691052427562701\n",
      "epoch: 35\n",
      "epoch: 35 loss: 0.1500711334969733\n",
      "eval loss: 0.16835395042522494 0.21999639066053353\n",
      "epoch: 36\n",
      "epoch: 36 loss: 0.14865177325293746\n",
      "eval loss: 0.16222002209337416 0.21193114121875992\n",
      "epoch: 37\n",
      "epoch: 37 loss: 0.14825486604904006\n",
      "eval loss: 0.16532526172900552 0.21625771895038204\n",
      "epoch: 38\n",
      "epoch: 38 loss: 0.14716330859682297\n",
      "eval loss: 0.16541606466418018 0.21575386854155348\n",
      "epoch: 39\n",
      "epoch: 39 loss: 0.14803691370571692\n",
      "eval loss: 0.16290108431530065 0.21247240746491974\n",
      "epoch: 40\n",
      "epoch: 40 loss: 0.14618886945444695\n",
      "eval loss: 0.16725217176889046 0.21885407271933693\n",
      "epoch: 41\n",
      "epoch: 41 loss: 0.1453207486545109\n",
      "eval loss: 0.16204324539942866 0.21221338622715571\n",
      "epoch: 42\n",
      "epoch: 42 loss: 0.14325920200789521\n",
      "eval loss: 0.1595488524154319 0.21111838524569282\n",
      "epoch: 43\n",
      "epoch: 43 loss: 0.14459859272380648\n",
      "eval loss: 0.16267314508358544 0.21303346948398896\n",
      "epoch: 44\n",
      "epoch: 44 loss: 0.142918051987529\n",
      "eval loss: 0.16274966921983663 0.2120700217707901\n",
      "epoch: 45\n",
      "epoch: 45 loss: 0.1416159063452779\n",
      "eval loss: 0.16019112268342212 0.20874292026227184\n",
      "epoch: 46\n",
      "epoch: 46 loss: 0.14108137054041486\n",
      "eval loss: 0.16267332126075623 0.21355077156767394\n",
      "epoch: 47\n",
      "epoch: 47 loss: 0.1403631957015861\n",
      "eval loss: 0.15972235664056278 0.2089409303263308\n",
      "epoch: 48\n",
      "epoch: 48 loss: 0.13921281558381826\n",
      "eval loss: 0.15906241688291195 0.2100424812909285\n",
      "epoch: 49\n",
      "epoch: 49 loss: 0.1389677472989268\n",
      "eval loss: 0.16265106291126674 0.2119588891660843\n",
      "epoch: 50\n",
      "epoch: 50 loss: 0.13931627297721125\n",
      "eval loss: 0.16009911152667936 0.20919126199341573\n",
      "epoch: 51\n",
      "epoch: 51 loss: 0.13926334193691434\n",
      "eval loss: 0.1620192409769596 0.2119757271201417\n",
      "epoch: 52\n",
      "epoch: 52 loss: 0.14007408146699302\n",
      "eval loss: 0.16050686483661933 0.2090021380898532\n",
      "epoch: 53\n",
      "epoch: 53 loss: 0.1384719287133623\n",
      "eval loss: 0.15818881677870666 0.20809075030796287\n",
      "epoch: 54\n",
      "epoch: 54 loss: 0.13719051672355437\n",
      "eval loss: 0.15741556723577832 0.20722105518413605\n",
      "epoch: 55\n",
      "epoch: 55 loss: 0.13717704899565475\n",
      "eval loss: 0.15926190897704867 0.20848594340249285\n",
      "epoch: 56\n",
      "epoch: 56 loss: 0.1357767051564091\n",
      "eval loss: 0.15949760696946455 0.20893339488247342\n",
      "epoch: 57\n",
      "epoch: 57 loss: 0.1357561759556835\n",
      "eval loss: 0.1601675725257619 0.2095445368099454\n",
      "epoch: 58\n",
      "epoch: 58 loss: 0.13468719356658376\n",
      "eval loss: 0.15900447594312322 0.20908835059441266\n",
      "epoch: 59\n",
      "epoch: 59 loss: 0.13322225012263744\n",
      "eval loss: 0.15662821467927282 0.20549177221622697\n",
      "epoch: 60\n",
      "epoch: 60 loss: 0.13338080758797743\n",
      "eval loss: 0.15841922361369534 0.2067095562897358\n",
      "epoch: 61\n",
      "epoch: 61 loss: 0.1327391967160284\n",
      "eval loss: 0.15956996855598257 0.20927073326966358\n",
      "epoch: 62\n",
      "epoch: 62 loss: 0.13292618364168035\n",
      "eval loss: 0.15874316442532788 0.20775409043532245\n",
      "epoch: 63\n",
      "epoch: 63 loss: 0.13302455414598824\n",
      "eval loss: 0.15799902660338955 0.2077890913875268\n",
      "epoch: 64\n",
      "epoch: 64 loss: 0.13184516573144953\n",
      "eval loss: 0.15995051785936976 0.20911244228285603\n",
      "epoch: 65\n",
      "epoch: 65 loss: 0.13027587794055173\n",
      "eval loss: 0.15622987531525306 0.20454673129043244\n",
      "epoch: 66\n",
      "epoch: 66 loss: 0.12983037910931183\n",
      "eval loss: 0.15747467157083417 0.2066062356852176\n",
      "epoch: 67\n",
      "epoch: 67 loss: 0.12985025232564704\n",
      "eval loss: 0.15792386247206633 0.20641214211965458\n",
      "epoch: 68\n",
      "epoch: 68 loss: 0.12991990964337546\n",
      "eval loss: 0.15643692939037643 0.20447397982918164\n",
      "epoch: 69\n",
      "epoch: 69 loss: 0.13053977041795298\n",
      "eval loss: 0.15729000622810582 0.2068360778670936\n",
      "epoch: 70\n",
      "epoch: 70 loss: 0.12776749035857746\n",
      "eval loss: 0.15571847066057895 0.20418233056830143\n",
      "epoch: 71\n",
      "epoch: 71 loss: 0.12710731106333434\n",
      "eval loss: 0.1577606445855036 0.20501222528145405\n",
      "epoch: 72\n",
      "epoch: 72 loss: 0.12810581306337204\n",
      "eval loss: 0.16032862459749359 0.2093308557176032\n",
      "epoch: 73\n",
      "epoch: 73 loss: 0.1273494491855808\n",
      "eval loss: 0.15968139557639038 0.20928778354853428\n",
      "epoch: 74\n",
      "epoch: 74 loss: 0.1261571374207189\n",
      "eval loss: 0.1585722930049333 0.20713175235956938\n",
      "epoch: 75\n",
      "epoch: 75 loss: 0.12700520919820388\n",
      "eval loss: 0.15571847903715053 0.20526173613828638\n",
      "epoch: 76\n",
      "epoch: 76 loss: 0.12636972391496668\n",
      "eval loss: 0.15727398672828463 0.2067788182242911\n",
      "epoch: 77\n",
      "epoch: 77 loss: 0.12592433997548408\n",
      "eval loss: 0.1563936813913016 0.20531150378337337\n",
      "epoch: 78\n",
      "epoch: 78 loss: 0.12501717160514\n",
      "eval loss: 0.15756727057476957 0.20633317125191514\n",
      "epoch: 79\n",
      "epoch: 79 loss: 0.1252467888059013\n",
      "eval loss: 0.15544276927218845 0.2040364645193479\n",
      "epoch: 80\n",
      "epoch: 80 loss: 0.12355359753534202\n",
      "eval loss: 0.15551206425075412 0.20278038371684276\n",
      "epoch: 81\n",
      "epoch: 81 loss: 0.12503515565132478\n",
      "eval loss: 0.157092717830487 0.20518349903996141\n",
      "epoch: 82\n",
      "epoch: 82 loss: 0.12375858062237785\n",
      "eval loss: 0.15918487052198854 0.2085523360012021\n",
      "epoch: 83\n",
      "epoch: 83 loss: 0.12345147145262368\n",
      "eval loss: 0.15635482945727158 0.20469841393359847\n",
      "epoch: 84\n",
      "epoch: 84 loss: 0.12326649115370214\n",
      "eval loss: 0.15454552905189628 0.20154105589623605\n",
      "epoch: 85\n",
      "epoch: 85 loss: 0.12361909899172063\n",
      "eval loss: 0.15807617715864794 0.20734417553501722\n",
      "epoch: 86\n",
      "epoch: 86 loss: 0.12265583744900474\n",
      "eval loss: 0.15673599042161038 0.2040111359040876\n",
      "epoch: 87\n",
      "epoch: 87 loss: 0.1223656178073871\n",
      "eval loss: 0.15568844688236513 0.20327534632316824\n",
      "epoch: 88\n",
      "epoch: 88 loss: 0.12119751657132355\n",
      "eval loss: 0.15429524983746049 0.20228084276194452\n",
      "epoch: 89\n",
      "epoch: 89 loss: 0.12245229853544615\n",
      "eval loss: 0.1575869004434067 0.20516433879886417\n",
      "epoch: 90\n",
      "epoch: 90 loss: 0.12097376105659378\n",
      "eval loss: 0.1545640948974424 0.20225414163419345\n",
      "epoch: 91\n",
      "epoch: 91 loss: 0.12046745970323203\n",
      "eval loss: 0.15562040121793844 0.20512161546766644\n",
      "epoch: 92\n",
      "epoch: 92 loss: 0.12045265409728025\n",
      "eval loss: 0.15721137420065392 0.20620639404187555\n",
      "epoch: 93\n",
      "epoch: 93 loss: 0.12263650319132718\n",
      "eval loss: 0.1544437610845136 0.20284167058615998\n",
      "epoch: 94\n",
      "epoch: 94 loss: 0.11897446481431413\n",
      "eval loss: 0.15506866251165943 0.20361743687977676\n",
      "epoch: 95\n",
      "epoch: 95 loss: 0.1191843002663726\n",
      "eval loss: 0.15449166626847533 0.20135552821918185\n",
      "epoch: 96\n",
      "epoch: 96 loss: 0.11913378228990776\n",
      "eval loss: 0.15661962928917617 0.20582482664076118\n",
      "epoch: 97\n",
      "epoch: 97 loss: 0.11833816370104581\n",
      "eval loss: 0.15574232138468364 0.20521276493495783\n",
      "epoch: 98\n",
      "epoch: 98 loss: 0.11810546542582563\n",
      "eval loss: 0.15286427776417857 0.20136001036718526\n",
      "epoch: 99\n",
      "epoch: 99 loss: 0.11779396061792002\n",
      "eval loss: 0.15776122520961547 0.2051425364774207\n",
      "epoch: 100\n",
      "epoch: 100 loss: 0.1180936277914891\n",
      "eval loss: 0.15644585542409628 0.20480307041575702\n",
      "epoch: 101\n",
      "epoch: 101 loss: 0.11805526977640782\n",
      "eval loss: 0.15586239883613043 0.20392173255501903\n",
      "epoch: 102\n",
      "epoch: 102 loss: 0.11701963306409897\n",
      "eval loss: 0.15481358440220383 0.20371059182414694\n",
      "epoch: 103\n",
      "epoch: 103 loss: 0.11605739192638496\n",
      "eval loss: 0.15560942078803564 0.2043687544984643\n",
      "epoch: 104\n",
      "epoch: 104 loss: 0.11702020150035575\n",
      "eval loss: 0.1558050427781702 0.2033146158012855\n",
      "epoch: 105\n",
      "epoch: 105 loss: 0.11616058589137926\n",
      "eval loss: 0.15630060802928064 0.20405213312013462\n",
      "epoch: 106\n",
      "epoch: 106 loss: 0.11567460036023991\n",
      "eval loss: 0.15545326069766507 0.2031989822064073\n",
      "epoch: 107\n",
      "epoch: 107 loss: 0.11584885169334186\n",
      "eval loss: 0.15297249833838372 0.20123358511964978\n",
      "epoch: 108\n",
      "epoch: 108 loss: 0.11535754788174196\n",
      "eval loss: 0.15509062054195338 0.20275465817431307\n",
      "epoch: 109\n",
      "epoch: 109 loss: 0.11620544765005722\n",
      "eval loss: 0.15788836294672046 0.20571094909024595\n",
      "epoch: 110\n",
      "epoch: 110 loss: 0.11475625580414432\n",
      "eval loss: 0.15437555061305486 0.20248086071856244\n",
      "epoch: 111\n",
      "epoch: 111 loss: 0.31714248876172907\n",
      "eval loss: 0.3243634229941006 0.42384827709224443\n",
      "epoch: 112\n",
      "epoch: 112 loss: 0.32447301467253153\n",
      "eval loss: 0.31890079436204377 0.4131052775353277\n",
      "epoch: 113\n",
      "epoch: 113 loss: 0.3229804845759846\n",
      "eval loss: 0.31813394428047487 0.4140105812399425\n",
      "epoch: 114\n",
      "epoch: 114 loss: 0.32197129281062264\n",
      "eval loss: 0.31770985678386054 0.4122758968543472\n",
      "epoch: 115\n",
      "epoch: 115 loss: 0.3231387278481311\n",
      "eval loss: 0.3160893317148905 0.4102314658371548\n",
      "epoch: 116\n",
      "epoch: 116 loss: 0.3228059698339842\n",
      "eval loss: 0.31594949952085993 0.4105682844767766\n",
      "epoch: 117\n",
      "epoch: 117 loss: 0.32334335443481194\n",
      "eval loss: 0.31863981297797206 0.41223844711237423\n",
      "epoch: 118\n",
      "epoch: 118 loss: 0.3253216223908855\n",
      "eval loss: 0.31729496890724757 0.41175686735657835\n",
      "epoch: 119\n",
      "epoch: 119 loss: 0.3217902540919573\n",
      "eval loss: 0.3173281514827845 0.413049317936438\n",
      "epoch: 120\n",
      "epoch: 120 loss: 0.32167754965542805\n",
      "eval loss: 0.31644300155343835 0.41199482511572083\n",
      "epoch: 121\n",
      "epoch: 121 loss: 0.3220499174474987\n",
      "eval loss: 0.3166373920724596 0.4124706675042581\n",
      "epoch: 122\n",
      "epoch: 122 loss: 0.3213148354918991\n",
      "eval loss: 0.317579567362196 0.41085690907779815\n",
      "epoch: 123\n",
      "epoch: 123 loss: 0.32084111276291394\n",
      "eval loss: 0.31911394800318615 0.4132069013676575\n",
      "epoch: 124\n",
      "epoch: 124 loss: 0.32647545852305765\n",
      "eval loss: 0.3200960261173424 0.41509963599187605\n",
      "epoch: 125\n",
      "epoch: 125 loss: 0.32443796997940616\n",
      "eval loss: 0.3147639090639435 0.4097917518630786\n",
      "epoch: 126\n",
      "epoch: 126 loss: 0.32192527135137883\n",
      "eval loss: 0.317931976039774 0.4118443770421077\n",
      "epoch: 127\n",
      "epoch: 127 loss: 0.32087797769631804\n",
      "eval loss: 0.3170718255234388 0.41186803575639785\n",
      "epoch: 128\n",
      "epoch: 128 loss: 0.32210615446023255\n",
      "eval loss: 0.3177716675214445 0.4120234968364269\n",
      "epoch: 129\n",
      "epoch: 129 loss: 0.3222978577073678\n",
      "eval loss: 0.316221727346796 0.4099385830603335\n",
      "epoch: 130\n",
      "epoch: 130 loss: 0.32175009472847194\n",
      "eval loss: 0.3175579960791069 0.4117039000908205\n",
      "epoch: 131\n",
      "epoch: 131 loss: 0.32244651329910634\n",
      "eval loss: 0.32073435454570803 0.418502353534405\n",
      "epoch: 132\n",
      "epoch: 132 loss: 0.3214973588134921\n",
      "eval loss: 0.31667003853383463 0.4099004114765016\n",
      "epoch: 133\n",
      "epoch: 133 loss: 0.321510484062448\n",
      "eval loss: 0.31439914526630863 0.41079776930408196\n",
      "epoch: 134\n",
      "epoch: 134 loss: 0.321179724977808\n",
      "eval loss: 0.31892339499732786 0.410830893794762\n",
      "epoch: 135\n",
      "epoch: 135 loss: 0.321472037311316\n",
      "eval loss: 0.31691187134612026 0.4128135529403504\n",
      "epoch: 136\n",
      "epoch: 136 loss: 0.3211614781160288\n",
      "eval loss: 0.3166027229174662 0.41143326396773916\n",
      "epoch: 137\n",
      "epoch: 137 loss: 0.32064507893306454\n",
      "eval loss: 0.3158523786423441 0.4098613224498867\n",
      "epoch: 138\n",
      "epoch: 138 loss: 0.32129148552358633\n",
      "eval loss: 0.31818904846631674 0.4107092261875418\n",
      "epoch: 139\n",
      "epoch: 139 loss: 0.321132953823026\n",
      "eval loss: 0.3168459643896577 0.41108803896320906\n",
      "epoch: 140\n",
      "epoch: 140 loss: 0.32157709537503576\n",
      "eval loss: 0.31848244155930966 0.41288192133546037\n",
      "epoch: 141\n",
      "epoch: 141 loss: 0.32094499140611005\n",
      "eval loss: 0.314895660313197 0.40992395620744415\n",
      "epoch: 142\n",
      "epoch: 142 loss: 0.32165477608524246\n",
      "eval loss: 0.31622711066964976 0.41280414189012715\n",
      "epoch: 143\n",
      "epoch: 143 loss: 0.32150099167875\n",
      "eval loss: 0.31583703146308295 0.41336520101669916\n",
      "epoch: 144\n",
      "epoch: 144 loss: 0.3212761871248335\n",
      "eval loss: 0.3187583405913339 0.4141467337590634\n",
      "epoch: 145\n",
      "epoch: 145 loss: 0.32127321321342944\n",
      "eval loss: 0.31835772810095925 0.41327186450580006\n",
      "epoch: 146\n",
      "epoch: 146 loss: 0.32179794380167026\n",
      "eval loss: 0.31829360049369754 0.4131046821813619\n",
      "epoch: 147\n",
      "epoch: 147 loss: 0.32087300315690204\n",
      "eval loss: 0.3166955018407404 0.4115637215207724\n",
      "epoch: 148\n",
      "epoch: 148 loss: 0.32098280964836845\n",
      "eval loss: 0.3165824875905191 0.4138158245863796\n",
      "epoch: 149\n",
      "epoch: 149 loss: 0.3211974948606686\n",
      "eval loss: 0.3162621141040097 0.41226430239618994\n",
      "epoch: 150\n",
      "epoch: 150 loss: 0.32184043544726204\n",
      "eval loss: 0.31637477851464824 0.41146824018701955\n",
      "epoch: 151\n",
      "epoch: 151 loss: 0.3212205831043347\n",
      "eval loss: 0.3137496719570684 0.40981042476990304\n",
      "epoch: 152\n",
      "epoch: 152 loss: 0.320526448195361\n",
      "eval loss: 0.3189909756185211 0.4136535221798227\n",
      "epoch: 153\n",
      "epoch: 153 loss: 0.3212981408690067\n",
      "eval loss: 0.31694005471491116 0.41128745230704866\n",
      "epoch: 154\n",
      "epoch: 154 loss: 0.32068954759135765\n",
      "eval loss: 0.315697665807507 0.4122533610602848\n",
      "epoch: 155\n",
      "epoch: 155 loss: 0.32046706917703155\n",
      "eval loss: 0.3163390557340146 0.4117921619032337\n",
      "epoch: 156\n",
      "epoch: 156 loss: 0.320453938678616\n",
      "eval loss: 0.31678645711675324 0.4118878974258\n",
      "epoch: 157\n",
      "epoch: 157 loss: 0.321436492814614\n",
      "eval loss: 0.3201075593217673 0.4158101644249426\n",
      "epoch: 158\n",
      "epoch: 158 loss: 0.3219664630037594\n",
      "eval loss: 0.31706222696628017 0.40992050954327625\n",
      "epoch: 159\n",
      "epoch: 159 loss: 0.32183888593904014\n",
      "eval loss: 0.3166569835325981 0.41124148613316314\n",
      "epoch: 160\n",
      "epoch: 160 loss: 0.3202443265173378\n",
      "eval loss: 0.3143632698577815 0.40997468721841523\n",
      "epoch: 161\n",
      "epoch: 161 loss: 0.3202843798429418\n",
      "eval loss: 0.31808497948439757 0.4121766638215002\n",
      "epoch: 162\n",
      "epoch: 162 loss: 0.3220736953312111\n",
      "eval loss: 0.31713092427683026 0.40936967846294847\n",
      "epoch: 163\n",
      "epoch: 163 loss: 0.3209130829010259\n",
      "eval loss: 0.31738338500336905 0.4107124318067372\n",
      "epoch: 164\n",
      "epoch: 164 loss: 0.32357435503253573\n",
      "eval loss: 0.31606967841813743 0.41064964628391964\n",
      "epoch: 165\n",
      "epoch: 165 loss: 0.3204408348377741\n",
      "eval loss: 0.31691493696905004 0.4124447934134443\n",
      "epoch: 166\n",
      "epoch: 166 loss: 0.320936740945068\n",
      "eval loss: 0.315044562917283 0.41141482845339816\n",
      "epoch: 167\n",
      "epoch: 167 loss: 0.3226161997531609\n",
      "eval loss: 0.3152843630062171 0.410152279552898\n",
      "epoch: 168\n",
      "epoch: 168 loss: 0.3202709208660258\n",
      "eval loss: 0.31396991485297776 0.40916800655708435\n",
      "epoch: 169\n",
      "epoch: 169 loss: 0.3244295968292567\n",
      "eval loss: 0.3269565160966447 0.42198444270844976\n",
      "epoch: 170\n",
      "epoch: 170 loss: 0.32158256448610734\n",
      "eval loss: 0.3197570049275259 0.41682669703334807\n",
      "epoch: 171\n",
      "epoch: 171 loss: 0.32100481273386283\n",
      "eval loss: 0.319639422860438 0.4156064587151288\n",
      "epoch: 172\n",
      "epoch: 172 loss: 0.3210402905488095\n",
      "eval loss: 0.3164683798012258 0.41108676643968783\n",
      "epoch: 173\n",
      "epoch: 173 loss: 0.32101356646342216\n",
      "eval loss: 0.31717534187944946 0.4117093519611524\n",
      "epoch: 174\n",
      "epoch: 174 loss: 0.3201321634836302\n",
      "eval loss: 0.31594627452391233 0.41097868588968783\n",
      "epoch: 175\n",
      "epoch: 175 loss: 0.3207206447378953\n",
      "eval loss: 0.3167087763679421 0.4118266755840735\n",
      "epoch: 176\n",
      "epoch: 176 loss: 0.3212364159474136\n",
      "eval loss: 0.3187629849368638 0.4143006687374621\n",
      "epoch: 177\n",
      "epoch: 177 loss: 0.32074599379559665\n",
      "eval loss: 0.31498050143774636 0.4093829390788142\n",
      "epoch: 178\n",
      "epoch: 178 loss: 0.32020220524243664\n",
      "eval loss: 0.31646576686901906 0.4118141369131491\n",
      "epoch: 179\n",
      "epoch: 179 loss: 0.32202726201868964\n",
      "eval loss: 0.3177328809687372 0.4101682083008239\n",
      "epoch: 180\n",
      "epoch: 180 loss: 0.32097266424028553\n",
      "eval loss: 0.3147317375285264 0.4100872597076102\n",
      "epoch: 181\n",
      "epoch: 181 loss: 0.32123199929981466\n",
      "eval loss: 0.316840556716379 0.41272026028150965\n",
      "epoch: 182\n",
      "epoch: 182 loss: 0.3223354901761132\n",
      "eval loss: 0.3144822664274469 0.41058365637507005\n",
      "epoch: 183\n",
      "epoch: 183 loss: 0.3203833571019848\n",
      "eval loss: 0.31516235869390175 0.4111042175317409\n",
      "epoch: 184\n",
      "epoch: 184 loss: 0.3204280439027807\n",
      "eval loss: 0.31810862601996126 0.4131834539070691\n",
      "epoch: 185\n",
      "epoch: 185 loss: 0.3205001915513129\n",
      "eval loss: 0.3171079773531337 0.4119349870550437\n",
      "epoch: 186\n",
      "epoch: 186 loss: 0.3203311045342228\n",
      "eval loss: 0.315318775631291 0.40998150380306186\n",
      "epoch: 187\n",
      "epoch: 187 loss: 0.32214344883571955\n",
      "eval loss: 0.32090449819913686 0.41734717709530483\n",
      "epoch: 188\n",
      "epoch: 188 loss: 0.3214219386815156\n",
      "eval loss: 0.31638600146418255 0.4112250330542465\n",
      "epoch: 189\n",
      "epoch: 189 loss: 0.3202462997830146\n",
      "eval loss: 0.31644718665687577 0.4115433791147497\n",
      "epoch: 190\n",
      "epoch: 190 loss: 0.3201520303988308\n",
      "eval loss: 0.31688159264048915 0.41165593803987405\n",
      "epoch: 191\n",
      "epoch: 191 loss: 0.3217967251356821\n",
      "eval loss: 0.3160941503729048 0.41054704250425506\n",
      "epoch: 192\n",
      "epoch: 192 loss: 0.32089334893881655\n",
      "eval loss: 0.31854685264945903 0.41376454665737833\n",
      "epoch: 193\n",
      "epoch: 193 loss: 0.3217608503837662\n",
      "eval loss: 0.3199608624115031 0.41767843404307803\n",
      "epoch: 194\n",
      "epoch: 194 loss: 0.3215743964604392\n",
      "eval loss: 0.31807583642405357 0.4150014868518557\n",
      "epoch: 195\n",
      "epoch: 195 loss: 0.32098770080963995\n",
      "eval loss: 0.31795723002092363 0.4132009782997889\n",
      "epoch: 196\n",
      "epoch: 196 loss: 0.3210478123390042\n",
      "eval loss: 0.31597379557368743 0.40951232777781904\n",
      "epoch: 197\n",
      "epoch: 197 loss: 0.32052850061081517\n",
      "eval loss: 0.31621992688478223 0.41138578414224336\n",
      "epoch: 198\n",
      "epoch: 198 loss: 0.3204294062793617\n",
      "eval loss: 0.31655479780498574 0.4122403835623516\n",
      "epoch: 199\n",
      "epoch: 199 loss: 0.3205558296466774\n",
      "eval loss: 0.3169385509887219 0.4138542461438086\n",
      "min eval loss: 0.15286427776417857 epoch 98\n",
      "fold: 1\n",
      "(1, 107, 107, 3)\n",
      "(1, 107, 107, 3)\n",
      "(2160, 21) (240, 21)\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='200' class='' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [200/200 32:46<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 0 loss: 0.3181987736482989\n",
      "eval loss: 0.269012711874039 0.34476528549723845\n",
      "epoch: 1\n",
      "epoch: 1 loss: 0.25142742173912735\n",
      "eval loss: 0.2502987958584305 0.32175619466895705\n",
      "epoch: 2\n",
      "epoch: 2 loss: 0.23724350052074897\n",
      "eval loss: 0.2366493922613413 0.30300353778159883\n",
      "epoch: 3\n",
      "epoch: 3 loss: 0.22876732599606867\n",
      "eval loss: 0.23081720523103616 0.29675948936631014\n",
      "epoch: 4\n",
      "epoch: 4 loss: 0.22235602177546504\n",
      "eval loss: 0.2268556522734344 0.290205301724517\n",
      "epoch: 5\n",
      "epoch: 5 loss: 0.21485286223850888\n",
      "eval loss: 0.21844033779238053 0.2810966452817575\n",
      "epoch: 6\n",
      "epoch: 6 loss: 0.21035657798096669\n",
      "eval loss: 0.21670661149395126 0.2786513677949892\n",
      "epoch: 7\n",
      "epoch: 7 loss: 0.20612980609174195\n",
      "eval loss: 0.21014767178400767 0.27030057744550323\n",
      "epoch: 8\n",
      "epoch: 8 loss: 0.20026288136918355\n",
      "eval loss: 0.2076115725443952 0.2667314803809023\n",
      "epoch: 9\n",
      "epoch: 9 loss: 0.1964911299651603\n",
      "eval loss: 0.20514962913518547 0.26438466414498935\n",
      "epoch: 10\n",
      "epoch: 10 loss: 0.19170140702260974\n",
      "eval loss: 0.19837215065461378 0.2548932952363073\n",
      "epoch: 11\n",
      "epoch: 11 loss: 0.18795743929728015\n",
      "eval loss: 0.19557744406915853 0.25069928725819285\n",
      "epoch: 12\n",
      "epoch: 12 loss: 0.18461421667840058\n",
      "eval loss: 0.19534201465060488 0.25187202344388737\n",
      "epoch: 13\n",
      "epoch: 13 loss: 0.183019664525\n",
      "eval loss: 0.1934077330304571 0.24768247896263057\n",
      "epoch: 14\n",
      "epoch: 14 loss: 0.18126966198951874\n",
      "eval loss: 0.19004501951999148 0.24516282757889857\n",
      "epoch: 15\n",
      "epoch: 15 loss: 0.1755861381679505\n",
      "eval loss: 0.19094950592718124 0.2459904921469828\n",
      "epoch: 16\n",
      "epoch: 16 loss: 0.17417645134551765\n",
      "eval loss: 0.1897007210899297 0.24379490258117953\n",
      "epoch: 17\n",
      "epoch: 17 loss: 0.17262707907991287\n",
      "eval loss: 0.19285351426675004 0.2485413965550351\n",
      "epoch: 18\n",
      "epoch: 18 loss: 0.1723054195545442\n",
      "eval loss: 0.18648866021078897 0.23913130941959032\n",
      "epoch: 19\n",
      "epoch: 19 loss: 0.16839808062931488\n",
      "eval loss: 0.1840355819698184 0.2384261147483706\n",
      "epoch: 20\n",
      "epoch: 20 loss: 0.1662511409958643\n",
      "eval loss: 0.18452712172369237 0.23808350377715057\n",
      "epoch: 21\n",
      "epoch: 21 loss: 0.1676633104139874\n",
      "eval loss: 0.18175119121389724 0.23338124341577188\n",
      "epoch: 22\n",
      "epoch: 22 loss: 0.1628903523429741\n",
      "eval loss: 0.17926897382827295 0.232213409668483\n",
      "epoch: 23\n",
      "epoch: 23 loss: 0.16348461852365032\n",
      "eval loss: 0.17873433040759876 0.23110675091985844\n",
      "epoch: 24\n",
      "epoch: 24 loss: 0.16424936324452208\n",
      "eval loss: 0.18803507325305482 0.2419621925723936\n",
      "epoch: 25\n",
      "epoch: 25 loss: 0.16387909927397742\n",
      "eval loss: 0.1835698401489498 0.23756407759126888\n",
      "epoch: 26\n",
      "epoch: 26 loss: 0.16082691092885565\n",
      "eval loss: 0.18040678434639698 0.23341261745091751\n",
      "epoch: 27\n",
      "epoch: 27 loss: 0.15949661491000872\n",
      "eval loss: 0.1765981449927671 0.22807789107123533\n",
      "epoch: 28\n",
      "epoch: 28 loss: 0.15725691097262318\n",
      "eval loss: 0.1806835523283834 0.2320097115108496\n",
      "epoch: 29\n",
      "epoch: 29 loss: 0.15662797425138225\n",
      "eval loss: 0.17987221469405987 0.2326536794520265\n",
      "epoch: 30\n",
      "epoch: 30 loss: 0.15743837155868148\n",
      "eval loss: 0.17754957013588263 0.22888566621979883\n",
      "epoch: 31\n",
      "epoch: 31 loss: 0.15583386389552847\n",
      "eval loss: 0.17913325721826212 0.23102422024374591\n",
      "epoch: 32\n",
      "epoch: 32 loss: 0.1531140885628907\n",
      "eval loss: 0.1783460302161583 0.22993795211471527\n",
      "epoch: 33\n",
      "epoch: 33 loss: 0.15503697556143828\n",
      "eval loss: 0.18163223673782738 0.23367109384819884\n",
      "epoch: 34\n",
      "epoch: 34 loss: 0.15330411492037058\n",
      "eval loss: 0.18097121406507816 0.23325557292319907\n",
      "epoch: 35\n",
      "epoch: 35 loss: 0.15312284519488242\n",
      "eval loss: 0.17559640842300056 0.22711300744444773\n",
      "epoch: 36\n",
      "epoch: 36 loss: 0.15087345821506407\n",
      "eval loss: 0.17587229262870013 0.22697414744660896\n",
      "epoch: 37\n",
      "epoch: 37 loss: 0.1513898576325134\n",
      "eval loss: 0.17775279737897318 0.22807575785359785\n",
      "epoch: 38\n",
      "epoch: 38 loss: 0.15026089033501186\n",
      "eval loss: 0.17487544699479818 0.22517684116854003\n",
      "epoch: 39\n",
      "epoch: 39 loss: 0.14955159285610117\n",
      "eval loss: 0.18020584055225264 0.23214910873046285\n",
      "epoch: 40\n",
      "epoch: 40 loss: 0.14862569737448614\n",
      "eval loss: 0.17899160692898258 0.23149637787274707\n",
      "epoch: 41\n",
      "epoch: 41 loss: 0.1493192107904703\n",
      "eval loss: 0.17736535212886917 0.22806498993139337\n",
      "epoch: 42\n",
      "epoch: 42 loss: 0.14727577179726312\n",
      "eval loss: 0.17553072042711515 0.22709935738434606\n",
      "epoch: 43\n",
      "epoch: 43 loss: 0.14653783133669576\n",
      "eval loss: 0.17406669567507638 0.22507254743783642\n",
      "epoch: 44\n",
      "epoch: 44 loss: 0.14618868899777285\n",
      "eval loss: 0.17464259482378358 0.22594487383197898\n",
      "epoch: 45\n",
      "epoch: 45 loss: 0.1456514982796616\n",
      "eval loss: 0.17833587859494082 0.23107429314899633\n",
      "epoch: 46\n",
      "epoch: 46 loss: 0.14608419620401136\n",
      "eval loss: 0.17495406836586358 0.2259070090855203\n",
      "epoch: 47\n",
      "epoch: 47 loss: 0.1442276810356168\n",
      "eval loss: 0.1732557777927447 0.2241520925586454\n",
      "epoch: 48\n",
      "epoch: 48 loss: 0.14183190949873944\n",
      "eval loss: 0.17154759030728203 0.22122575994573926\n",
      "epoch: 49\n",
      "epoch: 49 loss: 0.14240997462230123\n",
      "eval loss: 0.17424828771283637 0.22427152178261778\n",
      "epoch: 50\n",
      "epoch: 50 loss: 0.14102693244523237\n",
      "eval loss: 0.17339802794420087 0.22399832211951462\n",
      "epoch: 51\n",
      "epoch: 51 loss: 0.14136878166244413\n",
      "eval loss: 0.17253158699600835 0.22261437317146998\n",
      "epoch: 52\n",
      "epoch: 52 loss: 0.14018509194579917\n",
      "eval loss: 0.1727988288552489 0.22237038551456872\n",
      "epoch: 53\n",
      "epoch: 53 loss: 0.13972930660985813\n",
      "eval loss: 0.1717465002772792 0.22214906581261282\n",
      "epoch: 54\n",
      "epoch: 54 loss: 0.13913745300177405\n",
      "eval loss: 0.17306969224411453 0.22245752818140632\n",
      "epoch: 55\n",
      "epoch: 55 loss: 0.1400935934774792\n",
      "eval loss: 0.17501573759994735 0.22672207814930576\n",
      "epoch: 56\n",
      "epoch: 56 loss: 0.13835133044201378\n",
      "eval loss: 0.17398559518556705 0.22511641070233634\n",
      "epoch: 57\n",
      "epoch: 57 loss: 0.13796489672490764\n",
      "eval loss: 0.17185337173140672 0.22145690898504788\n",
      "epoch: 58\n",
      "epoch: 58 loss: 0.13664725500355338\n",
      "eval loss: 0.17380870089174735 0.22491075237050467\n",
      "epoch: 59\n",
      "epoch: 59 loss: 0.1372996547381335\n",
      "eval loss: 0.17130105488066522 0.22220541716108472\n",
      "epoch: 60\n",
      "epoch: 60 loss: 0.13773251244979096\n",
      "eval loss: 0.1718184885927031 0.22095835961414545\n",
      "epoch: 61\n",
      "epoch: 61 loss: 0.13578433790599728\n",
      "eval loss: 0.1699665955750683 0.2193419966049426\n",
      "epoch: 62\n",
      "epoch: 62 loss: 0.13479302480346164\n",
      "eval loss: 0.16943203046630334 0.21894966925973908\n",
      "epoch: 63\n",
      "epoch: 63 loss: 0.13519577733189575\n",
      "eval loss: 0.17248855618403655 0.22034669252112576\n",
      "epoch: 64\n",
      "epoch: 64 loss: 0.13447236430558107\n",
      "eval loss: 0.17106840329086015 0.22059653823436576\n",
      "epoch: 65\n",
      "epoch: 65 loss: 0.1340731584253622\n",
      "eval loss: 0.17498097760371417 0.22490881314782502\n",
      "epoch: 66\n",
      "epoch: 66 loss: 0.1328030583037977\n",
      "eval loss: 0.17121091492592744 0.22014830068916133\n",
      "epoch: 67\n",
      "epoch: 67 loss: 0.13150644547360443\n",
      "eval loss: 0.1705605411693026 0.22058143379720446\n",
      "epoch: 68\n",
      "epoch: 68 loss: 0.13212909807510873\n",
      "eval loss: 0.16997007494802457 0.22039286234175182\n",
      "epoch: 69\n",
      "epoch: 69 loss: 0.13265223729692008\n",
      "eval loss: 0.17193312755614565 0.22076485036395307\n",
      "epoch: 70\n",
      "epoch: 70 loss: 0.13099545543508526\n",
      "eval loss: 0.17193781017075374 0.22148303726869648\n",
      "epoch: 71\n",
      "epoch: 71 loss: 0.13110689172687592\n",
      "eval loss: 0.1693203643590628 0.21776515252619078\n",
      "epoch: 72\n",
      "epoch: 72 loss: 0.1285247405172544\n",
      "eval loss: 0.16754607273432054 0.2160505653948402\n",
      "epoch: 73\n",
      "epoch: 73 loss: 0.1291756678842295\n",
      "eval loss: 0.16950167085664444 0.2175970099514648\n",
      "epoch: 74\n",
      "epoch: 74 loss: 0.1281726266003449\n",
      "eval loss: 0.16820537359144294 0.216375411157332\n",
      "epoch: 75\n",
      "epoch: 75 loss: 0.12963952594917413\n",
      "eval loss: 0.17028763174719336 0.21940801308429242\n",
      "epoch: 76\n",
      "epoch: 76 loss: 0.12957242264974891\n",
      "eval loss: 0.17119527681926325 0.22015661097127126\n",
      "epoch: 77\n",
      "epoch: 77 loss: 0.130388277382902\n",
      "eval loss: 0.17262983652082092 0.2213916515237926\n",
      "epoch: 78\n",
      "epoch: 78 loss: 0.12774221438870348\n",
      "eval loss: 0.16818185434531316 0.2163208025156272\n",
      "epoch: 79\n",
      "epoch: 79 loss: 0.12602988205517252\n",
      "eval loss: 0.1668660490557035 0.21616349442527116\n",
      "epoch: 80\n",
      "epoch: 80 loss: 0.1269999379036146\n",
      "eval loss: 0.16906639650224797 0.2165492835469961\n",
      "epoch: 81\n",
      "epoch: 81 loss: 0.12724275867983978\n",
      "eval loss: 0.17097024311968714 0.22093658107356434\n",
      "epoch: 82\n",
      "epoch: 82 loss: 0.1263730929139414\n",
      "eval loss: 0.17035725299902513 0.21958700128697714\n",
      "epoch: 83\n",
      "epoch: 83 loss: 0.12704960126190487\n",
      "eval loss: 0.17007950916563244 0.21923131037338842\n",
      "epoch: 84\n",
      "epoch: 84 loss: 0.12531615849448233\n",
      "eval loss: 0.17161889914706505 0.22122034256676726\n",
      "epoch: 85\n",
      "epoch: 85 loss: 0.12446155932033619\n",
      "eval loss: 0.1665011633127051 0.214444184178319\n",
      "epoch: 86\n",
      "epoch: 86 loss: 0.12341906615028328\n",
      "eval loss: 0.17100641656804227 0.2204319616361109\n",
      "epoch: 87\n",
      "epoch: 87 loss: 0.12434547622563666\n",
      "eval loss: 0.16863472286509454 0.21900977346353612\n",
      "epoch: 88\n",
      "epoch: 88 loss: 0.12461356852174076\n",
      "eval loss: 0.16778960702985343 0.21608306979510256\n",
      "epoch: 89\n",
      "epoch: 89 loss: 0.12329680300963639\n",
      "eval loss: 0.16838860187675525 0.21710227265811383\n",
      "epoch: 90\n",
      "epoch: 90 loss: 0.12456687733945057\n",
      "eval loss: 0.16986172434763389 0.21862995312595052\n",
      "epoch: 91\n",
      "epoch: 91 loss: 0.123036976249961\n",
      "eval loss: 0.16873263055536075 0.21891785336538241\n",
      "epoch: 92\n",
      "epoch: 92 loss: 0.1233274086958948\n",
      "eval loss: 0.16950970965593207 0.2182300655264066\n",
      "epoch: 93\n",
      "epoch: 93 loss: 0.12251269151533416\n",
      "eval loss: 0.16853481873042947 0.21665855306365067\n",
      "epoch: 94\n",
      "epoch: 94 loss: 0.12205622851890187\n",
      "eval loss: 0.17117179202145164 0.2211293653220893\n",
      "epoch: 95\n",
      "epoch: 95 loss: 0.12230833828118504\n",
      "eval loss: 0.16751905582039645 0.21645123491416068\n",
      "epoch: 96\n",
      "epoch: 96 loss: 0.1201263888356746\n",
      "eval loss: 0.16810444296843963 0.2171353466940814\n",
      "epoch: 97\n",
      "epoch: 97 loss: 0.12042847419896109\n",
      "eval loss: 0.16928615232914634 0.21842689860960623\n",
      "epoch: 98\n",
      "epoch: 98 loss: 0.11984943055698212\n",
      "eval loss: 0.16855196807457334 0.21633351459710254\n",
      "epoch: 99\n",
      "epoch: 99 loss: 0.11904999214970559\n",
      "eval loss: 0.16699944601456287 0.21456518981953465\n",
      "epoch: 100\n",
      "epoch: 100 loss: 0.11869661632785726\n",
      "eval loss: 0.16745399143643885 0.21498006434060962\n",
      "epoch: 101\n",
      "epoch: 101 loss: 0.11951159048084345\n",
      "eval loss: 0.16765631159703467 0.21522928455769413\n",
      "epoch: 102\n",
      "epoch: 102 loss: 0.117487351626379\n",
      "eval loss: 0.1667183348582109 0.21547011209786068\n",
      "epoch: 103\n",
      "epoch: 103 loss: 0.11823516398691748\n",
      "eval loss: 0.16894940553749463 0.21810571090502592\n",
      "epoch: 104\n",
      "epoch: 104 loss: 0.11758610661351704\n",
      "eval loss: 0.16870557077237425 0.21728129999091933\n",
      "epoch: 105\n",
      "epoch: 105 loss: 0.11734692373742683\n",
      "eval loss: 0.16868403283636482 0.21795445318148798\n",
      "epoch: 106\n",
      "epoch: 106 loss: 0.11825001392871123\n",
      "eval loss: 0.168308113383207 0.21744631486612145\n",
      "epoch: 107\n",
      "epoch: 107 loss: 0.12009305382210587\n",
      "eval loss: 0.1683070383037053 0.21626456654146287\n",
      "epoch: 108\n",
      "epoch: 108 loss: 0.11937298737713317\n",
      "eval loss: 0.17025043499643444 0.2188743759970113\n",
      "epoch: 109\n",
      "epoch: 109 loss: 0.11775010882923054\n",
      "eval loss: 0.1695996279233088 0.2180056339400971\n",
      "epoch: 110\n",
      "epoch: 110 loss: 0.11636122751813201\n",
      "eval loss: 0.16766700505741733 0.21535596135805388\n",
      "epoch: 111\n",
      "epoch: 111 loss: 0.11613883400560457\n",
      "eval loss: 0.16756946209872486 0.21549397916816132\n",
      "epoch: 112\n",
      "epoch: 112 loss: 0.11708439725347906\n",
      "eval loss: 0.16803759162060095 0.21612509220019047\n",
      "epoch: 113\n",
      "epoch: 113 loss: 0.1158529798059053\n",
      "eval loss: 0.1688332631555473 0.21654734412922605\n",
      "epoch: 114\n",
      "epoch: 114 loss: 0.11559109705496208\n",
      "eval loss: 0.16796805657962688 0.21586023170716723\n",
      "epoch: 115\n",
      "epoch: 115 loss: 0.11556180457493193\n",
      "eval loss: 0.16896818174941267 0.2171461510822614\n",
      "epoch: 116\n",
      "epoch: 116 loss: 0.11500314070053831\n",
      "eval loss: 0.16583693174147185 0.21490100637562706\n",
      "epoch: 117\n",
      "epoch: 117 loss: 0.11461985383430534\n",
      "eval loss: 0.16673956864357958 0.21438603677926582\n",
      "epoch: 118\n",
      "epoch: 118 loss: 0.11401004952388061\n",
      "eval loss: 0.1671640310549673 0.2150850876557584\n",
      "epoch: 119\n",
      "epoch: 119 loss: 0.11409661327217464\n",
      "eval loss: 0.16573890349651646 0.21369435631570446\n",
      "epoch: 120\n",
      "epoch: 120 loss: 0.11338684780119228\n",
      "eval loss: 0.16751781817605182 0.21582825943035222\n",
      "epoch: 121\n",
      "epoch: 121 loss: 0.11460227463867424\n",
      "eval loss: 0.16788495764092015 0.21576288727058135\n",
      "epoch: 122\n",
      "epoch: 122 loss: 0.11356159303224256\n",
      "eval loss: 0.16723195406618852 0.21533048059062046\n",
      "epoch: 123\n",
      "epoch: 123 loss: 0.17433524955536825\n",
      "eval loss: 0.3509810705154013 0.4479582816251426\n",
      "epoch: 124\n",
      "epoch: 124 loss: 0.3399485036233674\n",
      "eval loss: 0.3264633911883802 0.41553364505811136\n",
      "epoch: 125\n",
      "epoch: 125 loss: 0.3220190760821266\n",
      "eval loss: 0.3320113293998964 0.4232543013589842\n",
      "epoch: 126\n",
      "epoch: 126 loss: 0.32221820256041594\n",
      "eval loss: 0.3260169178921458 0.41754636034131987\n",
      "epoch: 127\n",
      "epoch: 127 loss: 0.32078803108885057\n",
      "eval loss: 0.3263931217560646 0.41457784964646865\n",
      "epoch: 128\n",
      "epoch: 128 loss: 0.32075284407537863\n",
      "eval loss: 0.3274863891132628 0.41555151206717533\n",
      "epoch: 129\n",
      "epoch: 129 loss: 0.3207890883379849\n",
      "eval loss: 0.3270474741796535 0.41628714563033253\n",
      "epoch: 130\n",
      "epoch: 130 loss: 0.32183473095720183\n",
      "eval loss: 0.3253223112977006 0.41544387017469697\n",
      "epoch: 131\n",
      "epoch: 131 loss: 0.3196081978151808\n",
      "eval loss: 0.32380959969935513 0.4136964509113047\n",
      "epoch: 132\n",
      "epoch: 132 loss: 0.32095362144348266\n",
      "eval loss: 0.32677462958508147 0.41722505474683325\n",
      "epoch: 133\n",
      "epoch: 133 loss: 0.32178805062859056\n",
      "eval loss: 0.33595500534791767 0.4278084968640131\n",
      "epoch: 134\n",
      "epoch: 134 loss: 0.3242345379804444\n",
      "eval loss: 0.32220202090332034 0.41335385941896635\n",
      "epoch: 135\n",
      "epoch: 135 loss: 0.3205434454025207\n",
      "eval loss: 0.32633250165618916 0.41586012234257347\n",
      "epoch: 136\n",
      "epoch: 136 loss: 0.3203157401557343\n",
      "eval loss: 0.32414968078811984 0.41441478986259167\n",
      "epoch: 137\n",
      "epoch: 137 loss: 0.3205567010706152\n",
      "eval loss: 0.324283383626472 0.41272444001876657\n",
      "epoch: 138\n",
      "epoch: 138 loss: 0.3199020001499762\n",
      "eval loss: 0.32388195297604583 0.41477976578477854\n",
      "epoch: 139\n",
      "epoch: 139 loss: 0.3201187096648731\n",
      "eval loss: 0.3248826169128946 0.41431464235535803\n",
      "epoch: 140\n",
      "epoch: 140 loss: 0.32060341886860394\n",
      "eval loss: 0.32640224323248496 0.416357715999491\n",
      "epoch: 141\n",
      "epoch: 141 loss: 0.32118621951232085\n",
      "eval loss: 0.32581937381943377 0.41421359615638775\n",
      "epoch: 142\n",
      "epoch: 142 loss: 0.31965083617232204\n",
      "eval loss: 0.33390833832301964 0.42344138072798043\n",
      "epoch: 143\n",
      "epoch: 143 loss: 0.32028365031452866\n",
      "eval loss: 0.3232513719177554 0.41434889382631046\n",
      "epoch: 144\n",
      "epoch: 144 loss: 0.3198139947057152\n",
      "eval loss: 0.33929872844118625 0.43261697105077357\n",
      "epoch: 145\n",
      "epoch: 145 loss: 0.3209270320223164\n",
      "eval loss: 0.32412546787050095 0.4129342247127883\n",
      "epoch: 146\n",
      "epoch: 146 loss: 0.32032906133026434\n",
      "eval loss: 0.32455163224518635 0.41352109632842055\n",
      "epoch: 147\n",
      "epoch: 147 loss: 0.3205167236623929\n",
      "eval loss: 0.33044043800896633 0.41959602626208076\n",
      "epoch: 148\n",
      "epoch: 148 loss: 0.3163178651939958\n",
      "eval loss: 0.3197449405372553 0.4105389171766207\n",
      "epoch: 149\n",
      "epoch: 149 loss: 0.3166921530038126\n",
      "eval loss: 0.3252817208315288 0.41408946427368715\n",
      "epoch: 150\n",
      "epoch: 150 loss: 0.3149922200684102\n",
      "eval loss: 0.3220888295500538 0.41119955694546084\n",
      "epoch: 151\n",
      "epoch: 151 loss: 0.31374527567172206\n",
      "eval loss: 0.31743124123538513 0.40442400612557294\n",
      "epoch: 152\n",
      "epoch: 152 loss: 0.31358818130645905\n",
      "eval loss: 0.32220123360246056 0.4102105108388675\n",
      "epoch: 153\n",
      "epoch: 153 loss: 0.31378855454970234\n",
      "eval loss: 0.3207250374237081 0.4077298101051231\n",
      "epoch: 154\n",
      "epoch: 154 loss: 0.31288222682474515\n",
      "eval loss: 0.32642103917203935 0.4144051139209145\n",
      "epoch: 155\n",
      "epoch: 155 loss: 0.31705643901821734\n",
      "eval loss: 0.3176102858038783 0.40733845846520444\n",
      "epoch: 156\n",
      "epoch: 156 loss: 0.31422554435238076\n",
      "eval loss: 0.31801841677819376 0.4052311617534955\n",
      "epoch: 157\n",
      "epoch: 157 loss: 0.31306529384193715\n",
      "eval loss: 0.32029939290934956 0.40935870920903805\n",
      "epoch: 158\n",
      "epoch: 158 loss: 0.3124281129890008\n",
      "eval loss: 0.31787922622820586 0.40585680216590336\n",
      "epoch: 159\n",
      "epoch: 159 loss: 0.3124487824303973\n",
      "eval loss: 0.31898584393881735 0.408071657453827\n",
      "epoch: 160\n",
      "epoch: 160 loss: 0.3130644214298547\n",
      "eval loss: 0.31794480839307826 0.40442153979369694\n",
      "epoch: 161\n",
      "epoch: 161 loss: 0.31254742198541596\n",
      "eval loss: 0.31720638377098787 0.4044658473593022\n",
      "epoch: 162\n",
      "epoch: 162 loss: 0.31278494659017386\n",
      "eval loss: 0.32365547092526126 0.4122533571168784\n",
      "epoch: 163\n",
      "epoch: 163 loss: 0.31242368229589873\n",
      "eval loss: 0.3232498922061108 0.41360900147813395\n",
      "epoch: 164\n",
      "epoch: 164 loss: 0.3187876508097497\n",
      "eval loss: 0.3168874046269689 0.40342943998821185\n",
      "epoch: 165\n",
      "epoch: 165 loss: 0.31178914001112384\n",
      "eval loss: 0.31858467105553057 0.4057630215814031\n",
      "epoch: 166\n",
      "epoch: 166 loss: 0.3111094956738038\n",
      "eval loss: 0.31764731605207497 0.4051946273818276\n",
      "epoch: 167\n",
      "epoch: 167 loss: 0.31206973579593966\n",
      "eval loss: 0.31761783294257856 0.40246789774192476\n",
      "epoch: 168\n",
      "epoch: 168 loss: 0.3118422144290908\n",
      "eval loss: 0.31597661039812985 0.40263871536055695\n",
      "epoch: 169\n",
      "epoch: 169 loss: 0.3116366227747097\n",
      "eval loss: 0.3182876084945591 0.40574795240994127\n",
      "epoch: 170\n",
      "epoch: 170 loss: 0.3110320485904184\n",
      "eval loss: 0.3171974544683964 0.40262401029512673\n",
      "epoch: 171\n",
      "epoch: 171 loss: 0.3097836805335299\n",
      "eval loss: 0.31999841651122457 0.4078180221532061\n",
      "epoch: 172\n",
      "epoch: 172 loss: 0.310575977854558\n",
      "eval loss: 0.3175546020737506 0.40400599102827545\n",
      "epoch: 173\n",
      "epoch: 173 loss: 0.308813765939449\n",
      "eval loss: 0.3159931390336017 0.4023769558166469\n",
      "epoch: 174\n",
      "epoch: 174 loss: 0.31058527598770996\n",
      "eval loss: 0.3223856852778981 0.40843816504419966\n",
      "epoch: 175\n",
      "epoch: 175 loss: 0.31004418520755234\n",
      "eval loss: 0.31660131582978107 0.40289337590010144\n",
      "epoch: 176\n",
      "epoch: 176 loss: 0.31031754985990195\n",
      "eval loss: 0.3182771475755762 0.4060822407344977\n",
      "epoch: 177\n",
      "epoch: 177 loss: 0.3107201591381596\n",
      "eval loss: 0.31782840890570385 0.40386168039834036\n",
      "epoch: 178\n",
      "epoch: 178 loss: 0.3106743349415482\n",
      "eval loss: 0.31850174434972534 0.40488201271254226\n",
      "epoch: 179\n",
      "epoch: 179 loss: 0.3108089765315349\n",
      "eval loss: 0.3158187939192748 0.4018545158942313\n",
      "epoch: 180\n",
      "epoch: 180 loss: 0.31060680208803376\n",
      "eval loss: 0.3170813241746136 0.4032667141063709\n",
      "epoch: 181\n",
      "epoch: 181 loss: 0.3097464795995639\n",
      "eval loss: 0.31940422518758793 0.40890664118001746\n",
      "epoch: 182\n",
      "epoch: 182 loss: 0.3110378452143194\n",
      "eval loss: 0.31599037295137644 0.4004861343528843\n",
      "epoch: 183\n",
      "epoch: 183 loss: 0.31020447388247563\n",
      "eval loss: 0.31880930165278365 0.40587312406055154\n",
      "epoch: 184\n",
      "epoch: 184 loss: 0.31312569803572066\n",
      "eval loss: 0.3151597263900904 0.40063773892906085\n",
      "epoch: 185\n",
      "epoch: 185 loss: 0.3103166601014661\n",
      "eval loss: 0.3179788325931276 0.4037425730272882\n",
      "epoch: 186\n",
      "epoch: 186 loss: 0.3090024652644172\n",
      "eval loss: 0.31366829297176313 0.39966198416501897\n",
      "epoch: 187\n",
      "epoch: 187 loss: 0.30946349917047833\n",
      "eval loss: 0.3167149732097895 0.4015794836036811\n",
      "epoch: 188\n",
      "epoch: 188 loss: 0.30922624984123087\n",
      "eval loss: 0.32019271282036194 0.40841980809391565\n",
      "epoch: 189\n",
      "epoch: 189 loss: 0.3104083182224326\n",
      "eval loss: 0.3141733618286937 0.3986701618235776\n",
      "epoch: 190\n",
      "epoch: 190 loss: 0.31055697343331146\n",
      "eval loss: 0.3161561340461562 0.4011252601047338\n",
      "epoch: 191\n",
      "epoch: 191 loss: 0.31003993540669567\n",
      "eval loss: 0.31885128313677713 0.40535591246065084\n",
      "epoch: 192\n",
      "epoch: 192 loss: 0.30879417965722616\n",
      "eval loss: 0.31127233896187734 0.4004529652007984\n",
      "epoch: 193\n",
      "epoch: 193 loss: 0.3106069890535283\n",
      "eval loss: 0.31627415222592403 0.4015837001203338\n",
      "epoch: 194\n",
      "epoch: 194 loss: 0.3098169550295849\n",
      "eval loss: 0.31149716143457606 0.39515539332062966\n",
      "epoch: 195\n",
      "epoch: 195 loss: 0.3078184517257605\n",
      "eval loss: 0.3105018261710806 0.3953188823424853\n",
      "epoch: 196\n",
      "epoch: 196 loss: 0.3070702726093253\n",
      "eval loss: 0.31027537234925723 0.395220928741942\n",
      "epoch: 197\n",
      "epoch: 197 loss: 0.3074552823805826\n",
      "eval loss: 0.3114096459261628 0.3965290603033691\n",
      "epoch: 198\n",
      "epoch: 198 loss: 0.307407127985165\n",
      "eval loss: 0.31435293771161715 0.3980242968893333\n",
      "epoch: 199\n",
      "epoch: 199 loss: 0.3088565366658407\n",
      "eval loss: 0.31422202745944544 0.39846713353021995\n",
      "min eval loss: 0.16573890349651646 epoch 119\n",
      "fold: 2\n",
      "(1, 107, 107, 3)\n",
      "(1, 107, 107, 3)\n",
      "(2160, 21) (240, 21)\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='200' class='' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [200/200 32:23<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 0 loss: 0.30675255294334025\n",
      "eval loss: 0.2523324185841425 0.33043347320339367\n",
      "epoch: 1\n",
      "epoch: 1 loss: 0.24322392428209505\n",
      "eval loss: 0.22684039908639345 0.2984399328308906\n",
      "epoch: 2\n",
      "epoch: 2 loss: 0.23005927614710858\n",
      "eval loss: 0.2215354950919223 0.29013876566525304\n",
      "epoch: 3\n",
      "epoch: 3 loss: 0.21805803409069438\n",
      "eval loss: 0.2105247092112688 0.2749243725963975\n",
      "epoch: 4\n",
      "epoch: 4 loss: 0.21122834668303445\n",
      "eval loss: 0.2048872286408086 0.268073719707412\n",
      "epoch: 5\n",
      "epoch: 5 loss: 0.20428677541255644\n",
      "eval loss: 0.20161806564219875 0.2641234469247521\n",
      "epoch: 6\n",
      "epoch: 6 loss: 0.19843234963777687\n",
      "eval loss: 0.19669552856487388 0.2569515582608596\n",
      "epoch: 7\n",
      "epoch: 7 loss: 0.19304488797458272\n",
      "eval loss: 0.19212128865824096 0.25119577921496866\n",
      "epoch: 8\n",
      "epoch: 8 loss: 0.1911657480170006\n",
      "eval loss: 0.19257967119580024 0.25309481369730913\n",
      "epoch: 9\n",
      "epoch: 9 loss: 0.18706884036313812\n",
      "eval loss: 0.18655658723625546 0.24505390539759267\n",
      "epoch: 10\n",
      "epoch: 10 loss: 0.18278405414736484\n",
      "eval loss: 0.1895096883893714 0.24834916774883647\n",
      "epoch: 11\n",
      "epoch: 11 loss: 0.1808785028657655\n",
      "eval loss: 0.18388887516711774 0.2411105587222977\n",
      "epoch: 12\n",
      "epoch: 12 loss: 0.1785936214240222\n",
      "eval loss: 0.18321687193883004 0.23927754420566577\n",
      "epoch: 13\n",
      "epoch: 13 loss: 0.17550504740223202\n",
      "eval loss: 0.18082490535499077 0.2358001793693333\n",
      "epoch: 14\n",
      "epoch: 14 loss: 0.17346478840059978\n",
      "eval loss: 0.177786436726202 0.2318976697063251\n",
      "epoch: 15\n",
      "epoch: 15 loss: 0.17147655548630228\n",
      "eval loss: 0.17830712620344047 0.23336789672315783\n",
      "epoch: 16\n",
      "epoch: 16 loss: 0.16996801285752036\n",
      "eval loss: 0.17949830706581293 0.2357673406120799\n",
      "epoch: 17\n",
      "epoch: 17 loss: 0.16730549895154936\n",
      "eval loss: 0.17402282212979392 0.22712817830344317\n",
      "epoch: 18\n",
      "epoch: 18 loss: 0.16530909698091817\n",
      "eval loss: 0.17629133188752266 0.23005898062074076\n",
      "epoch: 19\n",
      "epoch: 19 loss: 0.16319300963037042\n",
      "eval loss: 0.1750508530775588 0.2286550809939258\n",
      "epoch: 20\n",
      "epoch: 20 loss: 0.16411169874138357\n",
      "eval loss: 0.18312021271294296 0.23756188792600913\n",
      "epoch: 21\n",
      "epoch: 21 loss: 0.16256853259262344\n",
      "eval loss: 0.17414238527626724 0.22686144729055877\n",
      "epoch: 22\n",
      "epoch: 22 loss: 0.16042920573441025\n",
      "eval loss: 0.17290938099571695 0.22510307412412678\n",
      "epoch: 23\n",
      "epoch: 23 loss: 0.1596881972285065\n",
      "eval loss: 0.1731689793265894 0.22574486319683856\n",
      "epoch: 24\n",
      "epoch: 24 loss: 0.15803116580386625\n",
      "eval loss: 0.17154290756064255 0.22329872771657494\n",
      "epoch: 25\n",
      "epoch: 25 loss: 0.1561656643842977\n",
      "eval loss: 0.17301540379857328 0.22607780666215946\n",
      "epoch: 26\n",
      "epoch: 26 loss: 0.15535580991504291\n",
      "eval loss: 0.17038860021750468 0.2227082840548807\n",
      "epoch: 27\n",
      "epoch: 27 loss: 0.15472590799089384\n",
      "eval loss: 0.17062274272549968 0.22292509109215164\n",
      "epoch: 28\n",
      "epoch: 28 loss: 0.15325484229461983\n",
      "eval loss: 0.16725419297734942 0.2194612237226181\n",
      "epoch: 29\n",
      "epoch: 29 loss: 0.1522755478707137\n",
      "eval loss: 0.1688109083179428 0.2194487399842613\n",
      "epoch: 30\n",
      "epoch: 30 loss: 0.1514667215758726\n",
      "eval loss: 0.1689143268935993 0.2205878390922196\n",
      "epoch: 31\n",
      "epoch: 31 loss: 0.15060635443928397\n",
      "eval loss: 0.17151148129696153 0.22410622614979264\n",
      "epoch: 32\n",
      "epoch: 32 loss: 0.1507282996663881\n",
      "eval loss: 0.16696499789192165 0.21854398981451534\n",
      "epoch: 33\n",
      "epoch: 33 loss: 0.14965147795099631\n",
      "eval loss: 0.16586534453674845 0.2153190300409782\n",
      "epoch: 34\n",
      "epoch: 34 loss: 0.14785086536272382\n",
      "eval loss: 0.16534508409504906 0.21470502841519587\n",
      "epoch: 35\n",
      "epoch: 35 loss: 0.14630521540995328\n",
      "eval loss: 0.16587512172807906 0.21451877423991472\n",
      "epoch: 36\n",
      "epoch: 36 loss: 0.14652329237045245\n",
      "eval loss: 0.16632846470577073 0.216026978574747\n",
      "epoch: 37\n",
      "epoch: 37 loss: 0.14550787639074925\n",
      "eval loss: 0.16884812621466017 0.21940984300525906\n",
      "epoch: 38\n",
      "epoch: 38 loss: 0.14545922238876421\n",
      "eval loss: 0.16512838452376968 0.21588589335137492\n",
      "epoch: 39\n",
      "epoch: 39 loss: 0.14434383938866643\n",
      "eval loss: 0.16485508636868643 0.21490908333407197\n",
      "epoch: 40\n",
      "epoch: 40 loss: 0.14417471133917217\n",
      "eval loss: 0.16535858539668957 0.21472165216856398\n",
      "epoch: 41\n",
      "epoch: 41 loss: 0.1427696426517502\n",
      "eval loss: 0.16495406070924937 0.21604512091260303\n",
      "epoch: 42\n",
      "epoch: 42 loss: 0.14205739984320917\n",
      "eval loss: 0.1656715447689513 0.21487659963053352\n",
      "epoch: 43\n",
      "epoch: 43 loss: 0.1417847073908527\n",
      "eval loss: 0.16599778158167247 0.21527188656146273\n",
      "epoch: 44\n",
      "epoch: 44 loss: 0.14127968522292975\n",
      "eval loss: 0.16332051254418112 0.21298886978161066\n",
      "epoch: 45\n",
      "epoch: 45 loss: 0.13969039541075598\n",
      "eval loss: 0.16325162560362294 0.21315829881704165\n",
      "epoch: 46\n",
      "epoch: 46 loss: 0.1392977870908761\n",
      "eval loss: 0.1631662951693682 0.21251142133993017\n",
      "epoch: 47\n",
      "epoch: 47 loss: 0.1383490318162391\n",
      "eval loss: 0.16224182154370573 0.21162846222107462\n",
      "epoch: 48\n",
      "epoch: 48 loss: 0.13834027349363628\n",
      "eval loss: 0.16689149303539025 0.2171430799417574\n",
      "epoch: 49\n",
      "epoch: 49 loss: 0.13836165934037592\n",
      "eval loss: 0.16260141880914997 0.21238659400926096\n",
      "epoch: 50\n",
      "epoch: 50 loss: 0.13778563808325028\n",
      "eval loss: 0.16254159257082565 0.21155329445283066\n",
      "epoch: 51\n",
      "epoch: 51 loss: 0.1369733038858457\n",
      "eval loss: 0.1639013198574067 0.21228801982330667\n",
      "epoch: 52\n",
      "epoch: 52 loss: 0.13691545386379134\n",
      "eval loss: 0.16512037938528412 0.21547595224236424\n",
      "epoch: 53\n",
      "epoch: 53 loss: 0.13795266010460216\n",
      "eval loss: 0.1636402570370955 0.21309876194909805\n",
      "epoch: 54\n",
      "epoch: 54 loss: 0.13543240811495694\n",
      "eval loss: 0.16488403704014779 0.21480973629446665\n",
      "epoch: 55\n",
      "epoch: 55 loss: 0.1348893308931255\n",
      "eval loss: 0.16644338000685566 0.21645467580651023\n",
      "epoch: 56\n",
      "epoch: 56 loss: 0.1333142190308277\n",
      "eval loss: 0.15974438024415477 0.20862651024011095\n",
      "epoch: 57\n",
      "epoch: 57 loss: 0.13281764913072971\n",
      "eval loss: 0.1634107613186205 0.2120624881779779\n",
      "epoch: 58\n",
      "epoch: 58 loss: 0.13331728550561367\n",
      "eval loss: 0.16092454887341207 0.20991358662635046\n",
      "epoch: 59\n",
      "epoch: 59 loss: 0.13173593424555027\n",
      "eval loss: 0.16192805517361614 0.21108975916382974\n",
      "epoch: 60\n",
      "epoch: 60 loss: 0.1316868889703563\n",
      "eval loss: 0.16163476914686467 0.2106441269849955\n",
      "epoch: 61\n",
      "epoch: 61 loss: 0.13042031708510074\n",
      "eval loss: 0.1654853547800148 0.2160505617476996\n",
      "epoch: 62\n",
      "epoch: 62 loss: 0.13018383009677834\n",
      "eval loss: 0.1605322445176811 0.20946765817231916\n",
      "epoch: 63\n",
      "epoch: 63 loss: 0.13071489675530792\n",
      "eval loss: 0.15897391759282384 0.20876590739502915\n",
      "epoch: 64\n",
      "epoch: 64 loss: 0.1288217565112981\n",
      "eval loss: 0.16171244032638274 0.21033647752850643\n",
      "epoch: 65\n",
      "epoch: 65 loss: 0.12840751748264823\n",
      "eval loss: 0.1605202536265212 0.2091135396096515\n",
      "epoch: 66\n",
      "epoch: 66 loss: 0.12787670134163587\n",
      "eval loss: 0.16048949910821142 0.2077032529634038\n",
      "epoch: 67\n",
      "epoch: 67 loss: 0.12809491556867553\n",
      "eval loss: 0.15970041498643825 0.20803973032262357\n",
      "epoch: 68\n",
      "epoch: 68 loss: 0.12678663318106728\n",
      "eval loss: 0.15872108724375683 0.2075910057886004\n",
      "epoch: 69\n",
      "epoch: 69 loss: 0.12672563568131334\n",
      "eval loss: 0.1618593957098295 0.21118317288308786\n",
      "epoch: 70\n",
      "epoch: 70 loss: 0.12650412786796064\n",
      "eval loss: 0.1618183892005245 0.21211778901846268\n",
      "epoch: 71\n",
      "epoch: 71 loss: 0.1265895277902851\n",
      "eval loss: 0.16156183779789024 0.21011194153170987\n",
      "epoch: 72\n",
      "epoch: 72 loss: 0.12602005105468425\n",
      "eval loss: 0.16062185167822027 0.2088426548000608\n",
      "epoch: 73\n",
      "epoch: 73 loss: 0.12577490619326717\n",
      "eval loss: 0.16122172723156042 0.21016350896259411\n",
      "epoch: 74\n",
      "epoch: 74 loss: 0.12510722795849089\n",
      "eval loss: 0.1601575910116168 0.20752260935477912\n",
      "epoch: 75\n",
      "epoch: 75 loss: 0.12421415713849378\n",
      "eval loss: 0.159151844347189 0.2080139020780521\n",
      "epoch: 76\n",
      "epoch: 76 loss: 0.12392792034947421\n",
      "eval loss: 0.1593903100367861 0.20732161488911255\n",
      "epoch: 77\n",
      "epoch: 77 loss: 0.12333711470776099\n",
      "eval loss: 0.16152972377278946 0.21132136574397453\n",
      "epoch: 78\n",
      "epoch: 78 loss: 0.12416581907386395\n",
      "eval loss: 0.1592513614008015 0.207866570648238\n",
      "epoch: 79\n",
      "epoch: 79 loss: 0.12267160001796136\n",
      "eval loss: 0.15935722293624072 0.2065761730912874\n",
      "epoch: 80\n",
      "epoch: 80 loss: 0.1224612634417434\n",
      "eval loss: 0.15816939149770154 0.20593728968455632\n",
      "epoch: 81\n",
      "epoch: 81 loss: 0.12154740214018253\n",
      "eval loss: 0.16017603038080805 0.20863263441071941\n",
      "epoch: 82\n",
      "epoch: 82 loss: 0.12194889660888292\n",
      "eval loss: 0.15999486675197258 0.20859297817472866\n",
      "epoch: 83\n",
      "epoch: 83 loss: 0.12166229233154813\n",
      "eval loss: 0.15940154299338186 0.20754960234431116\n",
      "epoch: 84\n",
      "epoch: 84 loss: 0.12004518056922177\n",
      "eval loss: 0.15915434757809707 0.20810861979581416\n",
      "epoch: 85\n",
      "epoch: 85 loss: 0.12096270727988528\n",
      "eval loss: 0.16140113857601807 0.21035469802211038\n",
      "epoch: 86\n",
      "epoch: 86 loss: 0.12044215169347755\n",
      "eval loss: 0.15977785555528187 0.20638748825172581\n",
      "epoch: 87\n",
      "epoch: 87 loss: 0.11952485800664367\n",
      "eval loss: 0.1595584781227535 0.20815658755745411\n",
      "epoch: 88\n",
      "epoch: 88 loss: 0.11987159487672754\n",
      "eval loss: 0.15987304569964003 0.2081115535908711\n",
      "epoch: 89\n",
      "epoch: 89 loss: 0.11938818042451053\n",
      "eval loss: 0.1598822551559098 0.20704521845455787\n",
      "epoch: 90\n",
      "epoch: 90 loss: 0.11901351538761666\n",
      "eval loss: 0.16102269975940423 0.21109315251396438\n",
      "epoch: 91\n",
      "epoch: 91 loss: 0.12194763972722186\n",
      "eval loss: 0.163004197323855 0.21154718945393566\n",
      "epoch: 92\n",
      "epoch: 92 loss: 0.12085718466586431\n",
      "eval loss: 0.1591971579024672 0.20648563726470476\n",
      "epoch: 93\n",
      "epoch: 93 loss: 0.118782849313446\n",
      "eval loss: 0.1591249660654429 0.20633901211693617\n",
      "epoch: 94\n",
      "epoch: 94 loss: 0.11874334002175138\n",
      "eval loss: 0.16007286737972715 0.20814890383627066\n",
      "epoch: 95\n",
      "epoch: 95 loss: 0.11790847710836795\n",
      "eval loss: 0.1590922021634996 0.2073620036212416\n",
      "epoch: 96\n",
      "epoch: 96 loss: 0.11779427917763616\n",
      "eval loss: 0.15883787926180737 0.20698732385229457\n",
      "epoch: 97\n",
      "epoch: 97 loss: 0.11767327520681856\n",
      "eval loss: 0.16132226543013367 0.20957340518561016\n",
      "epoch: 98\n",
      "epoch: 98 loss: 0.11681205031947656\n",
      "eval loss: 0.1602320128044301 0.2072775019123927\n",
      "epoch: 99\n",
      "epoch: 99 loss: 0.11707189374246794\n",
      "eval loss: 0.16165858745124007 0.21048141405452023\n",
      "epoch: 100\n",
      "epoch: 100 loss: 0.11572713805283895\n",
      "eval loss: 0.15756327340730714 0.20422286374661486\n",
      "epoch: 101\n",
      "epoch: 101 loss: 0.11505900719456463\n",
      "eval loss: 0.1590638144567598 0.20603091646366262\n",
      "epoch: 102\n",
      "epoch: 102 loss: 0.11548726670750276\n",
      "eval loss: 0.16070564943223928 0.2095700095506092\n",
      "epoch: 103\n",
      "epoch: 103 loss: 0.11659203792979789\n",
      "eval loss: 0.15817832264978407 0.2079871090546923\n",
      "epoch: 104\n",
      "epoch: 104 loss: 0.11642812271787067\n",
      "eval loss: 0.1590833600617233 0.2066406486972453\n",
      "epoch: 105\n",
      "epoch: 105 loss: 0.11516398306700128\n",
      "eval loss: 0.1590113591042039 0.20701236286238256\n",
      "epoch: 106\n",
      "epoch: 106 loss: 0.11551073919541148\n",
      "eval loss: 0.15881947770782798 0.2058528440454609\n",
      "epoch: 107\n",
      "epoch: 107 loss: 0.11348649710624606\n",
      "eval loss: 0.1581310118396303 0.2066605023570379\n",
      "epoch: 108\n",
      "epoch: 108 loss: 0.11322379792889677\n",
      "eval loss: 0.1601237825175242 0.20782440249078613\n",
      "epoch: 109\n",
      "epoch: 109 loss: 0.2337510858720549\n",
      "eval loss: 0.3603786091982205 0.469272813379666\n",
      "epoch: 110\n",
      "epoch: 110 loss: 0.33228679859202664\n",
      "eval loss: 0.3312823810900505 0.4317154045194967\n",
      "epoch: 111\n",
      "epoch: 111 loss: 0.32402981535082537\n",
      "eval loss: 0.3229057335501266 0.4206655617724888\n",
      "epoch: 112\n",
      "epoch: 112 loss: 0.32212403090689246\n",
      "eval loss: 0.3236163763666029 0.4212214557967136\n",
      "epoch: 113\n",
      "epoch: 113 loss: 0.3218591245191531\n",
      "eval loss: 0.32034256613851403 0.41860687275747815\n",
      "epoch: 114\n",
      "epoch: 114 loss: 0.3205657942643357\n",
      "eval loss: 0.3207890435739377 0.41797492106938494\n",
      "epoch: 115\n",
      "epoch: 115 loss: 0.3213320598372421\n",
      "eval loss: 0.3212170690362439 0.4171228773485162\n",
      "epoch: 116\n",
      "epoch: 116 loss: 0.32155808516904766\n",
      "eval loss: 0.32789314896242455 0.4269150502057012\n",
      "epoch: 117\n",
      "epoch: 117 loss: 0.32266149391881555\n",
      "eval loss: 0.32110071074296015 0.41980352764842055\n",
      "epoch: 118\n",
      "epoch: 118 loss: 0.3219186505814157\n",
      "eval loss: 0.3244380558108272 0.421775201398889\n",
      "epoch: 119\n",
      "epoch: 119 loss: 0.3227223723151542\n",
      "eval loss: 0.3239227816249586 0.42362247078282805\n",
      "epoch: 120\n",
      "epoch: 120 loss: 0.32147302094379404\n",
      "eval loss: 0.3241803721723918 0.42131834775995886\n",
      "epoch: 121\n",
      "epoch: 121 loss: 0.32029207585630626\n",
      "eval loss: 0.3187133416366119 0.4174410642567306\n",
      "epoch: 122\n",
      "epoch: 122 loss: 0.3220521116917378\n",
      "eval loss: 0.32071175215550685 0.4173491794890675\n",
      "epoch: 123\n",
      "epoch: 123 loss: 0.32055163236274514\n",
      "eval loss: 0.32045323735038644 0.4172491356941453\n",
      "epoch: 124\n",
      "epoch: 124 loss: 0.32077381495300317\n",
      "eval loss: 0.32086986204249457 0.4186442844978923\n",
      "epoch: 125\n",
      "epoch: 125 loss: 0.32019724320379706\n",
      "eval loss: 0.31984890246881936 0.4179723464401936\n",
      "epoch: 126\n",
      "epoch: 126 loss: 0.32020857142146647\n",
      "eval loss: 0.3211962544956165 0.41782206002760497\n",
      "epoch: 127\n",
      "epoch: 127 loss: 0.3203153519961184\n",
      "eval loss: 0.3202798807561915 0.41838976180914733\n",
      "epoch: 128\n",
      "epoch: 128 loss: 0.3205692216513074\n",
      "eval loss: 0.3198047991656258 0.41561022782284596\n",
      "epoch: 129\n",
      "epoch: 129 loss: 0.3198742149494284\n",
      "eval loss: 0.32154396974296506 0.4176884645605582\n",
      "epoch: 130\n",
      "epoch: 130 loss: 0.32214828949114505\n",
      "eval loss: 0.3238007876894132 0.4205235131021502\n",
      "epoch: 131\n",
      "epoch: 131 loss: 0.3211702844608788\n",
      "eval loss: 0.32405775344756044 0.4213678528603485\n",
      "epoch: 132\n",
      "epoch: 132 loss: 0.32198084197956456\n",
      "eval loss: 0.3286390570293297 0.42490918515073745\n",
      "epoch: 133\n",
      "epoch: 133 loss: 0.3214996863150872\n",
      "eval loss: 0.32073086731152434 0.41869596343796517\n",
      "epoch: 134\n",
      "epoch: 134 loss: 0.3214266918991183\n",
      "eval loss: 0.32264767745492595 0.4183798034634224\n",
      "epoch: 135\n",
      "epoch: 135 loss: 0.32048847525068674\n",
      "eval loss: 0.3200141247494984 0.416233316777121\n",
      "epoch: 136\n",
      "epoch: 136 loss: 0.3207762887059756\n",
      "eval loss: 0.3280511272550373 0.42555594432517546\n",
      "epoch: 137\n",
      "epoch: 137 loss: 0.3210383222767015\n",
      "eval loss: 0.3229312062578016 0.42048452457911156\n",
      "epoch: 138\n",
      "epoch: 138 loss: 0.32110932928524244\n",
      "eval loss: 0.32216990483493235 0.4181908483135986\n",
      "epoch: 139\n",
      "epoch: 139 loss: 0.32038858593343994\n",
      "eval loss: 0.32145506195318563 0.41698116900663823\n",
      "epoch: 140\n",
      "epoch: 140 loss: 0.32072835930857424\n",
      "eval loss: 0.321300034335832 0.41906500029400795\n",
      "epoch: 141\n",
      "epoch: 141 loss: 0.31972097814329736\n",
      "eval loss: 0.31873927266158264 0.4160278709472334\n",
      "epoch: 142\n",
      "epoch: 142 loss: 0.3205266590996595\n",
      "eval loss: 0.3192848679024497 0.41704072308897916\n",
      "epoch: 143\n",
      "epoch: 143 loss: 0.32100304161160187\n",
      "eval loss: 0.323720105273634 0.4205527652545406\n",
      "epoch: 144\n",
      "epoch: 144 loss: 0.32015801266997007\n",
      "eval loss: 0.32354424647347524 0.41915620918340857\n",
      "epoch: 145\n",
      "epoch: 145 loss: 0.319655530669673\n",
      "eval loss: 0.3177071144141562 0.4157306906756383\n",
      "epoch: 146\n",
      "epoch: 146 loss: 0.32010144574250077\n",
      "eval loss: 0.32463955199417477 0.41994009427358336\n",
      "epoch: 147\n",
      "epoch: 147 loss: 0.3199348869423018\n",
      "eval loss: 0.3195444627693089 0.41634153653723854\n",
      "epoch: 148\n",
      "epoch: 148 loss: 0.3207339371302333\n",
      "eval loss: 0.3222665344753093 0.4188300313605295\n",
      "epoch: 149\n",
      "epoch: 149 loss: 0.32103550297562217\n",
      "eval loss: 0.3214329816522421 0.41679841745528445\n",
      "epoch: 150\n",
      "epoch: 150 loss: 0.32185263391816193\n",
      "eval loss: 0.32053869322913087 0.4187205691357019\n",
      "epoch: 151\n",
      "epoch: 151 loss: 0.3204078528332893\n",
      "eval loss: 0.3217431091874996 0.42079865785770243\n",
      "epoch: 152\n",
      "epoch: 152 loss: 0.320184963156666\n",
      "eval loss: 0.3203970396664562 0.41826928756687176\n",
      "epoch: 153\n",
      "epoch: 153 loss: 0.32023967672236514\n",
      "eval loss: 0.31990469642821145 0.41580445373062275\n",
      "epoch: 154\n",
      "epoch: 154 loss: 0.3202435807422196\n",
      "eval loss: 0.31903586406455725 0.41582993299606164\n",
      "epoch: 155\n",
      "epoch: 155 loss: 0.32046713875835403\n",
      "eval loss: 0.3233364372369963 0.41933990217885125\n",
      "epoch: 156\n",
      "epoch: 156 loss: 0.3206960328902966\n",
      "eval loss: 0.32106660922173924 0.41754274069017683\n",
      "epoch: 157\n",
      "epoch: 157 loss: 0.3213497662807092\n",
      "eval loss: 0.32516046221022604 0.4200315902148418\n",
      "epoch: 158\n",
      "epoch: 158 loss: 0.3202195491325626\n",
      "eval loss: 0.3201626234649072 0.4173094824528983\n",
      "epoch: 159\n",
      "epoch: 159 loss: 0.3217818906361727\n",
      "eval loss: 0.3201430275897086 0.4185816843657715\n",
      "epoch: 160\n",
      "epoch: 160 loss: 0.31961698728446286\n",
      "eval loss: 0.32070124884373763 0.417657686534342\n",
      "epoch: 161\n",
      "epoch: 161 loss: 0.31991065054708157\n",
      "eval loss: 0.32124247553229424 0.41849921278834956\n",
      "epoch: 162\n",
      "epoch: 162 loss: 0.3201582954822091\n",
      "eval loss: 0.3212774722454407 0.41839683596057753\n",
      "epoch: 163\n",
      "epoch: 163 loss: 0.31994653325487643\n",
      "eval loss: 0.3216031776412297 0.41942598958646393\n",
      "epoch: 164\n",
      "epoch: 164 loss: 0.32082907771280944\n",
      "eval loss: 0.3224541763302016 0.4182614483635704\n",
      "epoch: 165\n",
      "epoch: 165 loss: 0.31997170089929394\n",
      "eval loss: 0.32152386784206005 0.4189905912325798\n",
      "epoch: 166\n",
      "epoch: 166 loss: 0.319926033880081\n",
      "eval loss: 0.32434106473732716 0.4232810857807979\n",
      "epoch: 167\n",
      "epoch: 167 loss: 0.3198256641158155\n",
      "eval loss: 0.3214948635526422 0.4176652965669907\n",
      "epoch: 168\n",
      "epoch: 168 loss: 0.32008727864297937\n",
      "eval loss: 0.3213152699902395 0.41760548482650467\n",
      "epoch: 169\n",
      "epoch: 169 loss: 0.3202601631296778\n",
      "eval loss: 0.3188755132126688 0.4167609411211134\n",
      "epoch: 170\n",
      "epoch: 170 loss: 0.3204825343608344\n",
      "eval loss: 0.3227171948844391 0.418936726154133\n",
      "epoch: 171\n",
      "epoch: 171 loss: 0.32097609499250646\n",
      "eval loss: 0.32027552796045045 0.41747961293093255\n",
      "epoch: 172\n",
      "epoch: 172 loss: 0.3201920490853998\n",
      "eval loss: 0.31879686036629495 0.41552833231273223\n",
      "epoch: 173\n",
      "epoch: 173 loss: 0.31942611440345914\n",
      "eval loss: 0.31983806287443783 0.41424671901352095\n",
      "epoch: 174\n",
      "epoch: 174 loss: 0.3195939560340517\n",
      "eval loss: 0.3220882957113032 0.4183568481581975\n",
      "epoch: 175\n",
      "epoch: 175 loss: 0.3192407740165983\n",
      "eval loss: 0.3205299570603585 0.4178478753011598\n",
      "epoch: 176\n",
      "epoch: 176 loss: 0.31933379450627236\n",
      "eval loss: 0.32155786358286315 0.4164249405595328\n",
      "epoch: 177\n",
      "epoch: 177 loss: 0.3203059127657872\n",
      "eval loss: 0.3190213628102293 0.41608742766957485\n",
      "epoch: 178\n",
      "epoch: 178 loss: 0.3199118269964365\n",
      "eval loss: 0.32111340176763054 0.41743398034542767\n",
      "epoch: 179\n",
      "epoch: 179 loss: 0.31993021946674344\n",
      "eval loss: 0.3200041377535905 0.41564470324109837\n",
      "epoch: 180\n",
      "epoch: 180 loss: 0.32000256676484184\n",
      "eval loss: 0.32451293980412277 0.4200507694490734\n",
      "epoch: 181\n",
      "epoch: 181 loss: 0.3206243644060129\n",
      "eval loss: 0.31988420080340385 0.41588312102850394\n",
      "epoch: 182\n",
      "epoch: 182 loss: 0.3198558796234053\n",
      "eval loss: 0.31898631804895244 0.41630056127543413\n",
      "epoch: 183\n",
      "epoch: 183 loss: 0.3200946823594586\n",
      "eval loss: 0.3193102635852667 0.4162349893887653\n",
      "epoch: 184\n",
      "epoch: 184 loss: 0.3195936562618707\n",
      "eval loss: 0.32133784452230946 0.421804991936503\n",
      "epoch: 185\n",
      "epoch: 185 loss: 0.32050600037969\n",
      "eval loss: 0.3192031060517488 0.41493863640425604\n",
      "epoch: 186\n",
      "epoch: 186 loss: 0.31970211682730953\n",
      "eval loss: 0.3229394623847816 0.4201469749206135\n",
      "epoch: 187\n",
      "epoch: 187 loss: 0.3199286312186059\n",
      "eval loss: 0.33005648902066015 0.43211444063609417\n",
      "epoch: 188\n",
      "epoch: 188 loss: 0.32256638138369714\n",
      "eval loss: 0.3205561368122379 0.41709768294943284\n",
      "epoch: 189\n",
      "epoch: 189 loss: 0.3195085269293993\n",
      "eval loss: 0.31907902776929475 0.4174704843793453\n",
      "epoch: 190\n",
      "epoch: 190 loss: 0.319763582835025\n",
      "eval loss: 0.32092707539757015 0.4161258395079709\n",
      "epoch: 191\n",
      "epoch: 191 loss: 0.32035611143050624\n",
      "eval loss: 0.320120643349871 0.41594812958526045\n",
      "epoch: 192\n",
      "epoch: 192 loss: 0.31959847582174733\n",
      "eval loss: 0.32359975943900593 0.4192393888084875\n",
      "epoch: 193\n",
      "epoch: 193 loss: 0.3208687953818263\n",
      "eval loss: 0.3232887814493533 0.42169842149638437\n",
      "epoch: 194\n",
      "epoch: 194 loss: 0.31978928507690435\n",
      "eval loss: 0.3209590812003882 0.41741404890318734\n",
      "epoch: 195\n",
      "epoch: 195 loss: 0.3195418230181981\n",
      "eval loss: 0.32148207458205413 0.4170206017034591\n",
      "epoch: 196\n",
      "epoch: 196 loss: 0.3201536429665736\n",
      "eval loss: 0.3255953724139358 0.42730524640677514\n",
      "epoch: 197\n",
      "epoch: 197 loss: 0.32181770590321274\n",
      "eval loss: 0.3205345034713829 0.4161698027395875\n",
      "epoch: 198\n",
      "epoch: 198 loss: 0.319863262803895\n",
      "eval loss: 0.3153999707134567 0.41259808810118703\n",
      "epoch: 199\n",
      "epoch: 199 loss: 0.31760074381761394\n",
      "eval loss: 0.31811620481544256 0.4131692528023031\n",
      "min eval loss: 0.15756327340730714 epoch 100\n",
      "fold: 3\n",
      "(1, 107, 107, 3)\n",
      "(1, 107, 107, 3)\n",
      "(2160, 21) (240, 21)\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='200' class='' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [200/200 31:58<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 0 loss: 0.3186809025693589\n",
      "eval loss: 0.25563235724675304 0.3399906603882233\n",
      "epoch: 1\n",
      "epoch: 1 loss: 0.24899763956752352\n",
      "eval loss: 0.23960901906615845 0.3187164446209102\n",
      "epoch: 2\n",
      "epoch: 2 loss: 0.23725210784761977\n",
      "eval loss: 0.22782554517314005 0.3060724300978687\n",
      "epoch: 3\n",
      "epoch: 3 loss: 0.2280039469471788\n",
      "eval loss: 0.22402556164129198 0.29897488948755346\n",
      "epoch: 4\n",
      "epoch: 4 loss: 0.2219356172351873\n",
      "eval loss: 0.21529204190886836 0.28812408690873914\n",
      "epoch: 5\n",
      "epoch: 5 loss: 0.21485844938403972\n",
      "eval loss: 0.20949259841245368 0.2803030939191537\n",
      "epoch: 6\n",
      "epoch: 6 loss: 0.20978094146979998\n",
      "eval loss: 0.20069114980166766 0.26588142780823376\n",
      "epoch: 7\n",
      "epoch: 7 loss: 0.20331028027014117\n",
      "eval loss: 0.2012952400990188 0.26772442443195804\n",
      "epoch: 8\n",
      "epoch: 8 loss: 0.19928223644912044\n",
      "eval loss: 0.19163303600678386 0.25541079577110554\n",
      "epoch: 9\n",
      "epoch: 9 loss: 0.19463957058702935\n",
      "eval loss: 0.19049495265234442 0.25396827632023566\n",
      "epoch: 10\n",
      "epoch: 10 loss: 0.19165836872160996\n",
      "eval loss: 0.18622481877511735 0.24583196672463326\n",
      "epoch: 11\n",
      "epoch: 11 loss: 0.18722858465566872\n",
      "eval loss: 0.17938083571690344 0.2376404130888909\n",
      "epoch: 12\n",
      "epoch: 12 loss: 0.1838282761518604\n",
      "eval loss: 0.1794884453073226 0.24070249267236468\n",
      "epoch: 13\n",
      "epoch: 13 loss: 0.18181870814682052\n",
      "eval loss: 0.17758758014149165 0.23513475730882832\n",
      "epoch: 14\n",
      "epoch: 14 loss: 0.17864110343371595\n",
      "eval loss: 0.17459735917185001 0.23118280016915244\n",
      "epoch: 15\n",
      "epoch: 15 loss: 0.17568478701665025\n",
      "eval loss: 0.17312434103018398 0.22858636196117565\n",
      "epoch: 16\n",
      "epoch: 16 loss: 0.17483014987802914\n",
      "eval loss: 0.17077880671915646 0.2260832813013095\n",
      "epoch: 17\n",
      "epoch: 17 loss: 0.17226683314244046\n",
      "eval loss: 0.16988996755447064 0.22564083905254778\n",
      "epoch: 18\n",
      "epoch: 18 loss: 0.17073186564691048\n",
      "eval loss: 0.16905086519896517 0.22396291814775648\n",
      "epoch: 19\n",
      "epoch: 19 loss: 0.16842377367733083\n",
      "eval loss: 0.1716926265280641 0.22688298585103384\n",
      "epoch: 20\n",
      "epoch: 20 loss: 0.16670395594459653\n",
      "eval loss: 0.16792259954697186 0.2230122503205744\n",
      "epoch: 21\n",
      "epoch: 21 loss: 0.1657506758605543\n",
      "eval loss: 0.16815472588583377 0.2228902283826309\n",
      "epoch: 22\n",
      "epoch: 22 loss: 0.16395309594258736\n",
      "eval loss: 0.16588404321678504 0.22034117678771142\n",
      "epoch: 23\n",
      "epoch: 23 loss: 0.16277907027048658\n",
      "eval loss: 0.1655109272647948 0.21946139634201794\n",
      "epoch: 24\n",
      "epoch: 24 loss: 0.16173303446155696\n",
      "eval loss: 0.16569645232474675 0.2222762943515383\n",
      "epoch: 25\n",
      "epoch: 25 loss: 0.16007372258127167\n",
      "eval loss: 0.1655702375691971 0.21968139415091947\n",
      "epoch: 26\n",
      "epoch: 26 loss: 0.15875672524828782\n",
      "eval loss: 0.16308072588676492 0.21787553364962847\n",
      "epoch: 27\n",
      "epoch: 27 loss: 0.15697415629969508\n",
      "eval loss: 0.16310020645916767 0.21678831514691577\n",
      "epoch: 28\n",
      "epoch: 28 loss: 0.15758333760119222\n",
      "eval loss: 0.16419091980324166 0.21808730317394773\n",
      "epoch: 29\n",
      "epoch: 29 loss: 0.1551796642776726\n",
      "eval loss: 0.16060980290596052 0.2139077465133207\n",
      "epoch: 30\n",
      "epoch: 30 loss: 0.15543411035283838\n",
      "eval loss: 0.16047684697592415 0.21406979813196636\n",
      "epoch: 31\n",
      "epoch: 31 loss: 0.1540021405376354\n",
      "eval loss: 0.1615548278511431 0.2156049492673605\n",
      "epoch: 32\n",
      "epoch: 32 loss: 0.15406583645045432\n",
      "eval loss: 0.16375597114023452 0.21617873034720986\n",
      "epoch: 33\n",
      "epoch: 33 loss: 0.15066695215372208\n",
      "eval loss: 0.16001406718895797 0.2131426591591682\n",
      "epoch: 34\n",
      "epoch: 34 loss: 0.15089402954511258\n",
      "eval loss: 0.1606217423394815 0.2118621367509879\n",
      "epoch: 35\n",
      "epoch: 35 loss: 0.15030726935412828\n",
      "eval loss: 0.16059311713504348 0.21391632135628105\n",
      "epoch: 36\n",
      "epoch: 36 loss: 0.1496298703016232\n",
      "eval loss: 0.1614477395426128 0.215808136425667\n",
      "epoch: 37\n",
      "epoch: 37 loss: 0.14788420967575916\n",
      "eval loss: 0.15714074001936554 0.20843479549753471\n",
      "epoch: 38\n",
      "epoch: 38 loss: 0.1470863044309621\n",
      "eval loss: 0.15761480623022575 0.20917982801304907\n",
      "epoch: 39\n",
      "epoch: 39 loss: 0.1466147345126427\n",
      "eval loss: 0.16061291828812854 0.21323862061258064\n",
      "epoch: 40\n",
      "epoch: 40 loss: 0.14504394982300736\n",
      "eval loss: 0.15906838070933146 0.21118187098999885\n",
      "epoch: 41\n",
      "epoch: 41 loss: 0.14389998655406053\n",
      "eval loss: 0.15573220439687505 0.20664153917391065\n",
      "epoch: 42\n",
      "epoch: 42 loss: 0.14528796878198497\n",
      "eval loss: 0.1586911882449312 0.21332140055191787\n",
      "epoch: 43\n",
      "epoch: 43 loss: 0.14310309081856273\n",
      "eval loss: 0.15720650109261283 0.20897184467810553\n",
      "epoch: 44\n",
      "epoch: 44 loss: 0.14480346972493327\n",
      "eval loss: 0.15950556057865256 0.21163778309948852\n",
      "epoch: 45\n",
      "epoch: 45 loss: 0.1424603090456035\n",
      "eval loss: 0.15902149535087762 0.21019600733382965\n",
      "epoch: 46\n",
      "epoch: 46 loss: 0.14187046978502726\n",
      "eval loss: 0.1564381548986496 0.2075501876673632\n",
      "epoch: 47\n",
      "epoch: 47 loss: 0.14130223198328143\n",
      "eval loss: 0.15638137523896045 0.20725465640893959\n",
      "epoch: 48\n",
      "epoch: 48 loss: 0.140018784942639\n",
      "eval loss: 0.15809980595492862 0.20988470443004426\n",
      "epoch: 49\n",
      "epoch: 49 loss: 0.13913256185151585\n",
      "eval loss: 0.15586724043950625 0.20817080449182918\n",
      "epoch: 50\n",
      "epoch: 50 loss: 0.13875605794994164\n",
      "eval loss: 0.15676311400016274 0.2089855568947255\n",
      "epoch: 51\n",
      "epoch: 51 loss: 0.1381479468671037\n",
      "eval loss: 0.1543358976221206 0.20530889484327255\n",
      "epoch: 52\n",
      "epoch: 52 loss: 0.1389169599248536\n",
      "eval loss: 0.1614810332836012 0.21240403481528014\n",
      "epoch: 53\n",
      "epoch: 53 loss: 0.13759956028036394\n",
      "eval loss: 0.15529902765488451 0.2057114201215469\n",
      "epoch: 54\n",
      "epoch: 54 loss: 0.13632742849623136\n",
      "eval loss: 0.1564472193357775 0.20757160887256296\n",
      "epoch: 55\n",
      "epoch: 55 loss: 0.13637456712932147\n",
      "eval loss: 0.15358753217644686 0.20433349079991175\n",
      "epoch: 56\n",
      "epoch: 56 loss: 0.13648602270749172\n",
      "eval loss: 0.15560661433048767 0.2070817308487378\n",
      "epoch: 57\n",
      "epoch: 57 loss: 0.1344616975927184\n",
      "eval loss: 0.15493053422828812 0.2053842117683648\n",
      "epoch: 58\n",
      "epoch: 58 loss: 0.13462131267171473\n",
      "eval loss: 0.15321487327729277 0.20406189835651958\n",
      "epoch: 59\n",
      "epoch: 59 loss: 0.13289063197306691\n",
      "eval loss: 0.15700038532832977 0.2084353107803321\n",
      "epoch: 60\n",
      "epoch: 60 loss: 0.1320909247856514\n",
      "eval loss: 0.1518776216486672 0.20177225572338237\n",
      "epoch: 61\n",
      "epoch: 61 loss: 0.13293679764252234\n",
      "eval loss: 0.15325281772163013 0.2037750585846053\n",
      "epoch: 62\n",
      "epoch: 62 loss: 0.13270381370767012\n",
      "eval loss: 0.15970732069209462 0.21191728583649339\n",
      "epoch: 63\n",
      "epoch: 63 loss: 0.13353070350254748\n",
      "eval loss: 0.15532735799040243 0.2067270948287694\n",
      "epoch: 64\n",
      "epoch: 64 loss: 0.13116586794345925\n",
      "eval loss: 0.15178673984739216 0.2022811603643882\n",
      "epoch: 65\n",
      "epoch: 65 loss: 0.13024077945897272\n",
      "eval loss: 0.1514370307458497 0.20053226081212122\n",
      "epoch: 66\n",
      "epoch: 66 loss: 0.130120198186072\n",
      "eval loss: 0.1532068301227939 0.20213313187621104\n",
      "epoch: 67\n",
      "epoch: 67 loss: 0.13052681694146434\n",
      "eval loss: 0.15414673316562227 0.20615160622363077\n",
      "epoch: 68\n",
      "epoch: 68 loss: 0.13050239118011278\n",
      "eval loss: 0.15664461074593647 0.20702295391537887\n",
      "epoch: 69\n",
      "epoch: 69 loss: 0.12983206096426128\n",
      "eval loss: 0.15313082202046335 0.20281351832224684\n",
      "epoch: 70\n",
      "epoch: 70 loss: 0.12786845595199475\n",
      "eval loss: 0.15365014971643448 0.2056072749290848\n",
      "epoch: 71\n",
      "epoch: 71 loss: 0.12841848620874424\n",
      "eval loss: 0.1512226316004796 0.20125896131756765\n",
      "epoch: 72\n",
      "epoch: 72 loss: 0.12777906198749459\n",
      "eval loss: 0.1521665564774593 0.2034689095988199\n",
      "epoch: 73\n",
      "epoch: 73 loss: 0.12795128305903802\n",
      "eval loss: 0.15776977056035732 0.21011558680422254\n",
      "epoch: 74\n",
      "epoch: 74 loss: 0.12792041526845788\n",
      "eval loss: 0.15385293056615104 0.20650963811345352\n",
      "epoch: 75\n",
      "epoch: 75 loss: 0.12657035541224435\n",
      "eval loss: 0.15290931780522177 0.20589601918782574\n",
      "epoch: 76\n",
      "epoch: 76 loss: 0.12532999422176327\n",
      "eval loss: 0.1530535437293991 0.20351428780461753\n",
      "epoch: 77\n",
      "epoch: 77 loss: 0.12592537420296487\n",
      "eval loss: 0.15320041281841276 0.20274997965027408\n",
      "epoch: 78\n",
      "epoch: 78 loss: 0.12460845601939514\n",
      "eval loss: 0.15346874316855438 0.2036857625766867\n",
      "epoch: 79\n",
      "epoch: 79 loss: 0.12424907306959432\n",
      "eval loss: 0.1511819569219739 0.19927631363171622\n",
      "epoch: 80\n",
      "epoch: 80 loss: 0.1247897483823136\n",
      "eval loss: 0.15391520985782553 0.2038026843516578\n",
      "epoch: 81\n",
      "epoch: 81 loss: 0.12398009184757217\n",
      "eval loss: 0.15185805690721596 0.2015977361393681\n",
      "epoch: 82\n",
      "epoch: 82 loss: 0.12371634785526468\n",
      "eval loss: 0.15110104312590353 0.20156894299965294\n",
      "epoch: 83\n",
      "epoch: 83 loss: 0.1245046902375867\n",
      "eval loss: 0.15211534568341178 0.20256671931470707\n",
      "epoch: 84\n",
      "epoch: 84 loss: 0.1235221426848648\n",
      "eval loss: 0.15278146065347875 0.20366650858115024\n",
      "epoch: 85\n",
      "epoch: 85 loss: 0.12284909454170284\n",
      "eval loss: 0.15207545337695932 0.20132259702339023\n",
      "epoch: 86\n",
      "epoch: 86 loss: 0.12171988939813373\n",
      "eval loss: 0.15354108926884422 0.203417023333827\n",
      "epoch: 87\n",
      "epoch: 87 loss: 0.12135724858652344\n",
      "eval loss: 0.15190245521235737 0.2013636604253966\n",
      "epoch: 88\n",
      "epoch: 88 loss: 0.122114346228623\n",
      "eval loss: 0.15247692341522362 0.20202525797706897\n",
      "epoch: 89\n",
      "epoch: 89 loss: 0.1221234797273279\n",
      "eval loss: 0.15206478778114585 0.20231024745778547\n",
      "epoch: 90\n",
      "epoch: 90 loss: 0.12052771652142083\n",
      "eval loss: 0.15236322776352762 0.20188205577020496\n",
      "epoch: 91\n",
      "epoch: 91 loss: 0.12112278091283037\n",
      "eval loss: 0.1502488441942759 0.19956234865873584\n",
      "epoch: 92\n",
      "epoch: 92 loss: 0.12033580589134259\n",
      "eval loss: 0.15106788777156446 0.2010148908780294\n",
      "epoch: 93\n",
      "epoch: 93 loss: 0.12026034961772224\n",
      "eval loss: 0.1508269537569468 0.19933711408528793\n",
      "epoch: 94\n",
      "epoch: 94 loss: 0.1205840541845298\n",
      "eval loss: 0.14963455821247218 0.20056093200710579\n",
      "epoch: 95\n",
      "epoch: 95 loss: 0.1195339839237137\n",
      "eval loss: 0.15216164256458542 0.20244922508208113\n",
      "epoch: 96\n",
      "epoch: 96 loss: 0.11944478996845037\n",
      "eval loss: 0.15132699079164785 0.2016455322305198\n",
      "epoch: 97\n",
      "epoch: 97 loss: 0.11876433112718213\n",
      "eval loss: 0.1516547699266495 0.20175050781241236\n",
      "epoch: 98\n",
      "epoch: 98 loss: 0.11839826243492582\n",
      "eval loss: 0.15293643818860392 0.20582278827620418\n",
      "epoch: 99\n",
      "epoch: 99 loss: 0.11841314682978418\n",
      "eval loss: 0.15044135993886346 0.20093706384455134\n",
      "epoch: 100\n",
      "epoch: 100 loss: 0.11832192810231004\n",
      "eval loss: 0.1524804220546901 0.20357751919632036\n",
      "epoch: 101\n",
      "epoch: 101 loss: 0.11778960755729144\n",
      "eval loss: 0.15177598578587936 0.20206596162555154\n",
      "epoch: 102\n",
      "epoch: 102 loss: 0.11672578726810831\n",
      "eval loss: 0.1528023914715062 0.20397986387467515\n",
      "epoch: 103\n",
      "epoch: 103 loss: 0.11655222942509252\n",
      "eval loss: 0.15059484790352157 0.19916873998863074\n",
      "epoch: 104\n",
      "epoch: 104 loss: 0.11861826081598074\n",
      "eval loss: 0.15283419557473515 0.20288687648329018\n",
      "epoch: 105\n",
      "epoch: 105 loss: 0.11610845863490737\n",
      "eval loss: 0.15020899763415288 0.19972769970699686\n",
      "epoch: 106\n",
      "epoch: 106 loss: 0.11544669118810627\n",
      "eval loss: 0.15249886927737877 0.2025298819805909\n",
      "epoch: 107\n",
      "epoch: 107 loss: 0.11840240906413768\n",
      "eval loss: 0.15206029106963467 0.20260389707881266\n",
      "epoch: 108\n",
      "epoch: 108 loss: 0.11680107630126078\n",
      "eval loss: 0.15228356541748458 0.20213948107682142\n",
      "epoch: 109\n",
      "epoch: 109 loss: 0.11658658933719244\n",
      "eval loss: 0.1507172817871868 0.2014365528830796\n",
      "epoch: 110\n",
      "epoch: 110 loss: 0.11477234092621746\n",
      "eval loss: 0.1511076996631463 0.20022167984331707\n",
      "epoch: 111\n",
      "epoch: 111 loss: 0.11442872480982048\n",
      "eval loss: 0.15310623969034448 0.2038488514660391\n",
      "epoch: 112\n",
      "epoch: 112 loss: 0.11467739719395437\n",
      "eval loss: 0.15280138126770065 0.2019199986291406\n",
      "epoch: 113\n",
      "epoch: 113 loss: 0.11398475702119412\n",
      "eval loss: 0.1501736404283551 0.20008581103322162\n",
      "epoch: 114\n",
      "epoch: 114 loss: 0.11360483126139273\n",
      "eval loss: 0.14956171378471525 0.19935115652250768\n",
      "epoch: 115\n",
      "epoch: 115 loss: 0.11370437547865306\n",
      "eval loss: 0.1495763961332508 0.1984929618764174\n",
      "epoch: 116\n",
      "epoch: 116 loss: 0.11465846887171709\n",
      "eval loss: 0.1504926883566321 0.2000411874488378\n",
      "epoch: 117\n",
      "epoch: 117 loss: 0.11339666778587044\n",
      "eval loss: 0.15125269978378697 0.2004175062028105\n",
      "epoch: 118\n",
      "epoch: 118 loss: 0.11304212051452232\n",
      "eval loss: 0.1535860659138663 0.20236292995889055\n",
      "epoch: 119\n",
      "epoch: 119 loss: 0.11351783796427044\n",
      "eval loss: 0.14985953542920455 0.19921086506147534\n",
      "epoch: 120\n",
      "epoch: 120 loss: 0.11384081416918237\n",
      "eval loss: 0.15197605148219334 0.20141510095284695\n",
      "epoch: 121\n",
      "epoch: 121 loss: 0.11226019558148008\n",
      "eval loss: 0.15095716915737334 0.19999847552029018\n",
      "epoch: 122\n",
      "epoch: 122 loss: 0.11229107502973733\n",
      "eval loss: 0.15112316306721124 0.20048654183002648\n",
      "epoch: 123\n",
      "epoch: 123 loss: 0.11212849213037121\n",
      "eval loss: 0.14972093357367178 0.1989774618857154\n",
      "epoch: 124\n",
      "epoch: 124 loss: 0.11141155928146496\n",
      "eval loss: 0.1527347921866647 0.20222803140736734\n",
      "epoch: 125\n",
      "epoch: 125 loss: 0.11258386948451794\n",
      "eval loss: 0.15087789849177188 0.20062395219053583\n",
      "epoch: 126\n",
      "epoch: 126 loss: 0.1105721829722955\n",
      "eval loss: 0.15206527968768632 0.20298853725221777\n",
      "epoch: 127\n",
      "epoch: 127 loss: 0.11138733972275476\n",
      "eval loss: 0.15260661832170813 0.2019675415901112\n",
      "epoch: 128\n",
      "epoch: 128 loss: 0.11148187191868171\n",
      "eval loss: 0.15123415951356967 0.20029955652465706\n",
      "epoch: 129\n",
      "epoch: 129 loss: 0.11045262216805753\n",
      "eval loss: 0.15076785901096956 0.2001574945273697\n",
      "epoch: 130\n",
      "epoch: 130 loss: 0.11048964850883304\n",
      "eval loss: 0.15438364279479144 0.2050531987056657\n",
      "epoch: 131\n",
      "epoch: 131 loss: 0.11155001259918455\n",
      "eval loss: 0.15110903177170848 0.19979483383958724\n",
      "epoch: 132\n",
      "epoch: 132 loss: 0.1095687714306553\n",
      "eval loss: 0.1507708601665241 0.20153376929630706\n",
      "epoch: 133\n",
      "epoch: 133 loss: 0.10933940793305044\n",
      "eval loss: 0.14983574578156836 0.19932755069890035\n",
      "epoch: 134\n",
      "epoch: 134 loss: 0.10919644704205808\n",
      "eval loss: 0.15114899353236233 0.20161916045860445\n",
      "epoch: 135\n",
      "epoch: 135 loss: 0.10974732689859179\n",
      "eval loss: 0.15124911952058537 0.20190298779789637\n",
      "epoch: 136\n",
      "epoch: 136 loss: 0.10926527514411216\n",
      "eval loss: 0.15151495332341114 0.20144994575727607\n",
      "epoch: 137\n",
      "epoch: 137 loss: 0.10842999737705743\n",
      "eval loss: 0.15027610187400892 0.2002044589966201\n",
      "epoch: 138\n",
      "epoch: 138 loss: 0.10791734549603231\n",
      "eval loss: 0.151011417043199 0.1999160737811022\n",
      "epoch: 139\n",
      "epoch: 139 loss: 0.10790180383815443\n",
      "eval loss: 0.15015693977925146 0.20025850712225257\n",
      "epoch: 140\n",
      "epoch: 140 loss: 0.10824290953361296\n",
      "eval loss: 0.1507715373613137 0.1999723946209067\n",
      "epoch: 141\n",
      "epoch: 141 loss: 0.10830475694603132\n",
      "eval loss: 0.1531472383738487 0.20281123656707872\n",
      "epoch: 142\n",
      "epoch: 142 loss: 0.10738248014813444\n",
      "eval loss: 0.15227646881325235 0.2041168716671649\n",
      "epoch: 143\n",
      "epoch: 143 loss: 0.10751442695442674\n",
      "eval loss: 0.1518125683671716 0.2027768305580766\n",
      "epoch: 144\n",
      "epoch: 144 loss: 0.10708982009152052\n",
      "eval loss: 0.14957845503879097 0.19837323538092128\n",
      "epoch: 145\n",
      "epoch: 145 loss: 0.10767332240228818\n",
      "eval loss: 0.15309859300909262 0.20140103781956248\n",
      "epoch: 146\n",
      "epoch: 146 loss: 0.10745339806499894\n",
      "eval loss: 0.15225653047338272 0.20301805595313116\n",
      "epoch: 147\n",
      "epoch: 147 loss: 0.10715425616167358\n",
      "eval loss: 0.15075343292097887 0.20022708989668128\n",
      "epoch: 148\n",
      "epoch: 148 loss: 0.10672688977983341\n",
      "eval loss: 0.1504469692438836 0.2008228501542409\n",
      "epoch: 149\n",
      "epoch: 149 loss: 0.10689297495524178\n",
      "eval loss: 0.15177609896955382 0.2016618263983564\n",
      "epoch: 150\n",
      "epoch: 150 loss: 0.10665221050714027\n",
      "eval loss: 0.15300834572117705 0.20246560510749143\n",
      "epoch: 151\n",
      "epoch: 151 loss: 0.10677187475512713\n",
      "eval loss: 0.15149286956971006 0.20189688017962754\n",
      "epoch: 152\n",
      "epoch: 152 loss: 0.10609980564699317\n",
      "eval loss: 0.15107074041922047 0.20219686019952635\n",
      "epoch: 153\n",
      "epoch: 153 loss: 0.10630281730314729\n",
      "eval loss: 0.15147851338703067 0.20176403819708438\n",
      "epoch: 154\n",
      "epoch: 154 loss: 0.10626554835107135\n",
      "eval loss: 0.1524563708691297 0.20326130635195294\n",
      "epoch: 155\n",
      "epoch: 155 loss: 0.10645446980920614\n",
      "eval loss: 0.15137243086125401 0.1999894199104787\n",
      "epoch: 156\n",
      "epoch: 156 loss: 0.10505844695829229\n",
      "eval loss: 0.15280211154659226 0.20209475628149756\n",
      "epoch: 157\n",
      "epoch: 157 loss: 0.10523216533442659\n",
      "eval loss: 0.15347284071886652 0.20419648360702614\n",
      "epoch: 158\n",
      "epoch: 158 loss: 0.10555521434853074\n",
      "eval loss: 0.15504524126181418 0.2047602797203529\n",
      "epoch: 159\n",
      "epoch: 159 loss: 0.10470459930483408\n",
      "eval loss: 0.14938629921173685 0.1981990708005198\n",
      "epoch: 160\n",
      "epoch: 160 loss: 0.10436504198202547\n",
      "eval loss: 0.15148214948619682 0.2014736301212603\n",
      "epoch: 161\n",
      "epoch: 161 loss: 0.10529002408256548\n",
      "eval loss: 0.1493555178600404 0.1990055691161895\n",
      "epoch: 162\n",
      "epoch: 162 loss: 0.1037837880826153\n",
      "eval loss: 0.1523601180415719 0.202656013521071\n",
      "epoch: 163\n",
      "epoch: 163 loss: 0.1049911587829335\n",
      "eval loss: 0.1513875258661651 0.19994094572569857\n",
      "epoch: 164\n",
      "epoch: 164 loss: 0.10492517482011786\n",
      "eval loss: 0.1509658214805911 0.1986742227526423\n",
      "epoch: 165\n",
      "epoch: 165 loss: 0.10507550756988165\n",
      "eval loss: 0.1519812603737772 0.2021936522247769\n",
      "epoch: 166\n",
      "epoch: 166 loss: 0.10402502753752249\n",
      "eval loss: 0.15234218290697915 0.20257531133735646\n",
      "epoch: 167\n",
      "epoch: 167 loss: 0.10347071184853596\n",
      "eval loss: 0.15246827541284652 0.20280281492350394\n",
      "epoch: 168\n",
      "epoch: 168 loss: 0.10318096960603759\n",
      "eval loss: 0.15154224908421454 0.20047993179223636\n",
      "epoch: 169\n",
      "epoch: 169 loss: 0.10312471965889602\n",
      "eval loss: 0.15069578408997666 0.2007703794155974\n",
      "epoch: 170\n",
      "epoch: 170 loss: 0.10279703901844929\n",
      "eval loss: 0.1544758805328661 0.20580438843564602\n",
      "epoch: 171\n",
      "epoch: 171 loss: 0.1039298310942722\n",
      "eval loss: 0.15312473313143746 0.20361606879569155\n",
      "epoch: 172\n",
      "epoch: 172 loss: 0.10295501160646672\n",
      "eval loss: 0.15007629127110877 0.1998688442708112\n",
      "epoch: 173\n",
      "epoch: 173 loss: 0.1021224201151565\n",
      "eval loss: 0.15082532077100283 0.200402606717855\n",
      "epoch: 174\n",
      "epoch: 174 loss: 0.1023240786764172\n",
      "eval loss: 0.14990481553449214 0.1996477636019593\n",
      "epoch: 175\n",
      "epoch: 175 loss: 0.1027891252641076\n",
      "eval loss: 0.15033702542076485 0.19927703858198312\n",
      "epoch: 176\n",
      "epoch: 176 loss: 0.10258082344806295\n",
      "eval loss: 0.15278611183291083 0.2022858265257824\n",
      "epoch: 177\n",
      "epoch: 177 loss: 0.10250359043966704\n",
      "eval loss: 0.1511721858529154 0.20113466645687617\n",
      "epoch: 178\n",
      "epoch: 178 loss: 0.10266216325722684\n",
      "eval loss: 0.1505753774964298 0.20029002768256224\n",
      "epoch: 179\n",
      "epoch: 179 loss: 0.10156914064567389\n",
      "eval loss: 0.15061341951980742 0.1994111712377964\n",
      "epoch: 180\n",
      "epoch: 180 loss: 0.10198298882014988\n",
      "eval loss: 0.1504669179300864 0.2003467653001324\n",
      "epoch: 181\n",
      "epoch: 181 loss: 0.10447217977070528\n",
      "eval loss: 0.1534295870817335 0.20392652800963107\n",
      "epoch: 182\n",
      "epoch: 182 loss: 0.10204851632765814\n",
      "eval loss: 0.15118802167494258 0.20068904864726386\n",
      "epoch: 183\n",
      "epoch: 183 loss: 0.10078934135381315\n",
      "eval loss: 0.15302447535507974 0.20250632096546753\n",
      "epoch: 184\n",
      "epoch: 184 loss: 0.10094053549775288\n",
      "eval loss: 0.15292176303249005 0.20241646326910645\n",
      "epoch: 185\n",
      "epoch: 185 loss: 0.10108942194477272\n",
      "eval loss: 0.15228562942533924 0.2027902153117164\n",
      "epoch: 186\n",
      "epoch: 186 loss: 0.10134010639317227\n",
      "eval loss: 0.15089294455033023 0.20099933023123834\n",
      "epoch: 187\n",
      "epoch: 187 loss: 0.10117289159158378\n",
      "eval loss: 0.15166099799516844 0.20306381863650494\n",
      "epoch: 188\n",
      "epoch: 188 loss: 0.10099130802772338\n",
      "eval loss: 0.15170607806222328 0.20183533411456644\n",
      "epoch: 189\n",
      "epoch: 189 loss: 0.09999262985317393\n",
      "eval loss: 0.15166047393307414 0.201536515650929\n",
      "epoch: 190\n",
      "epoch: 190 loss: 0.10097874725388944\n",
      "eval loss: 0.15299316042813954 0.20250016393844136\n",
      "epoch: 191\n",
      "epoch: 191 loss: 0.09979828801336439\n",
      "eval loss: 0.15302304260585334 0.2028094031901928\n",
      "epoch: 192\n",
      "epoch: 192 loss: 0.09941685396644555\n",
      "eval loss: 0.15090628627680092 0.19983137638792903\n",
      "epoch: 193\n",
      "epoch: 193 loss: 0.1002738989074585\n",
      "eval loss: 0.1517439932344569 0.20191456419334422\n",
      "epoch: 194\n",
      "epoch: 194 loss: 0.099006736149738\n",
      "eval loss: 0.1502310951810557 0.19942710712532427\n",
      "epoch: 195\n",
      "epoch: 195 loss: 0.09887907003950155\n",
      "eval loss: 0.1507992747479121 0.20001355410241467\n",
      "epoch: 196\n",
      "epoch: 196 loss: 0.09918552421897667\n",
      "eval loss: 0.15210023724579252 0.20064958356747922\n",
      "epoch: 197\n",
      "epoch: 197 loss: 0.09923430721962617\n",
      "eval loss: 0.1507260638477697 0.20116078211804456\n",
      "epoch: 198\n",
      "epoch: 198 loss: 0.09946169676335657\n",
      "eval loss: 0.15210322880341004 0.20152257522124797\n",
      "epoch: 199\n",
      "epoch: 199 loss: 0.09889330312006674\n",
      "eval loss: 0.1508857589277561 0.20002995183488498\n",
      "min eval loss: 0.1493555178600404 epoch 161\n",
      "fold: 4\n",
      "(1, 107, 107, 3)\n",
      "(1, 107, 107, 3)\n",
      "(2160, 21) (240, 21)\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='200' class='' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [200/200 32:09<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 0 loss: 0.3157238678187507\n",
      "eval loss: 0.2576153657947001 0.3377577131036481\n",
      "epoch: 1\n",
      "epoch: 1 loss: 0.2510768992136239\n",
      "eval loss: 0.23742329748919697 0.31270889240037714\n",
      "epoch: 2\n",
      "epoch: 2 loss: 0.2354397550483699\n",
      "eval loss: 0.2237385127435247 0.2941019187947601\n",
      "epoch: 3\n",
      "epoch: 3 loss: 0.22595574882957037\n",
      "eval loss: 0.22098277221921564 0.29030401049185484\n",
      "epoch: 4\n",
      "epoch: 4 loss: 0.22111148596798813\n",
      "eval loss: 0.20982624987443171 0.27757058014932456\n",
      "epoch: 5\n",
      "epoch: 5 loss: 0.21669163576967546\n",
      "eval loss: 0.21468091751586418 0.2835393538647315\n",
      "epoch: 6\n",
      "epoch: 6 loss: 0.20829267447481287\n",
      "eval loss: 0.20231908177986577 0.26724127604386033\n",
      "epoch: 7\n",
      "epoch: 7 loss: 0.20387064700707458\n",
      "eval loss: 0.19776693690683575 0.26190377329539777\n",
      "epoch: 8\n",
      "epoch: 8 loss: 0.19937918403364366\n",
      "eval loss: 0.19228317236222317 0.2563478537488796\n",
      "epoch: 9\n",
      "epoch: 9 loss: 0.19474765378688938\n",
      "eval loss: 0.19136781999897057 0.2533369214336424\n",
      "epoch: 10\n",
      "epoch: 10 loss: 0.19101062998470916\n",
      "eval loss: 0.189459446037662 0.24971290303490695\n",
      "epoch: 11\n",
      "epoch: 11 loss: 0.1874866214564038\n",
      "eval loss: 0.1857234870853702 0.2466260685943947\n",
      "epoch: 12\n",
      "epoch: 12 loss: 0.1844679873880683\n",
      "eval loss: 0.18528849609090994 0.24502430122171104\n",
      "epoch: 13\n",
      "epoch: 13 loss: 0.18173054417892429\n",
      "eval loss: 0.17670597680478556 0.2332133993813138\n",
      "epoch: 14\n",
      "epoch: 14 loss: 0.17996669558484368\n",
      "eval loss: 0.17966611322271267 0.23834043087784357\n",
      "epoch: 15\n",
      "epoch: 15 loss: 0.17966301267754678\n",
      "eval loss: 0.1822730749141866 0.241441208047087\n",
      "epoch: 16\n",
      "epoch: 16 loss: 0.17477236947409067\n",
      "eval loss: 0.1794689896789718 0.23697716443756944\n",
      "epoch: 17\n",
      "epoch: 17 loss: 0.17643095477267887\n",
      "eval loss: 0.17498572420735092 0.2313527114382657\n",
      "epoch: 18\n",
      "epoch: 18 loss: 0.17106465453496045\n",
      "eval loss: 0.17356087663735156 0.2306805722635692\n",
      "epoch: 19\n",
      "epoch: 19 loss: 0.17142050182881172\n",
      "eval loss: 0.17157072328751538 0.22696827178818768\n",
      "epoch: 20\n",
      "epoch: 20 loss: 0.16819648621266758\n",
      "eval loss: 0.17288587737164096 0.22813680304645922\n",
      "epoch: 21\n",
      "epoch: 21 loss: 0.16612520154000665\n",
      "eval loss: 0.1725530326709272 0.22794029412121924\n",
      "epoch: 22\n",
      "epoch: 22 loss: 0.16602395896644695\n",
      "eval loss: 0.17511647722610452 0.23029464070164124\n",
      "epoch: 23\n",
      "epoch: 23 loss: 0.1653164238974175\n",
      "eval loss: 0.16781126311116076 0.22193297213081084\n",
      "epoch: 24\n",
      "epoch: 24 loss: 0.16279117796395182\n",
      "eval loss: 0.17323596916753467 0.2281240229872066\n",
      "epoch: 25\n",
      "epoch: 25 loss: 0.1632756326037756\n",
      "eval loss: 0.16951335356887484 0.22406570698782224\n",
      "epoch: 26\n",
      "epoch: 26 loss: 0.16155519247314207\n",
      "eval loss: 0.16836222725561384 0.2216740747139246\n",
      "epoch: 27\n",
      "epoch: 27 loss: 0.16004944313452668\n",
      "eval loss: 0.16826706209162182 0.22291158004432998\n",
      "epoch: 28\n",
      "epoch: 28 loss: 0.15868145075271137\n",
      "eval loss: 0.1705607441018151 0.2272845565453866\n",
      "epoch: 29\n",
      "epoch: 29 loss: 0.15635310861055762\n",
      "eval loss: 0.16760638588935411 0.2240739484160996\n",
      "epoch: 30\n",
      "epoch: 30 loss: 0.15613898256863637\n",
      "eval loss: 0.16605458744715965 0.21920843679573399\n",
      "epoch: 31\n",
      "epoch: 31 loss: 0.15595567680422204\n",
      "eval loss: 0.17166398157669352 0.22574671593585893\n",
      "epoch: 32\n",
      "epoch: 32 loss: 0.15580693205660204\n",
      "eval loss: 0.16811942914546274 0.22107497562352907\n",
      "epoch: 33\n",
      "epoch: 33 loss: 0.15250232305084055\n",
      "eval loss: 0.16586625271579652 0.2199200800802385\n",
      "epoch: 34\n",
      "epoch: 34 loss: 0.15144653682538606\n",
      "eval loss: 0.16395775816464722 0.21771690025615886\n",
      "epoch: 35\n",
      "epoch: 35 loss: 0.15346068281614916\n",
      "eval loss: 0.16421224479168392 0.21692398514016242\n",
      "epoch: 36\n",
      "epoch: 36 loss: 0.14972806649646153\n",
      "eval loss: 0.16262094352494505 0.21577053678098274\n",
      "epoch: 37\n",
      "epoch: 37 loss: 0.1504143413244238\n",
      "eval loss: 0.1639388843793831 0.2169178893649678\n",
      "epoch: 38\n",
      "epoch: 38 loss: 0.15038903826564948\n",
      "eval loss: 0.1638588792492226 0.21681890306755322\n",
      "epoch: 39\n",
      "epoch: 39 loss: 0.1500468892260049\n",
      "eval loss: 0.1759534358676807 0.2319814823483471\n",
      "epoch: 40\n",
      "epoch: 40 loss: 0.15454064143856008\n",
      "eval loss: 0.1720791709446329 0.22785031243174586\n",
      "epoch: 41\n",
      "epoch: 41 loss: 0.14817219922508545\n",
      "eval loss: 0.16230489661019318 0.21580504474106668\n",
      "epoch: 42\n",
      "epoch: 42 loss: 0.14718804728339496\n",
      "eval loss: 0.16570461538298376 0.21819302430604148\n",
      "epoch: 43\n",
      "epoch: 43 loss: 0.14673958578023324\n",
      "eval loss: 0.16363894379448965 0.21591242301424596\n",
      "epoch: 44\n",
      "epoch: 44 loss: 0.14585691473020962\n",
      "eval loss: 0.16111172623425313 0.21459036035734347\n",
      "epoch: 45\n",
      "epoch: 45 loss: 0.1440593265918668\n",
      "eval loss: 0.16327016051974708 0.21617569335653747\n",
      "epoch: 46\n",
      "epoch: 46 loss: 0.1436165964858499\n",
      "eval loss: 0.16016327261895474 0.21288119397729793\n",
      "epoch: 47\n",
      "epoch: 47 loss: 0.14232663475282661\n",
      "eval loss: 0.16112134279585 0.21244357479116033\n",
      "epoch: 48\n",
      "epoch: 48 loss: 0.14306916133145348\n",
      "eval loss: 0.16363300734699515 0.217007223314274\n",
      "epoch: 49\n",
      "epoch: 49 loss: 0.1448095178133201\n",
      "eval loss: 0.16249812429750304 0.21520723878289305\n",
      "epoch: 50\n",
      "epoch: 50 loss: 0.1411086896063408\n",
      "eval loss: 0.16219637731988346 0.2147132397996141\n",
      "epoch: 51\n",
      "epoch: 51 loss: 0.1396677381133207\n",
      "eval loss: 0.16165859074329297 0.2150824751558638\n",
      "epoch: 52\n",
      "epoch: 52 loss: 0.138455125100716\n",
      "eval loss: 0.16487549899668857 0.217911418887059\n",
      "epoch: 53\n",
      "epoch: 53 loss: 0.13829896814342002\n",
      "eval loss: 0.1604841269711295 0.21209201621582008\n",
      "epoch: 54\n",
      "epoch: 54 loss: 0.13875290273603733\n",
      "eval loss: 0.1623299521280843 0.21490000919923014\n",
      "epoch: 55\n",
      "epoch: 55 loss: 0.13766248874173156\n",
      "eval loss: 0.15757555807192436 0.20886053948757377\n",
      "epoch: 56\n",
      "epoch: 56 loss: 0.13791987951121307\n",
      "eval loss: 0.15774751898788586 0.2088100348776613\n",
      "epoch: 57\n",
      "epoch: 57 loss: 0.13694757190621012\n",
      "eval loss: 0.16048683808258665 0.2130278583751864\n",
      "epoch: 58\n",
      "epoch: 58 loss: 0.1379371533278355\n",
      "eval loss: 0.16310266127566464 0.21489561304166152\n",
      "epoch: 59\n",
      "epoch: 59 loss: 0.13756369359368714\n",
      "eval loss: 0.15869285792052396 0.20953323403174934\n",
      "epoch: 60\n",
      "epoch: 60 loss: 0.13610468727711528\n",
      "eval loss: 0.1626392249371666 0.21481356456689454\n",
      "epoch: 61\n",
      "epoch: 61 loss: 0.13439903057795002\n",
      "eval loss: 0.16189202452418877 0.212974873284775\n",
      "epoch: 62\n",
      "epoch: 62 loss: 0.13492450924652913\n",
      "eval loss: 0.16005101502412536 0.21079143483326818\n",
      "epoch: 63\n",
      "epoch: 63 loss: 0.1377656720817152\n",
      "eval loss: 0.16271091073251484 0.2160170954455192\n",
      "epoch: 64\n",
      "epoch: 64 loss: 0.13659828634596713\n",
      "eval loss: 0.15948891815822225 0.2103988565629561\n",
      "epoch: 65\n",
      "epoch: 65 loss: 0.13385728260267182\n",
      "eval loss: 0.16003606231175105 0.2117028011418644\n",
      "epoch: 66\n",
      "epoch: 66 loss: 0.1330691050257531\n",
      "eval loss: 0.15985504792051564 0.211251231538927\n",
      "epoch: 67\n",
      "epoch: 67 loss: 0.132329484831237\n",
      "eval loss: 0.15689371222949272 0.20707342228393374\n",
      "epoch: 68\n",
      "epoch: 68 loss: 0.13177793065830407\n",
      "eval loss: 0.15935297860582423 0.21118759525932213\n",
      "epoch: 69\n",
      "epoch: 69 loss: 0.13096943854982535\n",
      "eval loss: 0.15750297851784956 0.20902504840333594\n",
      "epoch: 70\n",
      "epoch: 70 loss: 0.13034717216684893\n",
      "eval loss: 0.16095516641766275 0.2123545285111355\n",
      "epoch: 71\n",
      "epoch: 71 loss: 0.13167005895614933\n",
      "eval loss: 0.1563754777957837 0.20689745064791526\n",
      "epoch: 72\n",
      "epoch: 72 loss: 0.12921901825390608\n",
      "eval loss: 0.1579957594659971 0.21026595731560227\n",
      "epoch: 73\n",
      "epoch: 73 loss: 0.13013105493900576\n",
      "eval loss: 0.15890760024415065 0.2107210952875498\n",
      "epoch: 74\n",
      "epoch: 74 loss: 0.13074710370288947\n",
      "eval loss: 0.15890882988171667 0.20977180109428678\n",
      "epoch: 75\n",
      "epoch: 75 loss: 0.12913220983887264\n",
      "eval loss: 0.15757295247746173 0.20829120890172825\n",
      "epoch: 76\n",
      "epoch: 76 loss: 0.12974809640192705\n",
      "eval loss: 0.16340785467516544 0.2152913176252911\n",
      "epoch: 77\n",
      "epoch: 77 loss: 0.1297881127367934\n",
      "eval loss: 0.15605798422640654 0.2072227778210325\n",
      "epoch: 78\n",
      "epoch: 78 loss: 0.1279057168098464\n",
      "eval loss: 0.15944427706630798 0.21161479304600536\n",
      "epoch: 79\n",
      "epoch: 79 loss: 0.12713425716501217\n",
      "eval loss: 0.15663046817989607 0.20635669482310223\n",
      "epoch: 80\n",
      "epoch: 80 loss: 0.12705351264970247\n",
      "eval loss: 0.16094300295302263 0.21140040416748332\n",
      "epoch: 81\n",
      "epoch: 81 loss: 0.12688048057586457\n",
      "eval loss: 0.16478058897239478 0.2169028134346155\n",
      "epoch: 82\n",
      "epoch: 82 loss: 0.12762700396823118\n",
      "eval loss: 0.15979479363779658 0.2108184884530947\n",
      "epoch: 83\n",
      "epoch: 83 loss: 0.126134011053422\n",
      "eval loss: 0.15591664979831274 0.20760985657940167\n",
      "epoch: 84\n",
      "epoch: 84 loss: 0.12484252154865395\n",
      "eval loss: 0.1555275922550795 0.2063528666825912\n",
      "epoch: 85\n",
      "epoch: 85 loss: 0.1253246039549497\n",
      "eval loss: 0.15991226058174063 0.21100560292606604\n",
      "epoch: 86\n",
      "epoch: 86 loss: 0.12645518577076179\n",
      "eval loss: 0.15830600694260527 0.20891542555642945\n",
      "epoch: 87\n",
      "epoch: 87 loss: 0.12558477020538394\n",
      "eval loss: 0.1594332297678766 0.2113059719721605\n",
      "epoch: 88\n",
      "epoch: 88 loss: 0.12362928158431738\n",
      "eval loss: 0.1554737209820966 0.2062643677032172\n",
      "epoch: 89\n",
      "epoch: 89 loss: 0.12415401226951044\n",
      "eval loss: 0.15699726388282662 0.20789226298851612\n",
      "epoch: 90\n",
      "epoch: 90 loss: 0.12400928621612983\n",
      "eval loss: 0.156957375506211 0.20794092752992466\n",
      "epoch: 91\n",
      "epoch: 91 loss: 0.12496148765823072\n",
      "eval loss: 0.15650792601836755 0.20841632414227054\n",
      "epoch: 92\n",
      "epoch: 92 loss: 0.12409982891025659\n",
      "eval loss: 0.15952963607457843 0.21241494137579459\n",
      "epoch: 93\n",
      "epoch: 93 loss: 0.12611750182752898\n",
      "eval loss: 0.16073783015292964 0.21193129359585752\n",
      "epoch: 94\n",
      "epoch: 94 loss: 0.12463032863173798\n",
      "eval loss: 0.15625428497674387 0.20724244810107642\n",
      "epoch: 95\n",
      "epoch: 95 loss: 0.1220825707552257\n",
      "eval loss: 0.15720340326670681 0.20792986779648776\n",
      "epoch: 96\n",
      "epoch: 96 loss: 0.12170033101667262\n",
      "eval loss: 0.15538704231467648 0.20797221404865984\n",
      "epoch: 97\n",
      "epoch: 97 loss: 0.12096300496748956\n",
      "eval loss: 0.15616098315134141 0.2063374828324977\n",
      "epoch: 98\n",
      "epoch: 98 loss: 0.12160128395253589\n",
      "eval loss: 0.15526184375270985 0.20625758708077363\n",
      "epoch: 99\n",
      "epoch: 99 loss: 0.12174520295883502\n",
      "eval loss: 0.15708989745352858 0.20760218417850634\n",
      "epoch: 100\n",
      "epoch: 100 loss: 0.12228345395982293\n",
      "eval loss: 0.15783771203991726 0.20886481805305487\n",
      "epoch: 101\n",
      "epoch: 101 loss: 0.11999118372535399\n",
      "eval loss: 0.15729867064861275 0.20767192306437657\n",
      "epoch: 102\n",
      "epoch: 102 loss: 0.11970167830660386\n",
      "eval loss: 0.15650915750206532 0.2090695745593869\n",
      "epoch: 103\n",
      "epoch: 103 loss: 0.12059353919197138\n",
      "eval loss: 0.15597324126083234 0.20580237290015033\n",
      "epoch: 104\n",
      "epoch: 104 loss: 0.12026683020164498\n",
      "eval loss: 0.15517658357968908 0.20516388903565033\n",
      "epoch: 105\n",
      "epoch: 105 loss: 0.12135624541994225\n",
      "eval loss: 0.1594416969902226 0.21208501917715195\n",
      "epoch: 106\n",
      "epoch: 106 loss: 0.12004973289790669\n",
      "eval loss: 0.15546402579242458 0.20653291104538002\n",
      "epoch: 107\n",
      "epoch: 107 loss: 0.12033060611101447\n",
      "eval loss: 0.15884034376868275 0.209001177478704\n",
      "epoch: 108\n",
      "epoch: 108 loss: 0.11794785307774149\n",
      "eval loss: 0.15465746018193705 0.2037288913352832\n",
      "epoch: 109\n",
      "epoch: 109 loss: 0.12028276851059216\n",
      "eval loss: 0.15911760112367143 0.20956888038167565\n",
      "epoch: 110\n",
      "epoch: 110 loss: 0.11828866124487473\n",
      "eval loss: 0.15410450326882266 0.204054196845821\n",
      "epoch: 111\n",
      "epoch: 111 loss: 0.11820700677258271\n",
      "eval loss: 0.1567911442164578 0.20760455097183803\n",
      "epoch: 112\n",
      "epoch: 112 loss: 0.11970618105843975\n",
      "eval loss: 0.15564697223763568 0.20625097102706932\n",
      "epoch: 113\n",
      "epoch: 113 loss: 0.11769506486295664\n",
      "eval loss: 0.15516105352297013 0.20469589698885948\n",
      "epoch: 114\n",
      "epoch: 114 loss: 0.11794040041602234\n",
      "eval loss: 0.15572362550938873 0.2063285093398992\n",
      "epoch: 115\n",
      "epoch: 115 loss: 0.11752087234891458\n",
      "eval loss: 0.15522020621495156 0.20528756560373013\n",
      "epoch: 116\n",
      "epoch: 116 loss: 0.11728084639549538\n",
      "eval loss: 0.15477963445245124 0.20489799648543303\n",
      "epoch: 117\n",
      "epoch: 117 loss: 0.1166825685026107\n",
      "eval loss: 0.15453980034579562 0.2057831774844942\n",
      "epoch: 118\n",
      "epoch: 118 loss: 0.11760003796421879\n",
      "eval loss: 0.15629126957319178 0.20649545596313718\n",
      "epoch: 119\n",
      "epoch: 119 loss: 0.1181065553160211\n",
      "eval loss: 0.15575834845925987 0.20623760601686564\n",
      "epoch: 120\n",
      "epoch: 120 loss: 0.1157220737189511\n",
      "eval loss: 0.15711018389696968 0.2079468748200895\n",
      "epoch: 121\n",
      "epoch: 121 loss: 0.11554097819370346\n",
      "eval loss: 0.15696753407721548 0.20755359381961874\n",
      "epoch: 122\n",
      "epoch: 122 loss: 0.1150216484473197\n",
      "eval loss: 0.15383931738215456 0.20385152692621378\n",
      "epoch: 123\n",
      "epoch: 123 loss: 0.1151880045578273\n",
      "eval loss: 0.15544900954415736 0.20749797884672516\n",
      "epoch: 124\n",
      "epoch: 124 loss: 0.11527659852340698\n",
      "eval loss: 0.15566886140056224 0.20559259752068315\n",
      "epoch: 125\n",
      "epoch: 125 loss: 0.11436374701953177\n",
      "eval loss: 0.1538862566014714 0.20342073038146855\n",
      "epoch: 126\n",
      "epoch: 126 loss: 0.1145380236087406\n",
      "eval loss: 0.15478076951203035 0.20575009543536585\n",
      "epoch: 127\n",
      "epoch: 127 loss: 0.11454139749333195\n",
      "eval loss: 0.15474533900836837 0.20468986308745543\n",
      "epoch: 128\n",
      "epoch: 128 loss: 0.11374245761819267\n",
      "eval loss: 0.1559738504383935 0.20687618167186395\n",
      "epoch: 129\n",
      "epoch: 129 loss: 0.1143447477212564\n",
      "eval loss: 0.15524399223436225 0.20495241426859212\n",
      "epoch: 130\n",
      "epoch: 130 loss: 0.11374858868553317\n",
      "eval loss: 0.15647021587697815 0.20714290712184785\n",
      "epoch: 131\n",
      "epoch: 131 loss: 0.26587203210663835\n",
      "eval loss: 0.3361107822414716 0.43528736208515917\n",
      "epoch: 132\n",
      "epoch: 132 loss: 0.3274926405981818\n",
      "eval loss: 0.3175651298111663 0.41728032467788606\n",
      "epoch: 133\n",
      "epoch: 133 loss: 0.32233533223904565\n",
      "eval loss: 0.3217821510164063 0.4205593560405718\n",
      "epoch: 134\n",
      "epoch: 134 loss: 0.3228234890500935\n",
      "eval loss: 0.3240848726748826 0.4212847006558242\n",
      "epoch: 135\n",
      "epoch: 135 loss: 0.32211044326697985\n",
      "eval loss: 0.31827289874605624 0.41523169600552395\n",
      "epoch: 136\n",
      "epoch: 136 loss: 0.32191234347668746\n",
      "eval loss: 0.3216935093652674 0.4187160912382326\n",
      "epoch: 137\n",
      "epoch: 137 loss: 0.32123108132451\n",
      "eval loss: 0.32006928922069044 0.4172693135276788\n",
      "epoch: 138\n",
      "epoch: 138 loss: 0.32161850007496684\n",
      "eval loss: 0.3182097516793143 0.4162237887873511\n",
      "epoch: 139\n",
      "epoch: 139 loss: 0.32193720559770794\n",
      "eval loss: 0.3188110995003075 0.4186345026119186\n",
      "epoch: 140\n",
      "epoch: 140 loss: 0.32134214494782043\n",
      "eval loss: 0.3195950006244477 0.4168854586740505\n",
      "epoch: 141\n",
      "epoch: 141 loss: 0.32245217731967213\n",
      "eval loss: 0.31983623717583065 0.41736826864156773\n",
      "epoch: 142\n",
      "epoch: 142 loss: 0.32198295862970844\n",
      "eval loss: 0.31875185678675655 0.4162598885443148\n",
      "epoch: 143\n",
      "epoch: 143 loss: 0.3223237047978349\n",
      "eval loss: 0.3172124434440889 0.4175224897820264\n",
      "epoch: 144\n",
      "epoch: 144 loss: 0.3208764389695068\n",
      "eval loss: 0.31908663619281924 0.4170038374535283\n",
      "epoch: 145\n",
      "epoch: 145 loss: 0.32171521678662757\n",
      "eval loss: 0.3178603414088821 0.41564742370245533\n",
      "epoch: 146\n",
      "epoch: 146 loss: 0.32127129410817856\n",
      "eval loss: 0.31673359738624207 0.4153160981751146\n",
      "epoch: 147\n",
      "epoch: 147 loss: 0.32067780597220796\n",
      "eval loss: 0.32186617919892513 0.4193402225443137\n",
      "epoch: 148\n",
      "epoch: 148 loss: 0.3216325489356735\n",
      "eval loss: 0.3179035956742142 0.41550290867393797\n",
      "epoch: 149\n",
      "epoch: 149 loss: 0.3206115140053002\n",
      "eval loss: 0.31660402361414863 0.4152300862670356\n",
      "epoch: 150\n",
      "epoch: 150 loss: 0.3217542908253557\n",
      "eval loss: 0.3188518457366777 0.41737461287787675\n",
      "epoch: 151\n",
      "epoch: 151 loss: 0.3210119040578689\n",
      "eval loss: 0.3195849026466926 0.4165936668059079\n",
      "epoch: 152\n",
      "epoch: 152 loss: 0.32184496790933614\n",
      "eval loss: 0.3217749830031952 0.4224602402902221\n",
      "epoch: 153\n",
      "epoch: 153 loss: 0.32312748665091423\n",
      "eval loss: 0.3262761821618021 0.42560060554901846\n",
      "epoch: 154\n",
      "epoch: 154 loss: 0.3226289429504293\n",
      "eval loss: 0.31628768587667994 0.4174002650186089\n",
      "epoch: 155\n",
      "epoch: 155 loss: 0.32255361973952185\n",
      "eval loss: 0.31842192242430717 0.4157101206885659\n",
      "epoch: 156\n",
      "epoch: 156 loss: 0.3215273786491064\n",
      "eval loss: 0.31961157641090204 0.4161819988115573\n",
      "epoch: 157\n",
      "epoch: 157 loss: 0.3219760127753184\n",
      "eval loss: 0.32365343598207424 0.4223689801957775\n",
      "epoch: 158\n",
      "epoch: 158 loss: 0.3224194009934372\n",
      "eval loss: 0.31763590458869995 0.41450611018124756\n",
      "epoch: 159\n",
      "epoch: 159 loss: 0.3206000976839661\n",
      "eval loss: 0.31721525964337854 0.4155416660314781\n",
      "epoch: 160\n",
      "epoch: 160 loss: 0.3215901454168917\n",
      "eval loss: 0.31804550709911783 0.4170518332949425\n",
      "epoch: 161\n",
      "epoch: 161 loss: 0.32055184516587387\n",
      "eval loss: 0.3199101085718768 0.4158796869007104\n",
      "epoch: 162\n",
      "epoch: 162 loss: 0.32106328000795215\n",
      "eval loss: 0.3203263734978481 0.4179934635495597\n",
      "epoch: 163\n",
      "epoch: 163 loss: 0.3217341584707667\n",
      "eval loss: 0.3198875362930933 0.41499125823268723\n",
      "epoch: 164\n",
      "epoch: 164 loss: 0.3212589085537501\n",
      "eval loss: 0.31899437341596026 0.4169506210180711\n",
      "epoch: 165\n",
      "epoch: 165 loss: 0.3212438927907509\n",
      "eval loss: 0.3216012312683688 0.42242859289683243\n",
      "epoch: 166\n",
      "epoch: 166 loss: 0.3211611949657557\n",
      "eval loss: 0.31786766218291534 0.4170074304386818\n",
      "epoch: 167\n",
      "epoch: 167 loss: 0.32111861713264994\n",
      "eval loss: 0.319618544690753 0.41767047680565483\n",
      "epoch: 168\n",
      "epoch: 168 loss: 0.3216000588156622\n",
      "eval loss: 0.3221448938140067 0.4213548853629902\n",
      "epoch: 169\n",
      "epoch: 169 loss: 0.32191817362579167\n",
      "eval loss: 0.3212171077236613 0.4199443484934179\n",
      "epoch: 170\n",
      "epoch: 170 loss: 0.3213642154733606\n",
      "eval loss: 0.3190187898462471 0.41689588410321465\n",
      "epoch: 171\n",
      "epoch: 171 loss: 0.32130295324624303\n",
      "eval loss: 0.31779328403786145 0.4152357050634816\n",
      "epoch: 172\n",
      "epoch: 172 loss: 0.3203172826519634\n",
      "eval loss: 0.3159475168523939 0.4146043918433396\n",
      "epoch: 173\n",
      "epoch: 173 loss: 0.32110189417139823\n",
      "eval loss: 0.31763414665970924 0.4150375007441621\n",
      "epoch: 174\n",
      "epoch: 174 loss: 0.32083984924799275\n",
      "eval loss: 0.3191574271479986 0.41724738188011096\n",
      "epoch: 175\n",
      "epoch: 175 loss: 0.32071369879339207\n",
      "eval loss: 0.3193322089414717 0.4163499039346021\n",
      "epoch: 176\n",
      "epoch: 176 loss: 0.3209721084701244\n",
      "eval loss: 0.3200726547792433 0.41734592991003566\n",
      "epoch: 177\n",
      "epoch: 177 loss: 0.32067242312911365\n",
      "eval loss: 0.3199295283352307 0.41843266151915737\n",
      "epoch: 178\n",
      "epoch: 178 loss: 0.3212870549238086\n",
      "eval loss: 0.3174855795607721 0.4175102430063321\n",
      "epoch: 179\n",
      "epoch: 179 loss: 0.32083037876556925\n",
      "eval loss: 0.3189279620899048 0.41684808496154235\n",
      "epoch: 180\n",
      "epoch: 180 loss: 0.3205991925167096\n",
      "eval loss: 0.3193466297333638 0.4155467996920029\n",
      "epoch: 181\n",
      "epoch: 181 loss: 0.3200616418942791\n",
      "eval loss: 0.3172545607566088 0.4146142823304195\n",
      "epoch: 182\n",
      "epoch: 182 loss: 0.321011596288664\n",
      "eval loss: 0.3173103718699277 0.4143587485332153\n",
      "epoch: 183\n",
      "epoch: 183 loss: 0.3201645735843687\n",
      "eval loss: 0.318275867765342 0.4170246342196122\n",
      "epoch: 184\n",
      "epoch: 184 loss: 0.3206745990762465\n",
      "eval loss: 0.31652581451778256 0.41484143488344843\n",
      "epoch: 185\n",
      "epoch: 185 loss: 0.32013425674639817\n",
      "eval loss: 0.3156573675556925 0.41389985405155877\n",
      "epoch: 186\n",
      "epoch: 186 loss: 0.3207442637170172\n",
      "eval loss: 0.31840547187074614 0.41804266934439205\n",
      "epoch: 187\n",
      "epoch: 187 loss: 0.32083866958323126\n",
      "eval loss: 0.31656962742213834 0.41577450633626284\n",
      "epoch: 188\n",
      "epoch: 188 loss: 0.32071734829472304\n",
      "eval loss: 0.3172731083265508 0.41474953071284537\n",
      "epoch: 189\n",
      "epoch: 189 loss: 0.3211005770232552\n",
      "eval loss: 0.3178554236589193 0.4148875584344375\n",
      "epoch: 190\n",
      "epoch: 190 loss: 0.32092810473949834\n",
      "eval loss: 0.31776403044120055 0.4174528113087317\n",
      "epoch: 191\n",
      "epoch: 191 loss: 0.32102194616203933\n",
      "eval loss: 0.32051998492570755 0.4186216056685891\n",
      "epoch: 192\n",
      "epoch: 192 loss: 0.3210357200718468\n",
      "eval loss: 0.320533968521028 0.41720852377908196\n",
      "epoch: 193\n",
      "epoch: 193 loss: 0.3202115734113641\n",
      "eval loss: 0.3180451037845232 0.4131040651443517\n",
      "epoch: 194\n",
      "epoch: 194 loss: 0.3205369487174404\n",
      "eval loss: 0.3183340375939976 0.4152713417628199\n",
      "epoch: 195\n",
      "epoch: 195 loss: 0.32114532687062336\n",
      "eval loss: 0.31657307637330845 0.41480016938823405\n",
      "epoch: 196\n",
      "epoch: 196 loss: 0.32096621717763607\n",
      "eval loss: 0.3161262956182307 0.41451701944285607\n",
      "epoch: 197\n",
      "epoch: 197 loss: 0.321384601829767\n",
      "eval loss: 0.3200359761652244 0.41620665939040336\n",
      "epoch: 198\n",
      "epoch: 198 loss: 0.3209846384721309\n",
      "eval loss: 0.31780773116537175 0.4155690775364743\n",
      "epoch: 199\n",
      "epoch: 199 loss: 0.32194675173394144\n",
      "eval loss: 0.31687759593272113 0.415780993289381\n",
      "min eval loss: 0.15383931738215456 epoch 122\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "BATCH_SIZE = 64\n",
    "base_train_data = pd.read_json(str(Path(BASE_PATH) / 'train.json'), lines=True)\n",
    "samples = base_train_data\n",
    "save_path = Path(\"./model_prediction\")\n",
    "if not save_path.exists():\n",
    "    save_path.mkdir(parents=True)\n",
    "shutil.rmtree(\"./model\", True)\n",
    "shutil.rmtree(\"./logs\", True)\n",
    "split = ShuffleSplit(n_splits=5, test_size=.1)\n",
    "ids = samples.reset_index()[\"id\"]\n",
    "set_seed(124)\n",
    "for fold, (train_index, test_index) in enumerate(split.split(samples)):\n",
    "    print(f\"fold: {fold}\")\n",
    "    train_df = samples.loc[train_index].reset_index()\n",
    "    val_df = samples.loc[test_index].reset_index()\n",
    "    train_loader = create_loader(train_df, BATCH_SIZE)\n",
    "    valid_loader = create_loader(val_df, BATCH_SIZE)\n",
    "    print(train_df.shape, val_df.shape)\n",
    "    ae_model = AEModel()\n",
    "    state_dict = torch.load(\"./ae-model.pt\")\n",
    "    ae_model.load_state_dict(state_dict)\n",
    "    del state_dict\n",
    "    model = FromAeModel(ae_model.seq)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    lr_scheduler = None\n",
    "    epoch = train(model, train_loader, valid_loader, optimizer, lr_scheduler, 200, device=device,\n",
    "                  log_path=f\"logs/{fold}\")\n",
    "    shutil.copyfile(str(Path(MODEL_SAVE_PATH) / f\"./model-{epoch}.pt\"), f\"model_prediction/model-{fold}.pt\")\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T15:29:23.255573Z",
     "iopub.status.busy": "2020-09-30T15:29:23.254951Z",
     "iopub.status.idle": "2020-09-30T15:29:23.258837Z",
     "shell.execute_reply": "2020-09-30T15:29:23.258429Z"
    },
    "papermill": {
     "duration": 0.931345,
     "end_time": "2020-09-30T15:29:23.258939",
     "exception": false,
     "start_time": "2020-09-30T15:29:22.327594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_batch(model, data, device):\n",
    "    # batch x seq_len x target_size\n",
    "    with torch.no_grad():\n",
    "        pred = model(data[\"sequence\"].to(device), data[\"bpp\"].to(device))\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "    return_values = []\n",
    "    ids = data[\"ids\"]\n",
    "    for idx, p in enumerate(pred):\n",
    "        id_ = ids[idx]\n",
    "        assert p.shape == (model.pred_len, len(target_cols))\n",
    "        for seqpos, val in enumerate(p):\n",
    "            assert len(val) == len(target_cols)\n",
    "            dic = {key: val for key, val in zip(target_cols, val)}\n",
    "            dic[\"id_seqpos\"] = f\"{id_}_{seqpos}\"\n",
    "            return_values.append(dic)\n",
    "    return return_values\n",
    "\n",
    "\n",
    "def predict_data(model, loader, device, batch_size):\n",
    "    data_list = []\n",
    "    for i, data in enumerate(progress_bar(loader)):\n",
    "        data_list += predict_batch(model, data, device)\n",
    "    expected_length = model.pred_len * len(loader) * batch_size\n",
    "    assert len(data_list) == expected_length, f\"len = {len(data_list)} expected = {expected_length}\"\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.915552,
     "end_time": "2020-09-30T15:29:25.486446",
     "exception": false,
     "start_time": "2020-09-30T15:29:24.570894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T15:29:27.358028Z",
     "iopub.status.busy": "2020-09-30T15:29:27.357406Z",
     "iopub.status.idle": "2020-09-30T15:34:50.932766Z",
     "shell.execute_reply": "2020-09-30T15:34:50.931465Z"
    },
    "papermill": {
     "duration": 324.496965,
     "end_time": "2020-09-30T15:34:50.932883",
     "exception": false,
     "start_time": "2020-09-30T15:29:26.435918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public_df: (629, 7)\n",
      "private_df: (3005, 7)\n",
      "(1, 107, 107, 3)\n",
      "(1, 130, 130, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='629' class='' max='629' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [629/629 00:10<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3005' class='' max='3005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3005/3005 00:55<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C\n",
      "0  id_00073f8be_0    0.776515     0.824674  1.813194    0.563424  0.756904\n",
      "1  id_00073f8be_1    2.519537     3.295120  4.079534    3.278911  2.944239\n",
      "2  id_00073f8be_2    1.571656     0.658931  0.626493    0.653813  0.735708\n",
      "3  id_00073f8be_3    1.294815     1.216727  1.190936    1.761870  1.827749\n",
      "4  id_00073f8be_4    0.906778     0.595592  0.558260    0.938419  0.988071\n",
      "               id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C  \\\n",
      "457948  id_ffda94f24_125    0.096043     0.392177  0.354100    0.500296   \n",
      "457949  id_ffda94f24_126    0.377521     0.519269  1.019004    0.642925   \n",
      "457950  id_ffda94f24_127    0.599662     0.269538  0.383775    0.284465   \n",
      "457951  id_ffda94f24_128   -0.004982     0.451013  0.354492    0.449578   \n",
      "457952  id_ffda94f24_129    0.188647     0.457067  0.477021    0.670518   \n",
      "\n",
      "         deg_50C  \n",
      "457948  0.313625  \n",
      "457949  0.836353  \n",
      "457950  0.458611  \n",
      "457951  0.294836  \n",
      "457952  0.586635  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='629' class='' max='629' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [629/629 00:09<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3005' class='' max='3005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3005/3005 00:50<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C\n",
      "0  id_00073f8be_0    0.825423     0.584091  1.777551    0.435887  0.720499\n",
      "1  id_00073f8be_1    2.367449     3.301724  4.139466    3.217031  2.779341\n",
      "2  id_00073f8be_2    1.698558     0.455184  0.624785    0.606408  0.659401\n",
      "3  id_00073f8be_3    1.301391     1.243653  1.344100    1.777979  1.774092\n",
      "4  id_00073f8be_4    0.788625     0.510652  0.432923    0.903827  0.849623\n",
      "               id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C  \\\n",
      "457948  id_ffda94f24_125    0.213770     0.457415  0.370763    0.579796   \n",
      "457949  id_ffda94f24_126    0.498825     0.384016  0.493283    0.573369   \n",
      "457950  id_ffda94f24_127    0.713420     0.041531  0.087966    0.242617   \n",
      "457951  id_ffda94f24_128    0.364876     0.053125  0.010299    0.277405   \n",
      "457952  id_ffda94f24_129    0.598143     0.606256  0.325913    0.772884   \n",
      "\n",
      "         deg_50C  \n",
      "457948  0.361806  \n",
      "457949  0.492423  \n",
      "457950  0.320162  \n",
      "457951  0.183381  \n",
      "457952  0.386646  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='629' class='' max='629' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [629/629 00:09<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3005' class='' max='3005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3005/3005 00:50<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C\n",
      "0  id_00073f8be_0    0.874582     0.698138  2.006648    0.601986  0.738487\n",
      "1  id_00073f8be_1    2.397415     3.099681  3.949216    3.409038  2.769058\n",
      "2  id_00073f8be_2    1.704391     0.446882  0.469911    0.619796  0.591133\n",
      "3  id_00073f8be_3    1.391434     1.255318  1.268791    1.800835  1.835984\n",
      "4  id_00073f8be_4    0.980037     0.664914  0.454597    0.952523  0.893061\n",
      "               id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C  \\\n",
      "457948  id_ffda94f24_125   -0.071863     0.328742  0.281375    0.474900   \n",
      "457949  id_ffda94f24_126    0.201119     0.419974  0.498373    0.467236   \n",
      "457950  id_ffda94f24_127    0.382366     0.191364  0.234392    0.220138   \n",
      "457951  id_ffda94f24_128   -0.050018     0.227023  0.227780    0.477891   \n",
      "457952  id_ffda94f24_129    0.112536     0.327735  0.374343    0.318066   \n",
      "\n",
      "         deg_50C  \n",
      "457948  0.232758  \n",
      "457949  0.589303  \n",
      "457950  0.287520  \n",
      "457951  0.188397  \n",
      "457952  0.086707  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='629' class='' max='629' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [629/629 00:09<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3005' class='' max='3005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3005/3005 00:50<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C\n",
      "0  id_00073f8be_0    0.744365     0.596305  1.811344    0.507739  0.769864\n",
      "1  id_00073f8be_1    2.421815     2.954833  3.851343    3.061374  2.664587\n",
      "2  id_00073f8be_2    1.478380     0.728263  0.701230    0.779583  0.640335\n",
      "3  id_00073f8be_3    1.236575     1.100497  1.078285    1.434915  1.870876\n",
      "4  id_00073f8be_4    0.781425     0.519107  0.420098    0.813529  0.871711\n",
      "               id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C  \\\n",
      "457948  id_ffda94f24_125    0.301435     0.312064  0.369389    0.454155   \n",
      "457949  id_ffda94f24_126    0.428111     0.257571  0.899649    0.438248   \n",
      "457950  id_ffda94f24_127    0.621575     0.143875  0.155460    0.216259   \n",
      "457951  id_ffda94f24_128    0.184389     0.151896  0.061671    0.231299   \n",
      "457952  id_ffda94f24_129    0.107019     0.113484  0.304010    0.206129   \n",
      "\n",
      "         deg_50C  \n",
      "457948  0.146175  \n",
      "457949  0.552483  \n",
      "457950  0.125820  \n",
      "457951 -0.163225  \n",
      "457952  0.006032  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='629' class='' max='629' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [629/629 00:09<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3005' class='' max='3005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3005/3005 00:50<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C\n",
      "0  id_00073f8be_0    0.685752     0.735046  1.918670    0.567634  0.796215\n",
      "1  id_00073f8be_1    2.284224     3.042243  4.571076    2.981692  2.860991\n",
      "2  id_00073f8be_2    1.666587     0.742518  0.860221    0.886663  0.970798\n",
      "3  id_00073f8be_3    1.350224     1.100080  1.309342    1.608225  1.826831\n",
      "4  id_00073f8be_4    0.709335     0.624428  0.582916    0.789661  0.819878\n",
      "               id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C  \\\n",
      "457948  id_ffda94f24_125    0.058724     0.341151  0.419136    0.462688   \n",
      "457949  id_ffda94f24_126    0.181126     0.532955  1.350785    0.663485   \n",
      "457950  id_ffda94f24_127    0.424188     0.146118  0.377525    0.258806   \n",
      "457951  id_ffda94f24_128    0.028309     0.028396  0.164784    0.193107   \n",
      "457952  id_ffda94f24_129    0.125651     0.609985  0.674199    0.667489   \n",
      "\n",
      "         deg_50C  \n",
      "457948  0.008354  \n",
      "457949  0.731701  \n",
      "457950  0.465794  \n",
      "457951 -0.009807  \n",
      "457952  0.531626  \n",
      "        id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C\n",
      "0  id_00073f8be_0    0.781327     0.687651  1.865481    0.535334  0.756394\n",
      "1  id_00073f8be_1    2.398088     3.138720  4.118127    3.189609  2.803643\n",
      "2  id_00073f8be_2    1.623914     0.606355  0.656528    0.709252  0.719475\n",
      "3  id_00073f8be_3    1.314888     1.183255  1.238291    1.676765  1.827106\n",
      "4  id_00073f8be_4    0.833240     0.582938  0.489759    0.879592  0.884469\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 1\n",
    "base_test_data = pd.read_json(str(Path(BASE_PATH) / 'test.json'), lines=True)\n",
    "public_df = base_test_data.query(\"seq_length == 107\").copy()\n",
    "private_df = base_test_data.query(\"seq_length == 130\").copy()\n",
    "print(f\"public_df: {public_df.shape}\")\n",
    "print(f\"private_df: {private_df.shape}\")\n",
    "public_df = public_df.reset_index()\n",
    "private_df = private_df.reset_index()\n",
    "pub_loader = create_loader(public_df, BATCH_SIZE, is_test=True)\n",
    "pri_loader = create_loader(private_df, BATCH_SIZE, is_test=True)\n",
    "pred_df_list = []\n",
    "c = 0\n",
    "for fold in range(5):\n",
    "    model_load_path = f\"./model_prediction/model-{fold}.pt\"\n",
    "    ae_model0 = AEModel()\n",
    "    ae_model1 = AEModel()\n",
    "    model_pub = FromAeModel(pred_len=107, seq=ae_model0.seq)\n",
    "    model_pub = model_pub.to(device)\n",
    "    model_pri = FromAeModel(pred_len=130, seq=ae_model1.seq)\n",
    "    model_pri = model_pri.to(device)\n",
    "    state_dict = torch.load(model_load_path, map_location=device)\n",
    "    model_pub.load_state_dict(state_dict)\n",
    "    model_pri.load_state_dict(state_dict)\n",
    "    del state_dict\n",
    "\n",
    "    data_list = []\n",
    "    data_list += predict_data(model_pub, pub_loader, device, BATCH_SIZE)\n",
    "    data_list += predict_data(model_pri, pri_loader, device, BATCH_SIZE)\n",
    "    pred_df = pd.DataFrame(data_list, columns=[\"id_seqpos\"] + target_cols)\n",
    "    print(pred_df.head())\n",
    "    print(pred_df.tail())\n",
    "    pred_df_list.append(pred_df)\n",
    "    c += 1\n",
    "data_dic = dict(id_seqpos=pred_df_list[0][\"id_seqpos\"])\n",
    "for col in target_cols:\n",
    "    vals = np.zeros(pred_df_list[0][col].shape[0])\n",
    "    for df in pred_df_list:\n",
    "        vals += df[col].values\n",
    "    data_dic[col] = vals / float(c)\n",
    "pred_df_avg = pd.DataFrame(data_dic, columns=[\"id_seqpos\"] + target_cols)\n",
    "print(pred_df_avg.head())\n",
    "pred_df_avg.to_csv(\"./submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 10724.452119,
   "end_time": "2020-09-30T15:34:53.054048",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-30T12:36:08.601929",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
