{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-06T10:08:44.037618Z",
     "iopub.status.busy": "2020-10-06T10:08:44.036838Z",
     "iopub.status.idle": "2020-10-06T10:08:52.639515Z",
     "shell.execute_reply": "2020-10-06T10:08:52.638796Z"
    },
    "papermill": {
     "duration": 8.631681,
     "end_time": "2020-10-06T10:08:52.639649",
     "exception": false,
     "start_time": "2020-10-06T10:08:44.007968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing basic libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from numpy import zeros, newaxis\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "SEED = 101\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "               \n",
    "# Importing the training set\n",
    "DATA_DIR = Path(\"../input/stanford-covid-vaccine/\")\n",
    "BPPS_DIR = DATA_DIR / \"bpps\"\n",
    "\n",
    "train = pd.read_json(DATA_DIR / \"train.json\", lines=True)\n",
    "test = pd.read_json(DATA_DIR / \"test.json\", lines=True)\n",
    "aug_df = pd.read_csv('/kaggle/input/how-to-generate-augmentation-data/aug_data.csv')\n",
    "\n",
    "bppm_paths = list(BPPS_DIR.glob(\"*.npy\"))\n",
    "\n",
    "#settings\n",
    "debug = False\n",
    "TPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:08:52.686273Z",
     "iopub.status.busy": "2020-10-06T10:08:52.685334Z",
     "iopub.status.idle": "2020-10-06T10:08:52.689149Z",
     "shell.execute_reply": "2020-10-06T10:08:52.689638Z"
    },
    "papermill": {
     "duration": 0.030098,
     "end_time": "2020-10-06T10:08:52.689753",
     "exception": false,
     "start_time": "2020-10-06T10:08:52.659655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 107, 107)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Light data exploration, to check features lengths\n",
    "len(train['sequence'][0]), len(train['structure'][0]), len(train['predicted_loop_type'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:08:52.734491Z",
     "iopub.status.busy": "2020-10-06T10:08:52.733595Z",
     "iopub.status.idle": "2020-10-06T10:08:52.737629Z",
     "shell.execute_reply": "2020-10-06T10:08:52.737127Z"
    },
    "papermill": {
     "duration": 0.028147,
     "end_time": "2020-10-06T10:08:52.737731",
     "exception": false,
     "start_time": "2020-10-06T10:08:52.709584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GGAAAGACUACGAGUGUCGUGUUUACCUAACGAGAUAGAAUCGAAGGAUGGCGACGUUCGUAGUCGGACUUAGUUUUCGAACUAAGAAAAGAAACAACAACAACAAC',\n",
       " '.....(((((((((((((((.....(((..(((.......))).)))...)))))))))))))))...(((((((....))))))).....................',\n",
       " 'EEEEESSSSSSSSSSSSSSSIIIIISSSIISSSHHHHHHHSSSISSSIIISSSSSSSSSSSSSSSXXXSSSSSSSHHHHSSSSSSSEEEEEEEEEEEEEEEEEEEEE')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine features\n",
    "train['sequence'][60], train['structure'][60] ,train['predicted_loop_type'][60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:08:52.797652Z",
     "iopub.status.busy": "2020-10-06T10:08:52.786284Z",
     "iopub.status.idle": "2020-10-06T10:08:52.832921Z",
     "shell.execute_reply": "2020-10-06T10:08:52.832466Z"
    },
    "papermill": {
     "duration": 0.07422,
     "end_time": "2020-10-06T10:08:52.833054",
     "exception": false,
     "start_time": "2020-10-06T10:08:52.758834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "# Set alphabets\n",
    "alphabet = 'AGCU().MXBISHE'\n",
    "alphabet_rna = 'AGCU'\n",
    "alphabet_struc = '()XXX.'\n",
    "alphabet_loop = 'MXB...I...S.H.E'\n",
    "\n",
    "# Set target_cols\n",
    "target_cols  = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n",
    "non_target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n",
    "marked_target_cols  = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']\n",
    "\n",
    "def get_bppm(id_):\n",
    "    return np.load(BPPS_DIR / f\"{id_}.npy\")\n",
    "\n",
    "def get_bpps_nb(id_):\n",
    "     # from https://www.kaggle.com/symyksr/openvaccine-deepergcn \n",
    "    bpps_nb_mean = 0.077522 # mean of bpps_nb across all training data\n",
    "    bpps_nb_std = 0.08914   # std of bpps_nb across all training data\n",
    "    bpps = get_bppm(id_)\n",
    "    bpps_nb = (bpps > 0).sum(axis=0) / bpps.shape[0]\n",
    "    bpps_nb = (bpps_nb - bpps_nb_mean) / bpps_nb_std\n",
    "    return bpps_nb\n",
    "\n",
    "def mk_pair_map(structure, type='pm'):\n",
    "    pm = np.full(len(structure), 0, dtype=int)\n",
    "    pd = np.full(len(structure), 0, dtype=int)\n",
    "    queue = []\n",
    "    for i, s in enumerate(structure):\n",
    "        if s == \"(\":\n",
    "            queue.append(i)\n",
    "            #print(\"Found '(' at i={}, queue={}\".format(i, queue))\n",
    "        elif s == \")\":\n",
    "            j = queue.pop()\n",
    "            pm[i] = j\n",
    "            pm[j] = i\n",
    "            pd[i] = i-j\n",
    "            pd[j] = i-j\n",
    "            #print(\"Found ')' at i={}, j={}, queue={}, pd[i]={}, pd[j]={}, i-j={}\".format(i, j, queue, pd[i], pd[j], i-j))\n",
    "    if type == 'pm':\n",
    "        return pm\n",
    "    elif type == 'pd':\n",
    "        return pd    \n",
    "    \n",
    "def get_structure_adj(seq_length, structure, sequence):\n",
    "    Ss = []\n",
    "    cue = []\n",
    "    a_structures = OrderedDict([\n",
    "        ((\"A\", \"U\"), np.zeros([seq_length, seq_length])),\n",
    "        ((\"C\", \"G\"), np.zeros([seq_length, seq_length])),\n",
    "        ((\"U\", \"G\"), np.zeros([seq_length, seq_length])),\n",
    "        ((\"U\", \"A\"), np.zeros([seq_length, seq_length])),\n",
    "        ((\"G\", \"C\"), np.zeros([seq_length, seq_length])),\n",
    "        ((\"G\", \"U\"), np.zeros([seq_length, seq_length])),\n",
    "    ])\n",
    "    for j in range(seq_length):\n",
    "        if structure[j] == \"(\":\n",
    "            cue.append(j)\n",
    "        elif structure[j] == \")\":\n",
    "            start = cue.pop()\n",
    "            a_structures[(sequence[start], sequence[j])][start, j] = 1\n",
    "            a_structures[(sequence[j], sequence[start])][j, start] = 1\n",
    "\n",
    "    a_strc = np.stack([a for a in a_structures.values()], axis=2)\n",
    "    a_strc = np.sum(a_strc, axis=2, keepdims=False)\n",
    "    return a_strc\n",
    "\n",
    "def preprocess_data(data):\n",
    "    data = data.loc[data['SN_filter'] == 1].copy()\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "def step(seq_length):\n",
    "    data = list(range(int(seq_length)))\n",
    "    newList = []\n",
    "    newList = [x / seq_length for x in data]\n",
    "    return newList\n",
    "\n",
    "def preprocess_features(data):\n",
    "    data['seq'] = data.apply(lambda x: integer_encoder(x['sequence'], alphabet_rna), axis=1)\n",
    "    data['struc'] = data.apply(lambda x: integer_encoder(x['structure'], alphabet_struc), axis=1)\n",
    "    data['loop'] = data.apply(lambda x: integer_encoder(x['predicted_loop_type'], alphabet_loop), axis=1)\n",
    "    data['step'] = data.apply(lambda x: step(x['seq_length']), axis=1) # Doesn't help\n",
    "    data['pair_dist'] = data.structure.apply(mk_pair_map, type='pd') # Not sure it helps\n",
    "    data['pair_map'] = data.structure.apply(mk_pair_map, type='pm') # Not sure it helps\n",
    "    data['bppm_max'] = data.apply(lambda x: get_bppm(x['id']).max(0), axis=1)\n",
    "    data['bppm_sum'] = data.apply(lambda x: get_bppm(x['id']).sum(0), axis=1)\n",
    "    data['bppm_nb'] = data.apply(lambda x: get_bpps_nb(x['id']), axis=1)\n",
    "    data['adj_struc'] = data.apply(lambda x: get_structure_adj(x['seq_length'], x['structure'], x['sequence']).sum(0), axis=1)\n",
    "    a = np.array(data['seq'].values.tolist())[:,:,newaxis]\n",
    "    b = np.array(data['struc'].values.tolist())[:,:,newaxis]\n",
    "    c = np.array(data['loop'].values.tolist())[:,:,newaxis]\n",
    "    d = np.array(data['adj_struc'].values.tolist())[:,:,newaxis]\n",
    "    f = np.array(data['bppm_max'].values.tolist())[:,:,newaxis]\n",
    "    g = np.array(data['bppm_sum'].values.tolist())[:,:,newaxis]\n",
    "    h = np.array(data['bppm_nb'].values.tolist())[:,:,newaxis] \n",
    "    features_all=np.concatenate((a,b,c,d,f,g,h), axis = 2) \n",
    "    return features_all\n",
    "\n",
    "def preprocess_labels(data):\n",
    "    labels = data[target_cols].copy()\n",
    "    return np.array(labels.values.tolist())\n",
    "\n",
    "def integer_encoder(my_string, alphabet):\n",
    "    data = my_string.lower()\n",
    "    alphabet = alphabet.lower()\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    \n",
    "    # integer encode input data\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "        \n",
    "    return np.array(integer_encoded)\n",
    "\n",
    "def one_hot_encoder(my_string, alphabet):\n",
    "    data = my_string.lower()\n",
    "    alphabet = alphabet.lower()\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    \n",
    "    # integer encode input data\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    \n",
    "    onehot_encoded = list()\n",
    "    \n",
    "    for value in integer_encoded:\n",
    "        letter = [0 for _ in range(len(alphabet))]\n",
    "        letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "        \n",
    "    return np.array(onehot_encoded)\n",
    "\n",
    "def one_hot_encoder_int(integer_encoded):    \n",
    "    onehot_encoded = list()\n",
    "    \n",
    "    for value in integer_encoded:\n",
    "        letter = [0 for _ in range(-1,90)]\n",
    "        letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "        \n",
    "    return np.array(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:08:52.877734Z",
     "iopub.status.busy": "2020-10-06T10:08:52.876966Z",
     "iopub.status.idle": "2020-10-06T10:08:52.880349Z",
     "shell.execute_reply": "2020-10-06T10:08:52.880857Z"
    },
    "papermill": {
     "duration": 0.028523,
     "end_time": "2020-10-06T10:08:52.880972",
     "exception": false,
     "start_time": "2020-10-06T10:08:52.852449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUAACUGGAAUAACCCAUACCAGCAGUUAGAGUUCGCUCUAACAAAAGAAACAACAACAACAAC',\n",
       " '.....((((((.......)))).)).((.....((..((((((....))))))..)).....))....(((((((....))))))).....................',\n",
       " 'EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHHHSSSSSSIISSIIIIISSXXXXSSSSSSSHHHHSSSSSSSEEEEEEEEEEEEEEEEEEEEE')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine features\n",
    "train['sequence'][0], train['structure'][0] ,train['predicted_loop_type'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:08:52.931177Z",
     "iopub.status.busy": "2020-10-06T10:08:52.930215Z",
     "iopub.status.idle": "2020-10-06T10:08:53.008719Z",
     "shell.execute_reply": "2020-10-06T10:08:53.008220Z"
    },
    "papermill": {
     "duration": 0.107196,
     "end_time": "2020-10-06T10:08:53.008835",
     "exception": false,
     "start_time": "2020-10-06T10:08:52.901639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aug_data(df):\n",
    "    target_df = df.copy()\n",
    "    new_df = aug_df[aug_df['id'].isin(target_df['id'])]\n",
    "                         \n",
    "    del target_df['structure']\n",
    "    del target_df['predicted_loop_type']\n",
    "    new_df = new_df.merge(target_df, on=['id','sequence'], how='left')\n",
    "\n",
    "    df['cnt'] = df['id'].map(new_df[['id','cnt']].set_index('id').to_dict()['cnt'])\n",
    "    df['log_gamma'] = 100\n",
    "    df['score'] = 1.0\n",
    "    df = df.append(new_df[df.columns])\n",
    "    return df\n",
    "train = aug_data(train)\n",
    "test = aug_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:08:53.061037Z",
     "iopub.status.busy": "2020-10-06T10:08:53.059982Z",
     "iopub.status.idle": "2020-10-06T10:09:11.326054Z",
     "shell.execute_reply": "2020-10-06T10:09:11.324713Z"
    },
    "papermill": {
     "duration": 18.295927,
     "end_time": "2020-10-06T10:09:11.326208",
     "exception": false,
     "start_time": "2020-10-06T10:08:53.030281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "train_features = preprocess_features(preprocess_data(train))\n",
    "\n",
    "# Prepare labels data\n",
    "train_labels = preprocess_labels(preprocess_data(train)).transpose(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:09:11.374804Z",
     "iopub.status.busy": "2020-10-06T10:09:11.373986Z",
     "iopub.status.idle": "2020-10-06T10:09:11.378084Z",
     "shell.execute_reply": "2020-10-06T10:09:11.378630Z"
    },
    "papermill": {
     "duration": 0.031344,
     "end_time": "2020-10-06T10:09:11.378769",
     "exception": false,
     "start_time": "2020-10-06T10:09:11.347425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4653, 107, 7), (4653, 68, 5))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:09:11.428825Z",
     "iopub.status.busy": "2020-10-06T10:09:11.428061Z",
     "iopub.status.idle": "2020-10-06T10:09:11.431472Z",
     "shell.execute_reply": "2020-10-06T10:09:11.431925Z"
    },
    "papermill": {
     "duration": 0.032191,
     "end_time": "2020-10-06T10:09:11.432055",
     "exception": false,
     "start_time": "2020-10-06T10:09:11.399864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_structures(features: np.ndarray, labels: np.ndarray):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    axes[0].imshow(features.T)\n",
    "    axes[0].set_title(\"Features\")\n",
    "    axes[1].imshow(labels.T)\n",
    "    axes[1].set_title(\"Labels\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:09:11.485142Z",
     "iopub.status.busy": "2020-10-06T10:09:11.477812Z",
     "iopub.status.idle": "2020-10-06T10:09:11.490059Z",
     "shell.execute_reply": "2020-10-06T10:09:11.489567Z"
    },
    "papermill": {
     "duration": 0.036963,
     "end_time": "2020-10-06T10:09:11.490170",
     "exception": false,
     "start_time": "2020-10-06T10:09:11.453207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2    GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...\n",
       " 2    GGAAAAAGGUUGGAAUGCAGCAUCAGGAAUACUGAUGUCAAGUAAC...\n",
       " Name: sequence, dtype: object,\n",
       " 2    .....((((.((.....((((.(((.....)))..((((......)...\n",
       " 2    ................((.(((((((.....)))))))...))......\n",
       " Name: structure, dtype: object,\n",
       " 2    EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...\n",
       " 2    EEEEEEEEEEEEEEEESSISSSSSSSHHHHHSSSSSSSIIISSMMM...\n",
       " Name: predicted_loop_type, dtype: object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine features\n",
    "train['sequence'][2], train['structure'][2] ,train['predicted_loop_type'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:09:11.541018Z",
     "iopub.status.busy": "2020-10-06T10:09:11.540326Z",
     "iopub.status.idle": "2020-10-06T10:09:11.868160Z",
     "shell.execute_reply": "2020-10-06T10:09:11.868731Z"
    },
    "papermill": {
     "duration": 0.35721,
     "end_time": "2020-10-06T10:09:11.868877",
     "exception": false,
     "start_time": "2020-10-06T10:09:11.511667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature = train_features[0:1,:,:]\n",
    "feature = feature[0,:,:]\n",
    "labels = train_labels[0:1,:,:]\n",
    "labels = labels[0,:,:]\n",
    "\n",
    "plot_structures(feature, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:09:11.927292Z",
     "iopub.status.busy": "2020-10-06T10:09:11.926588Z",
     "iopub.status.idle": "2020-10-06T10:09:13.070903Z",
     "shell.execute_reply": "2020-10-06T10:09:13.070286Z"
    },
    "papermill": {
     "duration": 1.174622,
     "end_time": "2020-10-06T10:09:13.071011",
     "exception": false,
     "start_time": "2020-10-06T10:09:11.896389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing ML libraries\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Embedding, LSTM, Dense, Bidirectional, Activation, Flatten, GRU\n",
    "from keras.layers import BatchNormalization, SpatialDropout1D, InputLayer, Reshape, Lambda\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD, Adam, Adadelta, RMSprop\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:09:13.121898Z",
     "iopub.status.busy": "2020-10-06T10:09:13.121046Z",
     "iopub.status.idle": "2020-10-06T10:09:13.123505Z",
     "shell.execute_reply": "2020-10-06T10:09:13.124130Z"
    },
    "papermill": {
     "duration": 0.03064,
     "end_time": "2020-10-06T10:09:13.124262",
     "exception": false,
     "start_time": "2020-10-06T10:09:13.093622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def MCRMSE(y_true, y_pred):\n",
    "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
    "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:09:13.176458Z",
     "iopub.status.busy": "2020-10-06T10:09:13.175462Z",
     "iopub.status.idle": "2020-10-06T10:09:13.177890Z",
     "shell.execute_reply": "2020-10-06T10:09:13.178492Z"
    },
    "papermill": {
     "duration": 0.031381,
     "end_time": "2020-10-06T10:09:13.178624",
     "exception": false,
     "start_time": "2020-10-06T10:09:13.147243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TPU:\n",
    "    # detect and init the TPU\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    \n",
    "    # instantiate a distribution strategy\n",
    "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:09:13.243482Z",
     "iopub.status.busy": "2020-10-06T10:09:13.233024Z",
     "iopub.status.idle": "2020-10-06T10:09:13.257400Z",
     "shell.execute_reply": "2020-10-06T10:09:13.258008Z"
    },
    "papermill": {
     "duration": 0.05688,
     "end_time": "2020-10-06T10:09:13.258172",
     "exception": false,
     "start_time": "2020-10-06T10:09:13.201292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build model functions\n",
    "def gru_layer(hidden_dim, dropout):\n",
    "    return L.Bidirectional(L.GRU(hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer = 'orthogonal'))\n",
    "\n",
    "def lstm_layer(hidden_dim, dropout):\n",
    "    return L.Bidirectional(L.LSTM(hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer = 'orthogonal'))\n",
    "\n",
    "def conv1d_layer(filters, kernel_size):\n",
    "    return L.Conv1D(filters=filters, kernel_size=kernel_size, padding='same')\n",
    "\n",
    "def max_pool_1d(pool_size, strides):\n",
    "    return L.MaxPooling1D(pool_size=pool_size, strides=strides, padding='valid')\n",
    "\n",
    "def build_model(seq_len=107, pred_len=68, dropout1=0.0, dropout2=0.3, embed_dim=230, hidden_dim1=220, hidden_dim2=330, \n",
    "                type=0, filters=255, kernel_size=5):\n",
    "    \n",
    "    inputs = L.Input(shape=(seq_len, train_features.shape[2]))\n",
    "    \n",
    "    # split integer and float features and concatenate them later.\n",
    "    integer_fea_seq = inputs[:, :, :1]\n",
    "    embed_seq = L.Embedding(input_dim=len(alphabet_rna)+1, output_dim=embed_dim)(integer_fea_seq)\n",
    "    reshaped_seq = tf.reshape(embed_seq, shape=(-1, embed_seq.shape[1],  embed_seq.shape[2] * embed_seq.shape[3]))\n",
    "    conv_seq = conv1d_layer(filters, kernel_size)(reshaped_seq)\n",
    "    mpool_seq = max_pool_1d(1,1)(conv_seq)\n",
    "    \n",
    "    integer_fea_struc = inputs[:, :, 1:2]\n",
    "    embed_struc = L.Embedding(input_dim=len(alphabet_struc)+1, output_dim=embed_dim)(integer_fea_struc)\n",
    "    reshaped_struc = tf.reshape(embed_struc, shape=(-1, embed_struc.shape[1],  embed_struc.shape[2] * embed_struc.shape[3]))\n",
    "    conv_struc = conv1d_layer(filters, kernel_size)(reshaped_struc)\n",
    "    mpool_struc = max_pool_1d(1,1)(conv_struc)\n",
    "    \n",
    "    integer_fea_loop = inputs[:, :, 2:3]\n",
    "    embed_loop = L.Embedding(input_dim=len(alphabet_loop)+1, output_dim=embed_dim)(integer_fea_loop)\n",
    "    reshaped_loop = tf.reshape(embed_loop, shape=(-1, embed_loop.shape[1],  embed_loop.shape[2] * embed_loop.shape[3]))\n",
    "    conv_loop = conv1d_layer(filters, kernel_size)(reshaped_loop)\n",
    "    mpool_loop = max_pool_1d(1,1)(conv_loop)\n",
    "    \n",
    "    float_fea = inputs[:, :, 3:]\n",
    "    conv_float = conv1d_layer(filters, kernel_size)(float_fea)\n",
    "    mpool_float = max_pool_1d(1,1)(conv_float)\n",
    "    concat = L.concatenate([mpool_seq, mpool_struc, mpool_loop, mpool_float], axis=2)\n",
    "\n",
    "    if type == 0:\n",
    "        hidden = lstm_layer(hidden_dim1, dropout1)(concat)\n",
    "        hidden = gru_layer(hidden_dim2, dropout2)(hidden)\n",
    "    elif type == 1:\n",
    "        hidden = gru_layer(hidden_dim1, dropout1)(concat)\n",
    "        hidden = gru_layer(hidden_dim2, dropout2)(hidden)    \n",
    "    elif type == 2:\n",
    "        hidden = gru_layer(hidden_dim1, dropout1)(concat)\n",
    "        hidden = lstm_layer(hidden_dim2, dropout2)(hidden)\n",
    "    elif type == 3:\n",
    "        hidden = lstm_layer(hidden_dim1, dropout1)(concat)\n",
    "        hidden = lstm_layer(hidden_dim2, dropout2)(hidden)\n",
    "    \n",
    "    truncated = hidden[:, :pred_len]\n",
    "    out = L.Dense(5, activation='linear')(truncated)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "    model.compile(tf.keras.optimizers.Adam(), loss=MCRMSE)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:09:13.309302Z",
     "iopub.status.busy": "2020-10-06T10:09:13.308484Z",
     "iopub.status.idle": "2020-10-06T10:09:13.311597Z",
     "shell.execute_reply": "2020-10-06T10:09:13.311095Z"
    },
    "papermill": {
     "duration": 0.029932,
     "end_time": "2020-10-06T10:09:13.311701",
     "exception": false,
     "start_time": "2020-10-06T10:09:13.281769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "    train = train[:20]\n",
    "    test = test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:09:13.364308Z",
     "iopub.status.busy": "2020-10-06T10:09:13.363555Z",
     "iopub.status.idle": "2020-10-06T10:09:17.991934Z",
     "shell.execute_reply": "2020-10-06T10:09:17.991238Z"
    },
    "papermill": {
     "duration": 4.655988,
     "end_time": "2020-10-06T10:09:17.992107",
     "exception": false,
     "start_time": "2020-10-06T10:09:13.336119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 107, 7)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 107, 1)]     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 107, 1)]     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 107, 1)]     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 107, 1, 230)  1150        tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 107, 1, 230)  1610        tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 107, 1, 230)  3680        tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 107, 230)]   0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 107, 230)]   0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 107, 230)]   0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 107, 4)]     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 107, 255)     293505      tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 107, 255)     293505      tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 107, 255)     293505      tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 107, 255)     5355        tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 107, 255)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 107, 255)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 107, 255)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 107, 255)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 107, 1020)    0           max_pooling1d[0][0]              \n",
      "                                                                 max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_2[0][0]            \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 107, 440)     2184160     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 107, 660)     1528560     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 68, 660)]    0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 68, 5)        3305        tf_op_layer_strided_slice_4[0][0]\n",
      "==================================================================================================\n",
      "Total params: 4,608,335\n",
      "Trainable params: 4,608,335\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:09:18.052830Z",
     "iopub.status.busy": "2020-10-06T10:09:18.051990Z",
     "iopub.status.idle": "2020-10-06T10:09:49.454991Z",
     "shell.execute_reply": "2020-10-06T10:09:49.456092Z"
    },
    "papermill": {
     "duration": 31.435187,
     "end_time": "2020-10-06T10:09:49.456287",
     "exception": false,
     "start_time": "2020-10-06T10:09:18.021100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "    n_clusters = 20\n",
    "else:\n",
    "    n_clusters = 200\n",
    "\n",
    "kmeans_model = KMeans(n_clusters=n_clusters, random_state=110).fit(preprocess_features(train)[:,:,2])\n",
    "train['cluster_id'] = kmeans_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:09:49.526369Z",
     "iopub.status.busy": "2020-10-06T10:09:49.525604Z",
     "iopub.status.idle": "2020-10-06T10:09:49.545642Z",
     "shell.execute_reply": "2020-10-06T10:09:49.546613Z"
    },
    "papermill": {
     "duration": 0.060992,
     "end_time": "2020-10-06T10:09:49.546763",
     "exception": false,
     "start_time": "2020-10-06T10:09:49.485771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_predict(type = 0, FOLD_N = 5, Ver=1):\n",
    "    \n",
    "    if debug:\n",
    "        FOLD_N = 2\n",
    "    \n",
    "    gkf = GroupKFold(n_splits=FOLD_N)\n",
    "\n",
    "    test_107 = test.query(\"seq_length == 107\").copy()\n",
    "    test_130  = test.query(\"seq_length == 130\").copy()\n",
    "    \n",
    "    inputs_107 = preprocess_features(test_107)\n",
    "    inputs_130 = preprocess_features(test_130)\n",
    "        \n",
    "    holdouts = []\n",
    "    holdout_preds = []\n",
    "\n",
    "    for cv, (train_index, test_index) in enumerate(gkf.split(train,  train['deg_Mg_pH10'], train['cluster_id'])):\n",
    "        \n",
    "        trn = train.iloc[train_index].copy()\n",
    "        X_train = preprocess_features(trn)\n",
    "        y_train = np.array(trn[target_cols].values.tolist()).transpose((0, 2, 1))\n",
    "\n",
    "        val = train.iloc[test_index].copy()\n",
    "        x_val_all = preprocess_features(val)\n",
    "        val = val[val.SN_filter == 1]\n",
    "        X_test = preprocess_features(val)\n",
    "        y_test = np.array(val[target_cols].values.tolist()).transpose((0, 2, 1))\n",
    "        sample_weight = np.log(trn.signal_to_noise+1.1)*2\n",
    "        \n",
    "        if TPU:\n",
    "            with tpu_strategy.scope():\n",
    "                model = build_model(type=type)\n",
    "                model_107 = build_model(seq_len=107, pred_len=107,type=type)\n",
    "                model_130 = build_model(seq_len=130, pred_len=130,type=type)\n",
    "        else:\n",
    "            model = build_model(type=type)\n",
    "            model_107 = build_model(seq_len=107, pred_len=107,type=type)\n",
    "            model_130 = build_model(seq_len=130, pred_len=130,type=type)\n",
    "\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data = (X_test, y_test),\n",
    "            batch_size=64,\n",
    "            epochs=105,\n",
    "            sample_weight=sample_weight,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=7, restore_best_weights=True),\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "                tf.keras.callbacks.ModelCheckpoint(f'model{Ver}_cv{cv}.h5')\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        model.load_weights(f'model{Ver}_cv{cv}.h5')\n",
    "        model_107.load_weights(f'model{Ver}_cv{cv}.h5')\n",
    "        model_130.load_weights(f'model{Ver}_cv{cv}.h5')\n",
    "        \n",
    "        holdouts.append(train.iloc[test_index].copy())\n",
    "        holdout_preds.append(model.predict(x_val_all))\n",
    "        \n",
    "        if cv == 0:\n",
    "            preds_107 = model_107.predict(inputs_107)/FOLD_N\n",
    "            preds_130 = model_130.predict(inputs_130)/FOLD_N\n",
    "        else:\n",
    "            preds_107 += model_107.predict(inputs_107)/FOLD_N\n",
    "            preds_130 += model_130.predict(inputs_130)/FOLD_N\n",
    "    return holdouts, holdout_preds, test_107, preds_107, test_130, preds_130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:09:49.616773Z",
     "iopub.status.busy": "2020-10-06T10:09:49.616056Z",
     "iopub.status.idle": "2020-10-06T15:16:39.211530Z",
     "shell.execute_reply": "2020-10-06T15:16:39.209538Z"
    },
    "papermill": {
     "duration": 18409.636037,
     "end_time": "2020-10-06T15:16:39.211667",
     "exception": false,
     "start_time": "2020-10-06T10:09:49.575630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/105\n",
      "89/89 [==============================] - 10s 114ms/step - loss: 1.2002 - val_loss: 0.3022\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.9743 - val_loss: 0.2647\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.8831 - val_loss: 0.2469\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.8128 - val_loss: 0.2313\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.7686 - val_loss: 0.2230\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.7366 - val_loss: 0.2136\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.7075 - val_loss: 0.2071\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.6843 - val_loss: 0.2011\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.6628 - val_loss: 0.1960\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.6386 - val_loss: 0.1912\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.6217 - val_loss: 0.1872\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.6043 - val_loss: 0.1835\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.5882 - val_loss: 0.1777\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5741 - val_loss: 0.1744\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5585 - val_loss: 0.1698\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5503 - val_loss: 0.1695\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.5391 - val_loss: 0.1662\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5263 - val_loss: 0.1645\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5181 - val_loss: 0.1605\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.5095 - val_loss: 0.1580\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5031 - val_loss: 0.1571\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4950 - val_loss: 0.1544\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4860 - val_loss: 0.1531\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4794 - val_loss: 0.1515\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4747 - val_loss: 0.1507\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4695 - val_loss: 0.1476\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.4612 - val_loss: 0.1454\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4573 - val_loss: 0.1445\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4535 - val_loss: 0.1429\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4488 - val_loss: 0.1421\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4434 - val_loss: 0.1417\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4394 - val_loss: 0.1406\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4362 - val_loss: 0.1398\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 0.4323 - val_loss: 0.1375\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4297 - val_loss: 0.1370\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4254 - val_loss: 0.1356\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.4227 - val_loss: 0.1355\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4196 - val_loss: 0.1350\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4154 - val_loss: 0.1331\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4140 - val_loss: 0.1328\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.4105 - val_loss: 0.1323\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4073 - val_loss: 0.1305\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4046 - val_loss: 0.1304\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4021 - val_loss: 0.1303\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4001 - val_loss: 0.1290\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3983 - val_loss: 0.1297\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3954 - val_loss: 0.1277\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3929 - val_loss: 0.1274\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3915 - val_loss: 0.1263\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3888 - val_loss: 0.1259\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3885 - val_loss: 0.1263\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3860 - val_loss: 0.1244\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3828 - val_loss: 0.1253\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3813 - val_loss: 0.1242\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3801 - val_loss: 0.1235\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3782 - val_loss: 0.1229\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3755 - val_loss: 0.1218\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3739 - val_loss: 0.1214\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3741 - val_loss: 0.1220\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3714 - val_loss: 0.1217\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3710 - val_loss: 0.1197\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.3691 - val_loss: 0.1199\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3661 - val_loss: 0.1192\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3653 - val_loss: 0.1198\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3643 - val_loss: 0.1188\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3617 - val_loss: 0.1177\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3613 - val_loss: 0.1180\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3605 - val_loss: 0.1174\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.3583 - val_loss: 0.1172\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3580 - val_loss: 0.1166\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3562 - val_loss: 0.1171\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3557 - val_loss: 0.1165\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3551 - val_loss: 0.1150\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3532 - val_loss: 0.1145\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3513 - val_loss: 0.1146\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3508 - val_loss: 0.1145\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3498 - val_loss: 0.1139\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3484 - val_loss: 0.1147\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3476 - val_loss: 0.1138\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3471 - val_loss: 0.1135\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3457 - val_loss: 0.1126\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3436 - val_loss: 0.1122\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3432 - val_loss: 0.1136\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3425 - val_loss: 0.1122\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3423 - val_loss: 0.1124\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3396 - val_loss: 0.1113\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3397 - val_loss: 0.1116\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3397 - val_loss: 0.1116\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3378 - val_loss: 0.1106\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3369 - val_loss: 0.1103\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3366 - val_loss: 0.1101\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3351 - val_loss: 0.1104\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3340 - val_loss: 0.1092\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3348 - val_loss: 0.1093\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3336 - val_loss: 0.1096\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3324 - val_loss: 0.1098\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.3311 - val_loss: 0.1090\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3294 - val_loss: 0.1083\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3288 - val_loss: 0.1082\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3288 - val_loss: 0.1076\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3272 - val_loss: 0.1084\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3279 - val_loss: 0.1083\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3272 - val_loss: 0.1074\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3251 - val_loss: 0.1069\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3250 - val_loss: 0.1088\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 10s 108ms/step - loss: 1.1887 - val_loss: 0.2999\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.9648 - val_loss: 0.2758\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.8770 - val_loss: 0.2502\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.8053 - val_loss: 0.2360\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.7595 - val_loss: 0.2339\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.7290 - val_loss: 0.2228\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.6995 - val_loss: 0.2165\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.6745 - val_loss: 0.2156\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.6529 - val_loss: 0.2052\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.6292 - val_loss: 0.2017\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.6113 - val_loss: 0.1964\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5945 - val_loss: 0.1925\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.5795 - val_loss: 0.1912\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5657 - val_loss: 0.1848\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5518 - val_loss: 0.1828\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5397 - val_loss: 0.1783\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5278 - val_loss: 0.1773\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.5204 - val_loss: 0.1755\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.5127 - val_loss: 0.1710\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5027 - val_loss: 0.1702\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.4944 - val_loss: 0.1670\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4865 - val_loss: 0.1667\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4806 - val_loss: 0.1647\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4733 - val_loss: 0.1611\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4670 - val_loss: 0.1612\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4621 - val_loss: 0.1580\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4569 - val_loss: 0.1578\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.4532 - val_loss: 0.1558\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.4469 - val_loss: 0.1529\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4430 - val_loss: 0.1534\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4379 - val_loss: 0.1509\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4348 - val_loss: 0.1507\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.4298 - val_loss: 0.1483\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4265 - val_loss: 0.1480\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4223 - val_loss: 0.1457\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4200 - val_loss: 0.1450\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4178 - val_loss: 0.1449\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4148 - val_loss: 0.1442\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4110 - val_loss: 0.1431\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4064 - val_loss: 0.1425\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4052 - val_loss: 0.1401\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 0.4013 - val_loss: 0.1405\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3996 - val_loss: 0.1396\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3982 - val_loss: 0.1382\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3956 - val_loss: 0.1369\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3926 - val_loss: 0.1370\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3900 - val_loss: 0.1360\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3891 - val_loss: 0.1389\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3873 - val_loss: 0.1350\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3836 - val_loss: 0.1341\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3816 - val_loss: 0.1343\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3812 - val_loss: 0.1332\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3785 - val_loss: 0.1319\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3761 - val_loss: 0.1314\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3732 - val_loss: 0.1305\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3732 - val_loss: 0.1308\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3709 - val_loss: 0.1307\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3683 - val_loss: 0.1290\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3668 - val_loss: 0.1300\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3661 - val_loss: 0.1288\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3644 - val_loss: 0.1279\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3634 - val_loss: 0.1277\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3623 - val_loss: 0.1277\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3613 - val_loss: 0.1267\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3589 - val_loss: 0.1263\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3571 - val_loss: 0.1266\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3561 - val_loss: 0.1263\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3559 - val_loss: 0.1266\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3542 - val_loss: 0.1253\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3523 - val_loss: 0.1255\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3518 - val_loss: 0.1255\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3506 - val_loss: 0.1234\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3487 - val_loss: 0.1236\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3481 - val_loss: 0.1232\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3481 - val_loss: 0.1231\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3461 - val_loss: 0.1224\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3442 - val_loss: 0.1223\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3441 - val_loss: 0.1222\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3422 - val_loss: 0.1225\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3423 - val_loss: 0.1219\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3406 - val_loss: 0.1207\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3391 - val_loss: 0.1212\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3392 - val_loss: 0.1203\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3381 - val_loss: 0.1202\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3377 - val_loss: 0.1198\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3365 - val_loss: 0.1191\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3352 - val_loss: 0.1189\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3342 - val_loss: 0.1183\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3323 - val_loss: 0.1187\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3326 - val_loss: 0.1197\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3324 - val_loss: 0.1176\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3309 - val_loss: 0.1174\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3292 - val_loss: 0.1174\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3287 - val_loss: 0.1169\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3283 - val_loss: 0.1176\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3269 - val_loss: 0.1164\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3260 - val_loss: 0.1170\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3257 - val_loss: 0.1160\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3262 - val_loss: 0.1162\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3244 - val_loss: 0.1157\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3231 - val_loss: 0.1157\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3221 - val_loss: 0.1149\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3225 - val_loss: 0.1148\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3204 - val_loss: 0.1139\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3199 - val_loss: 0.1144\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 10s 111ms/step - loss: 1.1777 - val_loss: 0.2924\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.9627 - val_loss: 0.2657\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.8682 - val_loss: 0.2492\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.8037 - val_loss: 0.2284\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.7547 - val_loss: 0.2172\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.7216 - val_loss: 0.2105\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.6935 - val_loss: 0.2049\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 9s 103ms/step - loss: 0.6684 - val_loss: 0.1998\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.6441 - val_loss: 0.1936\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.6246 - val_loss: 0.1911\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.6059 - val_loss: 0.1859\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.5908 - val_loss: 0.1840\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.5733 - val_loss: 0.1803\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5612 - val_loss: 0.1764\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5494 - val_loss: 0.1742\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 0.5386 - val_loss: 0.1719\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5286 - val_loss: 0.1680\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.5188 - val_loss: 0.1669\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.5099 - val_loss: 0.1640\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.5014 - val_loss: 0.1625\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4950 - val_loss: 0.1627\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4867 - val_loss: 0.1589\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4800 - val_loss: 0.1570\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.4722 - val_loss: 0.1549\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.4668 - val_loss: 0.1533\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4627 - val_loss: 0.1538\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4570 - val_loss: 0.1520\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4548 - val_loss: 0.1505\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.4472 - val_loss: 0.1504\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4436 - val_loss: 0.1474\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4395 - val_loss: 0.1475\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4352 - val_loss: 0.1447\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.4309 - val_loss: 0.1444\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4272 - val_loss: 0.1427\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4239 - val_loss: 0.1431\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4211 - val_loss: 0.1409\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4186 - val_loss: 0.1411\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4147 - val_loss: 0.1398\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4125 - val_loss: 0.1387\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4101 - val_loss: 0.1375\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.4054 - val_loss: 0.1373\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4033 - val_loss: 0.1362\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4014 - val_loss: 0.1354\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3987 - val_loss: 0.1339\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3958 - val_loss: 0.1334\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3946 - val_loss: 0.1338\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3912 - val_loss: 0.1340\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3896 - val_loss: 0.1316\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3873 - val_loss: 0.1313\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3863 - val_loss: 0.1330\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3847 - val_loss: 0.1310\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3824 - val_loss: 0.1294\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3807 - val_loss: 0.1295\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3780 - val_loss: 0.1283\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3761 - val_loss: 0.1279\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3756 - val_loss: 0.1285\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3739 - val_loss: 0.1274\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 9s 100ms/step - loss: 0.3733 - val_loss: 0.1269\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3706 - val_loss: 0.1263\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3686 - val_loss: 0.1259\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3668 - val_loss: 0.1252\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3657 - val_loss: 0.1252\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3644 - val_loss: 0.1258\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3636 - val_loss: 0.1262\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3618 - val_loss: 0.1242\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3610 - val_loss: 0.1241\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3580 - val_loss: 0.1231\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3573 - val_loss: 0.1230\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3567 - val_loss: 0.1229\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3542 - val_loss: 0.1229\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3534 - val_loss: 0.1220\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3527 - val_loss: 0.1231\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3522 - val_loss: 0.1210\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3510 - val_loss: 0.1208\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3499 - val_loss: 0.1206\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3487 - val_loss: 0.1203\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3472 - val_loss: 0.1201\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3453 - val_loss: 0.1199\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3448 - val_loss: 0.1195\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3433 - val_loss: 0.1187\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3415 - val_loss: 0.1187\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3417 - val_loss: 0.1189\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3413 - val_loss: 0.1181\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3411 - val_loss: 0.1181\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3388 - val_loss: 0.1183\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3381 - val_loss: 0.1190\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3367 - val_loss: 0.1173\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3355 - val_loss: 0.1175\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 96ms/step - loss: 0.3349 - val_loss: 0.1165\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3342 - val_loss: 0.1167\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3339 - val_loss: 0.1164\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3336 - val_loss: 0.1169\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.3320 - val_loss: 0.1159\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3315 - val_loss: 0.1174\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3309 - val_loss: 0.1153\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3287 - val_loss: 0.1155\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3285 - val_loss: 0.1153\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3275 - val_loss: 0.1152\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3275 - val_loss: 0.1146\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3260 - val_loss: 0.1146\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3271 - val_loss: 0.1146\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3251 - val_loss: 0.1145\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3244 - val_loss: 0.1136\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3226 - val_loss: 0.1138\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3234 - val_loss: 0.1142\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 10s 107ms/step - loss: 1.1839 - val_loss: 0.2958\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.9630 - val_loss: 0.2703\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.8844 - val_loss: 0.2460\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.8262 - val_loss: 0.2322\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.7766 - val_loss: 0.2267\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.7389 - val_loss: 0.2165\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.7056 - val_loss: 0.2101\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.6781 - val_loss: 0.2015\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.6537 - val_loss: 0.1984\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.6362 - val_loss: 0.1948\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.6154 - val_loss: 0.1887\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.5959 - val_loss: 0.1840\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.5836 - val_loss: 0.1805\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5688 - val_loss: 0.1769\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.5538 - val_loss: 0.1729\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.5416 - val_loss: 0.1691\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.5315 - val_loss: 0.1662\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.5229 - val_loss: 0.1651\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.5127 - val_loss: 0.1614\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.5048 - val_loss: 0.1598\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4966 - val_loss: 0.1574\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4904 - val_loss: 0.1561\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4826 - val_loss: 0.1547\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4759 - val_loss: 0.1515\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.4696 - val_loss: 0.1502\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4653 - val_loss: 0.1484\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4586 - val_loss: 0.1468\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4547 - val_loss: 0.1461\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4507 - val_loss: 0.1459\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4454 - val_loss: 0.1428\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4404 - val_loss: 0.1425\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4358 - val_loss: 0.1408\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4319 - val_loss: 0.1394\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4291 - val_loss: 0.1392\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4261 - val_loss: 0.1370\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4216 - val_loss: 0.1373\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4192 - val_loss: 0.1364\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4159 - val_loss: 0.1348\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4130 - val_loss: 0.1335\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4099 - val_loss: 0.1327\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.4083 - val_loss: 0.1327\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4040 - val_loss: 0.1306\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4032 - val_loss: 0.1304\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3995 - val_loss: 0.1301\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3971 - val_loss: 0.1295\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3957 - val_loss: 0.1280\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3936 - val_loss: 0.1286\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3901 - val_loss: 0.1271\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3880 - val_loss: 0.1257\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3871 - val_loss: 0.1268\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3850 - val_loss: 0.1251\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3826 - val_loss: 0.1240\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3808 - val_loss: 0.1240\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3788 - val_loss: 0.1240\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3756 - val_loss: 0.1231\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3758 - val_loss: 0.1225\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3723 - val_loss: 0.1223\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3712 - val_loss: 0.1217\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3719 - val_loss: 0.1209\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3692 - val_loss: 0.1206\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3681 - val_loss: 0.1224\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3667 - val_loss: 0.1195\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3645 - val_loss: 0.1196\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3621 - val_loss: 0.1192\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3628 - val_loss: 0.1196\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3616 - val_loss: 0.1181\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3592 - val_loss: 0.1172\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3573 - val_loss: 0.1164\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3561 - val_loss: 0.1167\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3554 - val_loss: 0.1163\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3544 - val_loss: 0.1159\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3538 - val_loss: 0.1153\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3515 - val_loss: 0.1152\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 9s 100ms/step - loss: 0.3497 - val_loss: 0.1145\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3493 - val_loss: 0.1141\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3479 - val_loss: 0.1140\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3462 - val_loss: 0.1131\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3456 - val_loss: 0.1137\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3456 - val_loss: 0.1141\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3441 - val_loss: 0.1122\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3426 - val_loss: 0.1129\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3428 - val_loss: 0.1114\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3412 - val_loss: 0.1115\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3407 - val_loss: 0.1127\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3388 - val_loss: 0.1105\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3377 - val_loss: 0.1108\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3370 - val_loss: 0.1117\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3372 - val_loss: 0.1105\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3352 - val_loss: 0.1104\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3347 - val_loss: 0.1095\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3333 - val_loss: 0.1093\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3327 - val_loss: 0.1090\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3317 - val_loss: 0.1091\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3322 - val_loss: 0.1091\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3293 - val_loss: 0.1081\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3297 - val_loss: 0.1099\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3305 - val_loss: 0.1083\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3282 - val_loss: 0.1077\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3280 - val_loss: 0.1078\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3269 - val_loss: 0.1072\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3259 - val_loss: 0.1073\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3243 - val_loss: 0.1069\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3237 - val_loss: 0.1066\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3223 - val_loss: 0.1063\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3222 - val_loss: 0.1067\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 9s 107ms/step - loss: 1.1942 - val_loss: 0.2867\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.9661 - val_loss: 0.2595\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.8753 - val_loss: 0.2396\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.8111 - val_loss: 0.2306\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.7672 - val_loss: 0.2193\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.7365 - val_loss: 0.2125\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.7083 - val_loss: 0.2046\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.6783 - val_loss: 0.1988\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.6546 - val_loss: 0.1964\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.6346 - val_loss: 0.1911\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.6127 - val_loss: 0.1860\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 9s 105ms/step - loss: 0.5969 - val_loss: 0.1840\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5803 - val_loss: 0.1830\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.5654 - val_loss: 0.1782\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.5515 - val_loss: 0.1752\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.5402 - val_loss: 0.1743\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.5267 - val_loss: 0.1722\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.5193 - val_loss: 0.1704\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.5097 - val_loss: 0.1710\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.5028 - val_loss: 0.1669\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4927 - val_loss: 0.1654\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4862 - val_loss: 0.1650\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4784 - val_loss: 0.1636\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4709 - val_loss: 0.1623\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4659 - val_loss: 0.1603\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4604 - val_loss: 0.1595\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.4543 - val_loss: 0.1578\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.4507 - val_loss: 0.1588\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4463 - val_loss: 0.1556\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4402 - val_loss: 0.1550\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4378 - val_loss: 0.1533\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4307 - val_loss: 0.1534\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4286 - val_loss: 0.1530\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4253 - val_loss: 0.1512\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4204 - val_loss: 0.1503\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4182 - val_loss: 0.1508\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4133 - val_loss: 0.1500\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4100 - val_loss: 0.1492\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4073 - val_loss: 0.1485\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.4044 - val_loss: 0.1476\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4050 - val_loss: 0.1462\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3999 - val_loss: 0.1451\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3962 - val_loss: 0.1466\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3960 - val_loss: 0.1454\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3929 - val_loss: 0.1444\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3900 - val_loss: 0.1441\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3876 - val_loss: 0.1430\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3865 - val_loss: 0.1429\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3834 - val_loss: 0.1419\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3807 - val_loss: 0.1411\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3794 - val_loss: 0.1416\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3784 - val_loss: 0.1404\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3751 - val_loss: 0.1398\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3730 - val_loss: 0.1396\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3721 - val_loss: 0.1395\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3713 - val_loss: 0.1400\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3685 - val_loss: 0.1383\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3667 - val_loss: 0.1386\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3655 - val_loss: 0.1384\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3642 - val_loss: 0.1378\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 0.3618 - val_loss: 0.1368\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.3599 - val_loss: 0.1366\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3588 - val_loss: 0.1362\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3587 - val_loss: 0.1372\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3565 - val_loss: 0.1369\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3555 - val_loss: 0.1357\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3538 - val_loss: 0.1358\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3511 - val_loss: 0.1361\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3522 - val_loss: 0.1349\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3501 - val_loss: 0.1338\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3488 - val_loss: 0.1335\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3467 - val_loss: 0.1334\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3458 - val_loss: 0.1337\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3448 - val_loss: 0.1329\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3445 - val_loss: 0.1326\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3425 - val_loss: 0.1323\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3410 - val_loss: 0.1325\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3409 - val_loss: 0.1328\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3390 - val_loss: 0.1314\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3382 - val_loss: 0.1317\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3383 - val_loss: 0.1314\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3358 - val_loss: 0.1302\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3354 - val_loss: 0.1307\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3353 - val_loss: 0.1315\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3346 - val_loss: 0.1321\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3324 - val_loss: 0.1303\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3317 - val_loss: 0.1299\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3302 - val_loss: 0.1290\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3293 - val_loss: 0.1289\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3290 - val_loss: 0.1296\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3284 - val_loss: 0.1296\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3266 - val_loss: 0.1291\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3258 - val_loss: 0.1291\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3255 - val_loss: 0.1287\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.3245 - val_loss: 0.1283\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 9s 100ms/step - loss: 0.3246 - val_loss: 0.1285\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3234 - val_loss: 0.1281\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3220 - val_loss: 0.1276\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3211 - val_loss: 0.1276\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3207 - val_loss: 0.1283\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3205 - val_loss: 0.1273\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3207 - val_loss: 0.1272\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3181 - val_loss: 0.1269\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3177 - val_loss: 0.1265\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3167 - val_loss: 0.1257\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 11s 122ms/step - loss: 1.1862 - val_loss: 0.3069\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.9703 - val_loss: 0.2599\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.8636 - val_loss: 0.2429\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.8021 - val_loss: 0.2290\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.7642 - val_loss: 0.2217\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.7314 - val_loss: 0.2139\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.7046 - val_loss: 0.2070\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.6808 - val_loss: 0.2000\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6573 - val_loss: 0.1954\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.6407 - val_loss: 0.1895\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.6182 - val_loss: 0.1872\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.6020 - val_loss: 0.1814\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5860 - val_loss: 0.1791\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.5717 - val_loss: 0.1745\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5600 - val_loss: 0.1717\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5512 - val_loss: 0.1698\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.5374 - val_loss: 0.1673\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.5291 - val_loss: 0.1632\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.5194 - val_loss: 0.1619\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.5116 - val_loss: 0.1598\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5062 - val_loss: 0.1621\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4982 - val_loss: 0.1552\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4897 - val_loss: 0.1542\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4844 - val_loss: 0.1515\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4769 - val_loss: 0.1508\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4747 - val_loss: 0.1494\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4660 - val_loss: 0.1463\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4609 - val_loss: 0.1458\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4569 - val_loss: 0.1448\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4542 - val_loss: 0.1434\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4494 - val_loss: 0.1427\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4456 - val_loss: 0.1409\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4408 - val_loss: 0.1402\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4377 - val_loss: 0.1390\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4342 - val_loss: 0.1384\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4329 - val_loss: 0.1377\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4290 - val_loss: 0.1372\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4248 - val_loss: 0.1357\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4224 - val_loss: 0.1345\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4188 - val_loss: 0.1347\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4161 - val_loss: 0.1337\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4146 - val_loss: 0.1334\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4111 - val_loss: 0.1333\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4091 - val_loss: 0.1306\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4068 - val_loss: 0.1302\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4051 - val_loss: 0.1309\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4030 - val_loss: 0.1298\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4009 - val_loss: 0.1277\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4000 - val_loss: 0.1292\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3982 - val_loss: 0.1270\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3947 - val_loss: 0.1259\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3926 - val_loss: 0.1255\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 0.3912 - val_loss: 0.1255\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3886 - val_loss: 0.1274\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3872 - val_loss: 0.1237\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3862 - val_loss: 0.1240\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3837 - val_loss: 0.1235\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3826 - val_loss: 0.1243\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3809 - val_loss: 0.1227\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3790 - val_loss: 0.1223\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3774 - val_loss: 0.1214\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3767 - val_loss: 0.1218\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3745 - val_loss: 0.1215\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3732 - val_loss: 0.1205\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3718 - val_loss: 0.1202\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3710 - val_loss: 0.1196\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3699 - val_loss: 0.1192\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3686 - val_loss: 0.1186\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3676 - val_loss: 0.1192\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3692 - val_loss: 0.1196\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3655 - val_loss: 0.1179\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3641 - val_loss: 0.1180\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3636 - val_loss: 0.1186\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3616 - val_loss: 0.1173\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3605 - val_loss: 0.1166\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3588 - val_loss: 0.1160\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3584 - val_loss: 0.1160\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3571 - val_loss: 0.1152\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3565 - val_loss: 0.1154\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3546 - val_loss: 0.1147\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3536 - val_loss: 0.1154\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3525 - val_loss: 0.1152\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3518 - val_loss: 0.1146\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3510 - val_loss: 0.1141\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3506 - val_loss: 0.1136\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3493 - val_loss: 0.1132\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3487 - val_loss: 0.1138\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3472 - val_loss: 0.1141\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3464 - val_loss: 0.1126\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3463 - val_loss: 0.1125\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3443 - val_loss: 0.1124\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3440 - val_loss: 0.1121\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3424 - val_loss: 0.1126\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3422 - val_loss: 0.1118\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3420 - val_loss: 0.1109\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3412 - val_loss: 0.1108\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3390 - val_loss: 0.1117\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3393 - val_loss: 0.1103\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3386 - val_loss: 0.1099\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3390 - val_loss: 0.1099\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3362 - val_loss: 0.1101\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3360 - val_loss: 0.1091\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3342 - val_loss: 0.1084\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3348 - val_loss: 0.1089\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3336 - val_loss: 0.1087\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 10s 115ms/step - loss: 1.1864 - val_loss: 0.3002\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.9582 - val_loss: 0.2735\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.8667 - val_loss: 0.2565\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.8034 - val_loss: 0.2363\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.7580 - val_loss: 0.2286\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.7252 - val_loss: 0.2239\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6994 - val_loss: 0.2154\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6745 - val_loss: 0.2104\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.6486 - val_loss: 0.2057\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.6302 - val_loss: 0.2018\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.6107 - val_loss: 0.1973\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5950 - val_loss: 0.1940\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5795 - val_loss: 0.1897\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.5665 - val_loss: 0.1859\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.5529 - val_loss: 0.1827\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5423 - val_loss: 0.1805\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5355 - val_loss: 0.1770\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.5209 - val_loss: 0.1741\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.5148 - val_loss: 0.1726\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5060 - val_loss: 0.1699\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4958 - val_loss: 0.1690\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4901 - val_loss: 0.1671\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4846 - val_loss: 0.1656\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4786 - val_loss: 0.1637\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4720 - val_loss: 0.1630\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4686 - val_loss: 0.1610\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4647 - val_loss: 0.1595\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4603 - val_loss: 0.1588\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4510 - val_loss: 0.1559\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4484 - val_loss: 0.1556\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4446 - val_loss: 0.1545\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4404 - val_loss: 0.1525\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4363 - val_loss: 0.1521\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4321 - val_loss: 0.1501\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4295 - val_loss: 0.1497\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4271 - val_loss: 0.1492\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4241 - val_loss: 0.1473\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4205 - val_loss: 0.1474\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4167 - val_loss: 0.1445\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4126 - val_loss: 0.1441\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4116 - val_loss: 0.1438\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4085 - val_loss: 0.1429\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4070 - val_loss: 0.1425\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4040 - val_loss: 0.1410\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4025 - val_loss: 0.1414\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3999 - val_loss: 0.1398\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3967 - val_loss: 0.1389\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3954 - val_loss: 0.1380\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3924 - val_loss: 0.1371\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3906 - val_loss: 0.1359\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3884 - val_loss: 0.1367\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3874 - val_loss: 0.1359\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3850 - val_loss: 0.1354\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3834 - val_loss: 0.1351\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3809 - val_loss: 0.1336\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3799 - val_loss: 0.1342\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3788 - val_loss: 0.1338\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3766 - val_loss: 0.1329\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3757 - val_loss: 0.1326\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3736 - val_loss: 0.1318\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3730 - val_loss: 0.1304\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3699 - val_loss: 0.1317\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3703 - val_loss: 0.1317\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3689 - val_loss: 0.1296\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3691 - val_loss: 0.1309\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3662 - val_loss: 0.1287\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3641 - val_loss: 0.1292\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3637 - val_loss: 0.1283\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3601 - val_loss: 0.1272\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3598 - val_loss: 0.1282\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3597 - val_loss: 0.1274\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3584 - val_loss: 0.1269\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3574 - val_loss: 0.1272\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3552 - val_loss: 0.1264\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3547 - val_loss: 0.1269\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3534 - val_loss: 0.1261\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3520 - val_loss: 0.1243\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3508 - val_loss: 0.1256\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3512 - val_loss: 0.1250\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3498 - val_loss: 0.1255\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3494 - val_loss: 0.1237\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3464 - val_loss: 0.1230\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3456 - val_loss: 0.1233\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3452 - val_loss: 0.1223\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3455 - val_loss: 0.1220\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3457 - val_loss: 0.1233\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3440 - val_loss: 0.1232\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3417 - val_loss: 0.1217\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3397 - val_loss: 0.1214\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3394 - val_loss: 0.1225\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3400 - val_loss: 0.1220\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3380 - val_loss: 0.1205\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3366 - val_loss: 0.1208\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3366 - val_loss: 0.1201\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3366 - val_loss: 0.1218\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3352 - val_loss: 0.1198\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3341 - val_loss: 0.1205\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3343 - val_loss: 0.1203\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3340 - val_loss: 0.1186\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3320 - val_loss: 0.1188\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3318 - val_loss: 0.1206\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3310 - val_loss: 0.1188\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3309 - val_loss: 0.1197\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3285 - val_loss: 0.1182\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3280 - val_loss: 0.1184\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 10s 114ms/step - loss: 1.1750 - val_loss: 0.2917\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.9555 - val_loss: 0.2603\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.8543 - val_loss: 0.2384\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.7909 - val_loss: 0.2315\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.7508 - val_loss: 0.2144\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.7195 - val_loss: 0.2126\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6913 - val_loss: 0.2049\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6671 - val_loss: 0.2027\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6462 - val_loss: 0.1972\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6250 - val_loss: 0.1935\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.6082 - val_loss: 0.1870\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5919 - val_loss: 0.1838\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5781 - val_loss: 0.1835\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5644 - val_loss: 0.1781\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5513 - val_loss: 0.1776\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5407 - val_loss: 0.1729\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5304 - val_loss: 0.1697\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.5220 - val_loss: 0.1680\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5145 - val_loss: 0.1662\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5046 - val_loss: 0.1640\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4968 - val_loss: 0.1628\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.4907 - val_loss: 0.1605\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4857 - val_loss: 0.1585\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4773 - val_loss: 0.1577\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4733 - val_loss: 0.1555\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4692 - val_loss: 0.1538\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4607 - val_loss: 0.1541\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4579 - val_loss: 0.1514\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4538 - val_loss: 0.1508\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4487 - val_loss: 0.1498\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4451 - val_loss: 0.1511\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4422 - val_loss: 0.1515\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4365 - val_loss: 0.1464\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4337 - val_loss: 0.1455\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4313 - val_loss: 0.1449\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4262 - val_loss: 0.1437\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4256 - val_loss: 0.1422\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4204 - val_loss: 0.1418\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4179 - val_loss: 0.1404\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4154 - val_loss: 0.1407\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4135 - val_loss: 0.1395\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4089 - val_loss: 0.1385\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4075 - val_loss: 0.1389\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4052 - val_loss: 0.1379\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4025 - val_loss: 0.1369\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4031 - val_loss: 0.1373\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3994 - val_loss: 0.1365\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3963 - val_loss: 0.1362\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3943 - val_loss: 0.1345\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3920 - val_loss: 0.1344\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3914 - val_loss: 0.1339\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3899 - val_loss: 0.1327\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3872 - val_loss: 0.1333\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3872 - val_loss: 0.1328\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3843 - val_loss: 0.1327\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3830 - val_loss: 0.1314\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3811 - val_loss: 0.1306\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3781 - val_loss: 0.1295\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.3781 - val_loss: 0.1306\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3787 - val_loss: 0.1308\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3736 - val_loss: 0.1291\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3718 - val_loss: 0.1287\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3715 - val_loss: 0.1282\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3705 - val_loss: 0.1270\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3676 - val_loss: 0.1272\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3671 - val_loss: 0.1271\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3658 - val_loss: 0.1270\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3651 - val_loss: 0.1276\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3635 - val_loss: 0.1258\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3635 - val_loss: 0.1259\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3609 - val_loss: 0.1260\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3600 - val_loss: 0.1239\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3590 - val_loss: 0.1235\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3582 - val_loss: 0.1245\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3565 - val_loss: 0.1240\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3557 - val_loss: 0.1239\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3552 - val_loss: 0.1236\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3543 - val_loss: 0.1230\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3523 - val_loss: 0.1229\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3516 - val_loss: 0.1223\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3512 - val_loss: 0.1220\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3501 - val_loss: 0.1233\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3500 - val_loss: 0.1225\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3479 - val_loss: 0.1219\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3482 - val_loss: 0.1221\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3473 - val_loss: 0.1211\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3446 - val_loss: 0.1207\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3436 - val_loss: 0.1210\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3427 - val_loss: 0.1193\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3415 - val_loss: 0.1205\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3418 - val_loss: 0.1191\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3404 - val_loss: 0.1203\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3403 - val_loss: 0.1202\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3399 - val_loss: 0.1188\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3402 - val_loss: 0.1191\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3374 - val_loss: 0.1185\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3363 - val_loss: 0.1182\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3352 - val_loss: 0.1175\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3356 - val_loss: 0.1175\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3328 - val_loss: 0.1170\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3339 - val_loss: 0.1174\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3325 - val_loss: 0.1170\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3324 - val_loss: 0.1173\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3324 - val_loss: 0.1171\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3309 - val_loss: 0.1171\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 9s 102ms/step - loss: 1.1734 - val_loss: 0.2986\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.9544 - val_loss: 0.2634\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.8632 - val_loss: 0.2400\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.8083 - val_loss: 0.2292\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.7666 - val_loss: 0.2240\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.7317 - val_loss: 0.2135\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.6992 - val_loss: 0.2067\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.6741 - val_loss: 0.2033\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.6511 - val_loss: 0.1956\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.6311 - val_loss: 0.1936\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.6127 - val_loss: 0.1873\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5958 - val_loss: 0.1838\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.5796 - val_loss: 0.1804\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.5658 - val_loss: 0.1751\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.5539 - val_loss: 0.1730\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.5428 - val_loss: 0.1710\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5324 - val_loss: 0.1662\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.5239 - val_loss: 0.1653\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.5123 - val_loss: 0.1618\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.5043 - val_loss: 0.1602\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4975 - val_loss: 0.1571\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4894 - val_loss: 0.1551\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4832 - val_loss: 0.1540\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4766 - val_loss: 0.1526\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4712 - val_loss: 0.1520\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4672 - val_loss: 0.1489\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4606 - val_loss: 0.1475\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4582 - val_loss: 0.1473\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4511 - val_loss: 0.1463\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4487 - val_loss: 0.1447\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4431 - val_loss: 0.1434\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4394 - val_loss: 0.1421\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4358 - val_loss: 0.1409\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4321 - val_loss: 0.1398\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4298 - val_loss: 0.1399\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4259 - val_loss: 0.1382\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4244 - val_loss: 0.1367\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4198 - val_loss: 0.1349\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4171 - val_loss: 0.1352\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4136 - val_loss: 0.1339\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4132 - val_loss: 0.1334\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4090 - val_loss: 0.1325\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4055 - val_loss: 0.1326\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4036 - val_loss: 0.1329\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4021 - val_loss: 0.1297\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3999 - val_loss: 0.1306\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3973 - val_loss: 0.1289\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3944 - val_loss: 0.1288\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3935 - val_loss: 0.1275\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3917 - val_loss: 0.1286\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.3904 - val_loss: 0.1268\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3875 - val_loss: 0.1276\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3853 - val_loss: 0.1265\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3832 - val_loss: 0.1248\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3819 - val_loss: 0.1258\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3823 - val_loss: 0.1236\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3793 - val_loss: 0.1247\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3769 - val_loss: 0.1230\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3762 - val_loss: 0.1227\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3747 - val_loss: 0.1214\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3737 - val_loss: 0.1221\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3724 - val_loss: 0.1209\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3698 - val_loss: 0.1201\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3688 - val_loss: 0.1206\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3684 - val_loss: 0.1192\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3660 - val_loss: 0.1190\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3641 - val_loss: 0.1211\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3653 - val_loss: 0.1188\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3619 - val_loss: 0.1177\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3601 - val_loss: 0.1180\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3599 - val_loss: 0.1175\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3582 - val_loss: 0.1172\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3566 - val_loss: 0.1167\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3562 - val_loss: 0.1162\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3553 - val_loss: 0.1159\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3542 - val_loss: 0.1152\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3528 - val_loss: 0.1154\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3511 - val_loss: 0.1152\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3506 - val_loss: 0.1155\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3507 - val_loss: 0.1147\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3488 - val_loss: 0.1134\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3490 - val_loss: 0.1129\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3464 - val_loss: 0.1142\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3477 - val_loss: 0.1135\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3467 - val_loss: 0.1137\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3443 - val_loss: 0.1141\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3449 - val_loss: 0.1119\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3428 - val_loss: 0.1126\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3414 - val_loss: 0.1123\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3409 - val_loss: 0.1116\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3408 - val_loss: 0.1120\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3394 - val_loss: 0.1110\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3389 - val_loss: 0.1126\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3387 - val_loss: 0.1106\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3373 - val_loss: 0.1113\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3360 - val_loss: 0.1105\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3358 - val_loss: 0.1104\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3349 - val_loss: 0.1097\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3355 - val_loss: 0.1100\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3337 - val_loss: 0.1089\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3325 - val_loss: 0.1082\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3321 - val_loss: 0.1086\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3306 - val_loss: 0.1083\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3304 - val_loss: 0.1081\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3304 - val_loss: 0.1081\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 9s 102ms/step - loss: 1.1855 - val_loss: 0.2860\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.9667 - val_loss: 0.2549\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.8650 - val_loss: 0.2354\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.7987 - val_loss: 0.2242\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.7591 - val_loss: 0.2203\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.7302 - val_loss: 0.2108\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.6979 - val_loss: 0.2020\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.6754 - val_loss: 0.1984\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.6492 - val_loss: 0.1946\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.6312 - val_loss: 0.1912\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.6098 - val_loss: 0.1855\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5947 - val_loss: 0.1831\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5773 - val_loss: 0.1809\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.5676 - val_loss: 0.1784\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5526 - val_loss: 0.1757\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5413 - val_loss: 0.1730\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5293 - val_loss: 0.1722\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5202 - val_loss: 0.1729\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5122 - val_loss: 0.1689\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.5036 - val_loss: 0.1663\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4953 - val_loss: 0.1658\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4888 - val_loss: 0.1639\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4818 - val_loss: 0.1624\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4772 - val_loss: 0.1641\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4687 - val_loss: 0.1596\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4644 - val_loss: 0.1606\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4591 - val_loss: 0.1585\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4532 - val_loss: 0.1563\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4484 - val_loss: 0.1566\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4438 - val_loss: 0.1552\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4406 - val_loss: 0.1544\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4366 - val_loss: 0.1527\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4354 - val_loss: 0.1546\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4286 - val_loss: 0.1516\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4251 - val_loss: 0.1511\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4227 - val_loss: 0.1509\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4183 - val_loss: 0.1493\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4158 - val_loss: 0.1486\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4136 - val_loss: 0.1493\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4090 - val_loss: 0.1479\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4083 - val_loss: 0.1489\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4052 - val_loss: 0.1464\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.4027 - val_loss: 0.1464\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4005 - val_loss: 0.1454\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3988 - val_loss: 0.1459\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3955 - val_loss: 0.1445\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3932 - val_loss: 0.1434\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3914 - val_loss: 0.1439\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3901 - val_loss: 0.1435\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3880 - val_loss: 0.1424\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3856 - val_loss: 0.1433\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3835 - val_loss: 0.1427\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3811 - val_loss: 0.1413\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3799 - val_loss: 0.1403\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3791 - val_loss: 0.1411\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3763 - val_loss: 0.1426\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3752 - val_loss: 0.1394\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3731 - val_loss: 0.1388\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3714 - val_loss: 0.1388\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3717 - val_loss: 0.1387\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3698 - val_loss: 0.1381\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3675 - val_loss: 0.1389\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3669 - val_loss: 0.1384\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3638 - val_loss: 0.1375\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3622 - val_loss: 0.1366\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3620 - val_loss: 0.1363\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3618 - val_loss: 0.1364\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3598 - val_loss: 0.1369\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3594 - val_loss: 0.1351\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3565 - val_loss: 0.1354\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3569 - val_loss: 0.1361\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3546 - val_loss: 0.1344\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3526 - val_loss: 0.1345\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3514 - val_loss: 0.1343\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3507 - val_loss: 0.1348\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3502 - val_loss: 0.1332\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3490 - val_loss: 0.1337\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3482 - val_loss: 0.1331\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3469 - val_loss: 0.1331\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3456 - val_loss: 0.1324\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3448 - val_loss: 0.1334\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3428 - val_loss: 0.1316\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3427 - val_loss: 0.1322\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3419 - val_loss: 0.1319\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3402 - val_loss: 0.1318\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3415 - val_loss: 0.1315\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3390 - val_loss: 0.1309\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3368 - val_loss: 0.1303\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3369 - val_loss: 0.1306\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3353 - val_loss: 0.1306\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3355 - val_loss: 0.1302\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3347 - val_loss: 0.1309\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3330 - val_loss: 0.1303\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3336 - val_loss: 0.1295\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3321 - val_loss: 0.1300\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3305 - val_loss: 0.1286\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3304 - val_loss: 0.1299\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3300 - val_loss: 0.1291\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3293 - val_loss: 0.1287\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3274 - val_loss: 0.1285\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3272 - val_loss: 0.1291\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3263 - val_loss: 0.1284\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3246 - val_loss: 0.1280\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3248 - val_loss: 0.1280\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3245 - val_loss: 0.1269\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 10s 112ms/step - loss: 1.1932 - val_loss: 0.3044\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.9644 - val_loss: 0.2603\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.8478 - val_loss: 0.2385\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.7806 - val_loss: 0.2216\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.7354 - val_loss: 0.2119\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.6997 - val_loss: 0.2038\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.6721 - val_loss: 0.1979\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.6402 - val_loss: 0.1920\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.6153 - val_loss: 0.1852\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.5924 - val_loss: 0.1797\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.5731 - val_loss: 0.1741\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.5536 - val_loss: 0.1704\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.5400 - val_loss: 0.1662\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.5256 - val_loss: 0.1636\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.5128 - val_loss: 0.1597\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.5023 - val_loss: 0.1579\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4918 - val_loss: 0.1538\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4831 - val_loss: 0.1540\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4751 - val_loss: 0.1501\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4692 - val_loss: 0.1479\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4622 - val_loss: 0.1482\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.4551 - val_loss: 0.1443\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.4473 - val_loss: 0.1432\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4416 - val_loss: 0.1417\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4365 - val_loss: 0.1408\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4306 - val_loss: 0.1389\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4263 - val_loss: 0.1388\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4217 - val_loss: 0.1370\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4188 - val_loss: 0.1347\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.4134 - val_loss: 0.1346\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4102 - val_loss: 0.1335\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4063 - val_loss: 0.1318\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4029 - val_loss: 0.1335\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3995 - val_loss: 0.1302\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3977 - val_loss: 0.1302\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3948 - val_loss: 0.1293\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3914 - val_loss: 0.1277\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3880 - val_loss: 0.1274\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3859 - val_loss: 0.1270\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3841 - val_loss: 0.1260\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3813 - val_loss: 0.1255\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3788 - val_loss: 0.1255\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3760 - val_loss: 0.1241\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3739 - val_loss: 0.1228\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3716 - val_loss: 0.1227\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3701 - val_loss: 0.1220\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3682 - val_loss: 0.1216\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3649 - val_loss: 0.1217\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3633 - val_loss: 0.1207\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3611 - val_loss: 0.1199\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3595 - val_loss: 0.1208\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3582 - val_loss: 0.1194\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3567 - val_loss: 0.1191\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3544 - val_loss: 0.1183\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3526 - val_loss: 0.1167\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3515 - val_loss: 0.1169\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3497 - val_loss: 0.1169\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3493 - val_loss: 0.1172\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3474 - val_loss: 0.1166\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3454 - val_loss: 0.1167\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3449 - val_loss: 0.1148\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3438 - val_loss: 0.1155\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3433 - val_loss: 0.1149\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3401 - val_loss: 0.1135\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3387 - val_loss: 0.1134\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3377 - val_loss: 0.1131\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3363 - val_loss: 0.1128\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3356 - val_loss: 0.1127\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3339 - val_loss: 0.1135\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3332 - val_loss: 0.1126\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3332 - val_loss: 0.1119\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3306 - val_loss: 0.1109\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3289 - val_loss: 0.1120\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3283 - val_loss: 0.1110\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3275 - val_loss: 0.1103\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3267 - val_loss: 0.1105\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3263 - val_loss: 0.1098\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3248 - val_loss: 0.1100\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3244 - val_loss: 0.1091\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3233 - val_loss: 0.1096\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3218 - val_loss: 0.1086\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3202 - val_loss: 0.1085\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3217 - val_loss: 0.1084\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3189 - val_loss: 0.1087\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3185 - val_loss: 0.1082\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3179 - val_loss: 0.1074\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3164 - val_loss: 0.1078\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3148 - val_loss: 0.1067\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3144 - val_loss: 0.1069\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3134 - val_loss: 0.1071\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3136 - val_loss: 0.1070\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3123 - val_loss: 0.1066\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3117 - val_loss: 0.1076\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3110 - val_loss: 0.1066\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3100 - val_loss: 0.1063\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3095 - val_loss: 0.1062\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3084 - val_loss: 0.1050\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3070 - val_loss: 0.1053\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3069 - val_loss: 0.1052\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3078 - val_loss: 0.1046\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3060 - val_loss: 0.1050\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3045 - val_loss: 0.1040\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3040 - val_loss: 0.1039\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3036 - val_loss: 0.1036\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3029 - val_loss: 0.1037\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 10s 114ms/step - loss: 1.1837 - val_loss: 0.2987\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.9517 - val_loss: 0.2692\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.8484 - val_loss: 0.2485\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.7742 - val_loss: 0.2305\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.7284 - val_loss: 0.2221\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.6943 - val_loss: 0.2152\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.6633 - val_loss: 0.2086\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.6352 - val_loss: 0.2008\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.6073 - val_loss: 0.1948\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.5859 - val_loss: 0.1911\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.5679 - val_loss: 0.1863\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.5496 - val_loss: 0.1816\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.5343 - val_loss: 0.1791\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.5203 - val_loss: 0.1744\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.5085 - val_loss: 0.1716\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4986 - val_loss: 0.1722\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4893 - val_loss: 0.1667\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.4782 - val_loss: 0.1645\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4723 - val_loss: 0.1615\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4638 - val_loss: 0.1603\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4574 - val_loss: 0.1580\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4507 - val_loss: 0.1560\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4450 - val_loss: 0.1549\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4399 - val_loss: 0.1533\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4336 - val_loss: 0.1510\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4285 - val_loss: 0.1498\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4249 - val_loss: 0.1495\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4202 - val_loss: 0.1476\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4173 - val_loss: 0.1479\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4118 - val_loss: 0.1454\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4091 - val_loss: 0.1439\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4050 - val_loss: 0.1417\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4016 - val_loss: 0.1422\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3999 - val_loss: 0.1405\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3956 - val_loss: 0.1395\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3921 - val_loss: 0.1391\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3895 - val_loss: 0.1377\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3868 - val_loss: 0.1377\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3838 - val_loss: 0.1365\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3814 - val_loss: 0.1357\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3788 - val_loss: 0.1345\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3763 - val_loss: 0.1345\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3739 - val_loss: 0.1338\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3730 - val_loss: 0.1335\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3706 - val_loss: 0.1326\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3680 - val_loss: 0.1313\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3659 - val_loss: 0.1307\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3645 - val_loss: 0.1300\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3624 - val_loss: 0.1305\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3606 - val_loss: 0.1291\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3587 - val_loss: 0.1293\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3565 - val_loss: 0.1277\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3555 - val_loss: 0.1284\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3533 - val_loss: 0.1268\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3524 - val_loss: 0.1278\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3501 - val_loss: 0.1269\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3489 - val_loss: 0.1250\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3477 - val_loss: 0.1249\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3454 - val_loss: 0.1244\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3446 - val_loss: 0.1244\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3431 - val_loss: 0.1237\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3416 - val_loss: 0.1230\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3412 - val_loss: 0.1228\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3397 - val_loss: 0.1228\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3379 - val_loss: 0.1222\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3372 - val_loss: 0.1226\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3354 - val_loss: 0.1226\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3341 - val_loss: 0.1209\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3327 - val_loss: 0.1204\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3314 - val_loss: 0.1206\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3317 - val_loss: 0.1212\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3301 - val_loss: 0.1199\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3284 - val_loss: 0.1199\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3279 - val_loss: 0.1186\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3268 - val_loss: 0.1191\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3267 - val_loss: 0.1193\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3245 - val_loss: 0.1185\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3236 - val_loss: 0.1175\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3243 - val_loss: 0.1180\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3214 - val_loss: 0.1187\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3210 - val_loss: 0.1170\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3190 - val_loss: 0.1164\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3178 - val_loss: 0.1162\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3173 - val_loss: 0.1172\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3164 - val_loss: 0.1156\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3166 - val_loss: 0.1153\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3153 - val_loss: 0.1164\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3138 - val_loss: 0.1147\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3128 - val_loss: 0.1149\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3122 - val_loss: 0.1151\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3116 - val_loss: 0.1139\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3105 - val_loss: 0.1136\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3104 - val_loss: 0.1136\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3094 - val_loss: 0.1140\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3095 - val_loss: 0.1132\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3082 - val_loss: 0.1142\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3076 - val_loss: 0.1150\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3070 - val_loss: 0.1127\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3054 - val_loss: 0.1124\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3050 - val_loss: 0.1125\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3045 - val_loss: 0.1115\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3037 - val_loss: 0.1113\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3026 - val_loss: 0.1121\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3021 - val_loss: 0.1121\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3021 - val_loss: 0.1115\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 10s 111ms/step - loss: 1.1727 - val_loss: 0.2933\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.9423 - val_loss: 0.2545\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.8353 - val_loss: 0.2390\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.7718 - val_loss: 0.2240\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.7251 - val_loss: 0.2083\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.6911 - val_loss: 0.2065\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6607 - val_loss: 0.1971\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.6309 - val_loss: 0.1954\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.6065 - val_loss: 0.1868\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.5846 - val_loss: 0.1839\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.5667 - val_loss: 0.1787\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.5506 - val_loss: 0.1729\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.5349 - val_loss: 0.1697\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.5212 - val_loss: 0.1663\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.5083 - val_loss: 0.1651\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4990 - val_loss: 0.1629\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4891 - val_loss: 0.1587\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4801 - val_loss: 0.1572\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4720 - val_loss: 0.1549\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.4636 - val_loss: 0.1534\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4585 - val_loss: 0.1532\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4518 - val_loss: 0.1501\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4459 - val_loss: 0.1494\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4387 - val_loss: 0.1469\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4342 - val_loss: 0.1450\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4307 - val_loss: 0.1443\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4249 - val_loss: 0.1449\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4223 - val_loss: 0.1427\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.4162 - val_loss: 0.1416\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4127 - val_loss: 0.1420\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4088 - val_loss: 0.1385\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4048 - val_loss: 0.1377\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4011 - val_loss: 0.1369\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3989 - val_loss: 0.1384\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3956 - val_loss: 0.1368\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3928 - val_loss: 0.1343\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3905 - val_loss: 0.1344\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3862 - val_loss: 0.1330\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3861 - val_loss: 0.1330\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3827 - val_loss: 0.1331\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3795 - val_loss: 0.1315\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3768 - val_loss: 0.1315\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3741 - val_loss: 0.1294\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3715 - val_loss: 0.1288\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3710 - val_loss: 0.1294\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3692 - val_loss: 0.1284\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3665 - val_loss: 0.1295\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3662 - val_loss: 0.1275\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3625 - val_loss: 0.1270\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3608 - val_loss: 0.1267\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3598 - val_loss: 0.1274\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3578 - val_loss: 0.1250\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3556 - val_loss: 0.1251\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3534 - val_loss: 0.1249\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3517 - val_loss: 0.1242\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3522 - val_loss: 0.1249\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3503 - val_loss: 0.1250\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3481 - val_loss: 0.1224\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3475 - val_loss: 0.1229\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3458 - val_loss: 0.1232\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3438 - val_loss: 0.1216\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3422 - val_loss: 0.1223\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3404 - val_loss: 0.1207\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3395 - val_loss: 0.1206\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3382 - val_loss: 0.1200\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3367 - val_loss: 0.1197\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3357 - val_loss: 0.1189\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3344 - val_loss: 0.1189\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3337 - val_loss: 0.1193\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3324 - val_loss: 0.1202\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3316 - val_loss: 0.1194\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3307 - val_loss: 0.1186\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3296 - val_loss: 0.1189\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3281 - val_loss: 0.1181\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3274 - val_loss: 0.1182\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3259 - val_loss: 0.1178\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3265 - val_loss: 0.1174\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3240 - val_loss: 0.1165\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3233 - val_loss: 0.1170\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3216 - val_loss: 0.1173\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3218 - val_loss: 0.1160\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3207 - val_loss: 0.1154\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3198 - val_loss: 0.1162\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3193 - val_loss: 0.1153\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3183 - val_loss: 0.1152\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3175 - val_loss: 0.1156\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3161 - val_loss: 0.1151\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3153 - val_loss: 0.1145\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3147 - val_loss: 0.1140\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3130 - val_loss: 0.1129\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3133 - val_loss: 0.1154\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3120 - val_loss: 0.1142\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3110 - val_loss: 0.1139\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3097 - val_loss: 0.1133\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3097 - val_loss: 0.1121\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3090 - val_loss: 0.1134\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3089 - val_loss: 0.1137\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3079 - val_loss: 0.1123\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3066 - val_loss: 0.1127\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3059 - val_loss: 0.1129\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3056 - val_loss: 0.1118\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3056 - val_loss: 0.1115\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3042 - val_loss: 0.1113\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3037 - val_loss: 0.1116\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3031 - val_loss: 0.1110\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 10s 109ms/step - loss: 1.1666 - val_loss: 0.2953\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.9484 - val_loss: 0.2608\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.8529 - val_loss: 0.2348\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.7847 - val_loss: 0.2224\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.7364 - val_loss: 0.2160\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.7005 - val_loss: 0.2067\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.6695 - val_loss: 0.2000\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.6405 - val_loss: 0.1938\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.6139 - val_loss: 0.1862\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.5903 - val_loss: 0.1813\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.5718 - val_loss: 0.1771\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.5536 - val_loss: 0.1739\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.5393 - val_loss: 0.1682\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.5246 - val_loss: 0.1649\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.5125 - val_loss: 0.1626\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.5007 - val_loss: 0.1591\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 85ms/step - loss: 0.4907 - val_loss: 0.1568\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4826 - val_loss: 0.1553\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4753 - val_loss: 0.1528\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 85ms/step - loss: 0.4650 - val_loss: 0.1507\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4598 - val_loss: 0.1496\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.4516 - val_loss: 0.1486\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.4466 - val_loss: 0.1454\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 85ms/step - loss: 0.4412 - val_loss: 0.1430\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4356 - val_loss: 0.1423\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4307 - val_loss: 0.1406\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 85ms/step - loss: 0.4247 - val_loss: 0.1408\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4220 - val_loss: 0.1384\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4170 - val_loss: 0.1389\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.4138 - val_loss: 0.1373\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4114 - val_loss: 0.1348\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4063 - val_loss: 0.1339\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4028 - val_loss: 0.1331\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3983 - val_loss: 0.1325\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3958 - val_loss: 0.1315\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3925 - val_loss: 0.1307\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 85ms/step - loss: 0.3897 - val_loss: 0.1287\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3873 - val_loss: 0.1287\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3847 - val_loss: 0.1281\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3826 - val_loss: 0.1272\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3795 - val_loss: 0.1269\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3769 - val_loss: 0.1256\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3748 - val_loss: 0.1255\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 85ms/step - loss: 0.3733 - val_loss: 0.1246\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3706 - val_loss: 0.1232\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3683 - val_loss: 0.1227\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3664 - val_loss: 0.1233\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3649 - val_loss: 0.1221\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3628 - val_loss: 0.1217\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3611 - val_loss: 0.1207\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3596 - val_loss: 0.1207\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3574 - val_loss: 0.1196\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3558 - val_loss: 0.1195\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3537 - val_loss: 0.1189\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3518 - val_loss: 0.1190\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3513 - val_loss: 0.1178\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3494 - val_loss: 0.1166\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3470 - val_loss: 0.1166\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3458 - val_loss: 0.1163\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3441 - val_loss: 0.1158\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3438 - val_loss: 0.1160\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3425 - val_loss: 0.1157\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3403 - val_loss: 0.1156\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3398 - val_loss: 0.1145\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 85ms/step - loss: 0.3387 - val_loss: 0.1148\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3374 - val_loss: 0.1140\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3362 - val_loss: 0.1135\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3359 - val_loss: 0.1153\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3330 - val_loss: 0.1124\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3319 - val_loss: 0.1139\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3329 - val_loss: 0.1120\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3298 - val_loss: 0.1114\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3298 - val_loss: 0.1114\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3282 - val_loss: 0.1108\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3268 - val_loss: 0.1110\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3257 - val_loss: 0.1101\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3246 - val_loss: 0.1106\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3246 - val_loss: 0.1096\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3230 - val_loss: 0.1094\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3220 - val_loss: 0.1085\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3205 - val_loss: 0.1095\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 85ms/step - loss: 0.3209 - val_loss: 0.1094\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3197 - val_loss: 0.1084\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3187 - val_loss: 0.1076\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3182 - val_loss: 0.1071\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3171 - val_loss: 0.1083\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3164 - val_loss: 0.1083\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3161 - val_loss: 0.1066\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3141 - val_loss: 0.1076\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3124 - val_loss: 0.1062\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3133 - val_loss: 0.1065\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3117 - val_loss: 0.1061\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3115 - val_loss: 0.1056\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3106 - val_loss: 0.1056\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3099 - val_loss: 0.1052\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 85ms/step - loss: 0.3087 - val_loss: 0.1059\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3076 - val_loss: 0.1046\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3066 - val_loss: 0.1041\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3064 - val_loss: 0.1042\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3056 - val_loss: 0.1039\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3051 - val_loss: 0.1042\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3048 - val_loss: 0.1039\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3030 - val_loss: 0.1044\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3021 - val_loss: 0.1031\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3022 - val_loss: 0.1042\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 9s 100ms/step - loss: 1.1892 - val_loss: 0.2883\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.9558 - val_loss: 0.2547\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.8519 - val_loss: 0.2314\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.7869 - val_loss: 0.2245\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.7377 - val_loss: 0.2129\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.7044 - val_loss: 0.2075\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.6699 - val_loss: 0.1959\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.6408 - val_loss: 0.1909\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.6120 - val_loss: 0.1871\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.5900 - val_loss: 0.1851\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.5691 - val_loss: 0.1779\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.5516 - val_loss: 0.1758\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.5367 - val_loss: 0.1728\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.5211 - val_loss: 0.1705\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.5110 - val_loss: 0.1685\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4982 - val_loss: 0.1653\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4883 - val_loss: 0.1638\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.4781 - val_loss: 0.1617\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4694 - val_loss: 0.1605\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4630 - val_loss: 0.1595\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4555 - val_loss: 0.1578\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4487 - val_loss: 0.1551\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4422 - val_loss: 0.1541\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.4355 - val_loss: 0.1548\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.4322 - val_loss: 0.1530\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.4256 - val_loss: 0.1519\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4219 - val_loss: 0.1505\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4166 - val_loss: 0.1500\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4130 - val_loss: 0.1495\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4085 - val_loss: 0.1474\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4040 - val_loss: 0.1470\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.4007 - val_loss: 0.1457\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3975 - val_loss: 0.1453\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3955 - val_loss: 0.1451\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3915 - val_loss: 0.1431\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3882 - val_loss: 0.1427\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3840 - val_loss: 0.1428\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3825 - val_loss: 0.1423\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3795 - val_loss: 0.1419\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3775 - val_loss: 0.1418\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3770 - val_loss: 0.1413\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3706 - val_loss: 0.1389\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3693 - val_loss: 0.1398\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3682 - val_loss: 0.1389\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3650 - val_loss: 0.1383\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3628 - val_loss: 0.1380\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3607 - val_loss: 0.1368\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3584 - val_loss: 0.1370\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3575 - val_loss: 0.1370\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3557 - val_loss: 0.1379\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3549 - val_loss: 0.1364\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3516 - val_loss: 0.1351\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3492 - val_loss: 0.1344\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3474 - val_loss: 0.1346\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3471 - val_loss: 0.1340\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3447 - val_loss: 0.1333\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3425 - val_loss: 0.1327\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3417 - val_loss: 0.1333\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3409 - val_loss: 0.1325\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3387 - val_loss: 0.1338\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3376 - val_loss: 0.1327\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3360 - val_loss: 0.1321\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3347 - val_loss: 0.1312\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3341 - val_loss: 0.1309\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3326 - val_loss: 0.1311\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3305 - val_loss: 0.1328\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3298 - val_loss: 0.1310\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3282 - val_loss: 0.1303\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3269 - val_loss: 0.1299\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3255 - val_loss: 0.1293\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3249 - val_loss: 0.1306\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3243 - val_loss: 0.1295\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3229 - val_loss: 0.1286\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3221 - val_loss: 0.1289\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3204 - val_loss: 0.1289\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3193 - val_loss: 0.1290\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3183 - val_loss: 0.1285\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3178 - val_loss: 0.1296\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3164 - val_loss: 0.1274\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3145 - val_loss: 0.1272\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3137 - val_loss: 0.1279\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3139 - val_loss: 0.1266\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3127 - val_loss: 0.1274\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3116 - val_loss: 0.1267\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 0.3108 - val_loss: 0.1265\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3100 - val_loss: 0.1272\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3099 - val_loss: 0.1262\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3091 - val_loss: 0.1261\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3076 - val_loss: 0.1257\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3065 - val_loss: 0.1256\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3057 - val_loss: 0.1253\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3042 - val_loss: 0.1253\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3049 - val_loss: 0.1252\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3035 - val_loss: 0.1258\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3026 - val_loss: 0.1252\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 0.3012 - val_loss: 0.1237\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.3016 - val_loss: 0.1252\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3011 - val_loss: 0.1243\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2996 - val_loss: 0.1245\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.2991 - val_loss: 0.1242\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2977 - val_loss: 0.1235\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2982 - val_loss: 0.1234\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.2962 - val_loss: 0.1235\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2960 - val_loss: 0.1239\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 0.2963 - val_loss: 0.1243\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 9s 107ms/step - loss: 1.2145 - val_loss: 0.3023\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.9765 - val_loss: 0.2670\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.8805 - val_loss: 0.2441\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.8099 - val_loss: 0.2316\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.7678 - val_loss: 0.2214\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.7325 - val_loss: 0.2147\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.7004 - val_loss: 0.2049\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.6710 - val_loss: 0.1988\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.6466 - val_loss: 0.1926\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6216 - val_loss: 0.1891\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6026 - val_loss: 0.1795\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5813 - val_loss: 0.1771\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5659 - val_loss: 0.1725\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5508 - val_loss: 0.1685\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5363 - val_loss: 0.1650\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.5237 - val_loss: 0.1628\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5115 - val_loss: 0.1581\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5018 - val_loss: 0.1573\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4925 - val_loss: 0.1546\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4851 - val_loss: 0.1540\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4788 - val_loss: 0.1507\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4685 - val_loss: 0.1486\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4613 - val_loss: 0.1465\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4534 - val_loss: 0.1445\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4488 - val_loss: 0.1465\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4449 - val_loss: 0.1417\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4357 - val_loss: 0.1397\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4319 - val_loss: 0.1387\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4281 - val_loss: 0.1378\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4225 - val_loss: 0.1363\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4184 - val_loss: 0.1355\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4136 - val_loss: 0.1338\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4086 - val_loss: 0.1328\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4055 - val_loss: 0.1311\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4030 - val_loss: 0.1305\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3986 - val_loss: 0.1313\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3963 - val_loss: 0.1284\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3925 - val_loss: 0.1282\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3895 - val_loss: 0.1267\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3866 - val_loss: 0.1263\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3839 - val_loss: 0.1254\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3817 - val_loss: 0.1246\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3778 - val_loss: 0.1239\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3761 - val_loss: 0.1238\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3742 - val_loss: 0.1226\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3710 - val_loss: 0.1218\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3676 - val_loss: 0.1212\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3659 - val_loss: 0.1204\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3645 - val_loss: 0.1206\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3650 - val_loss: 0.1194\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3600 - val_loss: 0.1190\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.3570 - val_loss: 0.1180\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3552 - val_loss: 0.1179\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3542 - val_loss: 0.1176\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3515 - val_loss: 0.1161\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3506 - val_loss: 0.1162\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3472 - val_loss: 0.1154\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3463 - val_loss: 0.1152\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3452 - val_loss: 0.1151\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3430 - val_loss: 0.1140\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3407 - val_loss: 0.1135\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3410 - val_loss: 0.1130\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3397 - val_loss: 0.1127\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3370 - val_loss: 0.1130\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3349 - val_loss: 0.1116\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3339 - val_loss: 0.1115\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3329 - val_loss: 0.1110\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3318 - val_loss: 0.1112\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3303 - val_loss: 0.1104\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3285 - val_loss: 0.1099\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3292 - val_loss: 0.1101\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3267 - val_loss: 0.1091\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3249 - val_loss: 0.1088\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3233 - val_loss: 0.1092\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3229 - val_loss: 0.1084\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3214 - val_loss: 0.1076\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3200 - val_loss: 0.1072\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3194 - val_loss: 0.1071\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3182 - val_loss: 0.1066\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3171 - val_loss: 0.1065\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3155 - val_loss: 0.1067\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3145 - val_loss: 0.1063\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3140 - val_loss: 0.1060\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3137 - val_loss: 0.1049\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3124 - val_loss: 0.1058\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3111 - val_loss: 0.1047\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3106 - val_loss: 0.1060\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3090 - val_loss: 0.1046\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3082 - val_loss: 0.1037\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3073 - val_loss: 0.1041\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3059 - val_loss: 0.1033\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3060 - val_loss: 0.1034\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3040 - val_loss: 0.1031\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3042 - val_loss: 0.1035\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3037 - val_loss: 0.1029\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3024 - val_loss: 0.1025\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3010 - val_loss: 0.1025\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3010 - val_loss: 0.1019\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2993 - val_loss: 0.1023\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2986 - val_loss: 0.1015\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2985 - val_loss: 0.1013\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2968 - val_loss: 0.1010\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.2974 - val_loss: 0.1015\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.2963 - val_loss: 0.1002\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2956 - val_loss: 0.1006\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 9s 105ms/step - loss: 1.1978 - val_loss: 0.2983\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.9608 - val_loss: 0.2724\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.8677 - val_loss: 0.2509\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.7944 - val_loss: 0.2344\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.7474 - val_loss: 0.2276\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.7123 - val_loss: 0.2183\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.6804 - val_loss: 0.2130\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.6548 - val_loss: 0.2065\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.6299 - val_loss: 0.2007\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.6084 - val_loss: 0.1974\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.5880 - val_loss: 0.1910\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.5693 - val_loss: 0.1868\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.5570 - val_loss: 0.1830\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.5392 - val_loss: 0.1786\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.5257 - val_loss: 0.1760\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5125 - val_loss: 0.1726\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5035 - val_loss: 0.1706\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4937 - val_loss: 0.1677\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4844 - val_loss: 0.1654\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4757 - val_loss: 0.1625\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4681 - val_loss: 0.1601\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4609 - val_loss: 0.1591\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4539 - val_loss: 0.1564\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4481 - val_loss: 0.1551\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4408 - val_loss: 0.1529\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4357 - val_loss: 0.1507\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4316 - val_loss: 0.1507\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4276 - val_loss: 0.1488\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4222 - val_loss: 0.1474\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4173 - val_loss: 0.1455\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4119 - val_loss: 0.1436\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4087 - val_loss: 0.1429\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4054 - val_loss: 0.1420\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4012 - val_loss: 0.1405\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3979 - val_loss: 0.1407\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3944 - val_loss: 0.1386\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3910 - val_loss: 0.1381\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3880 - val_loss: 0.1373\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3845 - val_loss: 0.1354\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3814 - val_loss: 0.1353\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3792 - val_loss: 0.1342\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3756 - val_loss: 0.1333\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3741 - val_loss: 0.1332\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3726 - val_loss: 0.1323\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3708 - val_loss: 0.1313\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3681 - val_loss: 0.1304\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3635 - val_loss: 0.1301\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3622 - val_loss: 0.1291\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3604 - val_loss: 0.1283\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3578 - val_loss: 0.1277\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3569 - val_loss: 0.1276\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3544 - val_loss: 0.1267\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3528 - val_loss: 0.1262\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3501 - val_loss: 0.1259\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3491 - val_loss: 0.1265\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3477 - val_loss: 0.1247\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3457 - val_loss: 0.1251\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3451 - val_loss: 0.1240\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3416 - val_loss: 0.1229\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3401 - val_loss: 0.1223\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3384 - val_loss: 0.1227\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3368 - val_loss: 0.1214\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3350 - val_loss: 0.1210\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3350 - val_loss: 0.1213\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3330 - val_loss: 0.1203\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3323 - val_loss: 0.1212\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3318 - val_loss: 0.1195\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3291 - val_loss: 0.1189\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3284 - val_loss: 0.1207\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3268 - val_loss: 0.1186\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3253 - val_loss: 0.1182\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3243 - val_loss: 0.1178\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3224 - val_loss: 0.1173\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3217 - val_loss: 0.1170\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3208 - val_loss: 0.1162\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3207 - val_loss: 0.1167\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3189 - val_loss: 0.1160\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3168 - val_loss: 0.1158\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.3166 - val_loss: 0.1163\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3161 - val_loss: 0.1151\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3143 - val_loss: 0.1148\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3134 - val_loss: 0.1136\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3128 - val_loss: 0.1145\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3124 - val_loss: 0.1153\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3112 - val_loss: 0.1143\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3102 - val_loss: 0.1136\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3092 - val_loss: 0.1146\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3078 - val_loss: 0.1134\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3067 - val_loss: 0.1138\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3068 - val_loss: 0.1124\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3056 - val_loss: 0.1121\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3050 - val_loss: 0.1120\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3038 - val_loss: 0.1112\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3023 - val_loss: 0.1117\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3014 - val_loss: 0.1110\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3003 - val_loss: 0.1108\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3020 - val_loss: 0.1107\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3002 - val_loss: 0.1106\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2994 - val_loss: 0.1097\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.2976 - val_loss: 0.1097\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.2972 - val_loss: 0.1096\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.2964 - val_loss: 0.1090\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2956 - val_loss: 0.1089\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2961 - val_loss: 0.1086\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2946 - val_loss: 0.1094\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 10s 107ms/step - loss: 1.1945 - val_loss: 0.2908\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.9576 - val_loss: 0.2626\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.8628 - val_loss: 0.2418\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.7932 - val_loss: 0.2254\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.7443 - val_loss: 0.2143\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.7103 - val_loss: 0.2099\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6791 - val_loss: 0.2024\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.6503 - val_loss: 0.1960\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6258 - val_loss: 0.1918\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.6023 - val_loss: 0.1881\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5844 - val_loss: 0.1824\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.5688 - val_loss: 0.1813\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.5537 - val_loss: 0.1770\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5374 - val_loss: 0.1727\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5250 - val_loss: 0.1690\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.5129 - val_loss: 0.1666\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5039 - val_loss: 0.1664\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4926 - val_loss: 0.1635\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4877 - val_loss: 0.1592\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4762 - val_loss: 0.1575\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4670 - val_loss: 0.1558\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4606 - val_loss: 0.1535\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4533 - val_loss: 0.1528\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4492 - val_loss: 0.1504\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4423 - val_loss: 0.1488\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4373 - val_loss: 0.1473\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4311 - val_loss: 0.1460\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4268 - val_loss: 0.1444\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4201 - val_loss: 0.1447\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4159 - val_loss: 0.1432\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4133 - val_loss: 0.1410\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4085 - val_loss: 0.1402\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4050 - val_loss: 0.1396\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 0.4020 - val_loss: 0.1377\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3977 - val_loss: 0.1370\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3945 - val_loss: 0.1358\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3918 - val_loss: 0.1357\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3894 - val_loss: 0.1364\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3864 - val_loss: 0.1327\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3825 - val_loss: 0.1333\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3811 - val_loss: 0.1318\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3765 - val_loss: 0.1308\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3740 - val_loss: 0.1308\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3719 - val_loss: 0.1295\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3714 - val_loss: 0.1286\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3681 - val_loss: 0.1280\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3641 - val_loss: 0.1274\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3616 - val_loss: 0.1271\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3612 - val_loss: 0.1266\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3588 - val_loss: 0.1269\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3567 - val_loss: 0.1258\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3554 - val_loss: 0.1250\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3527 - val_loss: 0.1247\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3509 - val_loss: 0.1236\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3490 - val_loss: 0.1239\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3486 - val_loss: 0.1241\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3476 - val_loss: 0.1236\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3486 - val_loss: 0.1217\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3436 - val_loss: 0.1212\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3420 - val_loss: 0.1209\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3392 - val_loss: 0.1213\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3382 - val_loss: 0.1212\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3370 - val_loss: 0.1199\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3350 - val_loss: 0.1191\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3337 - val_loss: 0.1192\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3320 - val_loss: 0.1188\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3310 - val_loss: 0.1182\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3297 - val_loss: 0.1175\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3280 - val_loss: 0.1177\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3274 - val_loss: 0.1173\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3259 - val_loss: 0.1174\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3242 - val_loss: 0.1170\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3236 - val_loss: 0.1161\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3219 - val_loss: 0.1153\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3210 - val_loss: 0.1159\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3208 - val_loss: 0.1147\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3194 - val_loss: 0.1149\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3182 - val_loss: 0.1147\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3165 - val_loss: 0.1149\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3165 - val_loss: 0.1141\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3154 - val_loss: 0.1155\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3155 - val_loss: 0.1134\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3136 - val_loss: 0.1128\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3126 - val_loss: 0.1123\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3106 - val_loss: 0.1130\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3096 - val_loss: 0.1128\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3085 - val_loss: 0.1128\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3080 - val_loss: 0.1130\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3072 - val_loss: 0.1123\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3062 - val_loss: 0.1109\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3057 - val_loss: 0.1119\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3062 - val_loss: 0.1109\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3048 - val_loss: 0.1112\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3042 - val_loss: 0.1116\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3027 - val_loss: 0.1106\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3016 - val_loss: 0.1098\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3010 - val_loss: 0.1094\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3001 - val_loss: 0.1096\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.2993 - val_loss: 0.1097\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.2986 - val_loss: 0.1098\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.2977 - val_loss: 0.1088\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.2967 - val_loss: 0.1094\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.2960 - val_loss: 0.1090\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.2970 - val_loss: 0.1083\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.2952 - val_loss: 0.1086\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 9s 105ms/step - loss: 1.2106 - val_loss: 0.2989\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.9645 - val_loss: 0.2704\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.8866 - val_loss: 0.2468\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.8253 - val_loss: 0.2344\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.7756 - val_loss: 0.2272\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.7360 - val_loss: 0.2160\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.7004 - val_loss: 0.2067\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.6712 - val_loss: 0.2030\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6426 - val_loss: 0.1938\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6203 - val_loss: 0.1908\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6001 - val_loss: 0.1851\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5827 - val_loss: 0.1788\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5659 - val_loss: 0.1769\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5506 - val_loss: 0.1719\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5376 - val_loss: 0.1697\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.5234 - val_loss: 0.1653\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5117 - val_loss: 0.1616\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5012 - val_loss: 0.1590\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4925 - val_loss: 0.1557\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4838 - val_loss: 0.1542\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4758 - val_loss: 0.1536\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4706 - val_loss: 0.1514\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4621 - val_loss: 0.1484\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4553 - val_loss: 0.1468\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4472 - val_loss: 0.1455\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4439 - val_loss: 0.1438\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4372 - val_loss: 0.1423\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4322 - val_loss: 0.1404\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4268 - val_loss: 0.1389\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4229 - val_loss: 0.1384\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4172 - val_loss: 0.1371\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4134 - val_loss: 0.1364\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4103 - val_loss: 0.1348\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4067 - val_loss: 0.1329\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.4031 - val_loss: 0.1325\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3988 - val_loss: 0.1306\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3950 - val_loss: 0.1308\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3920 - val_loss: 0.1291\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3887 - val_loss: 0.1282\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3856 - val_loss: 0.1280\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3836 - val_loss: 0.1271\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3804 - val_loss: 0.1254\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3783 - val_loss: 0.1268\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.3751 - val_loss: 0.1244\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3721 - val_loss: 0.1238\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3704 - val_loss: 0.1223\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3687 - val_loss: 0.1216\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3654 - val_loss: 0.1214\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3642 - val_loss: 0.1205\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3607 - val_loss: 0.1196\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3594 - val_loss: 0.1192\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3577 - val_loss: 0.1190\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3544 - val_loss: 0.1180\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3533 - val_loss: 0.1189\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3523 - val_loss: 0.1174\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3499 - val_loss: 0.1170\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3480 - val_loss: 0.1167\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3463 - val_loss: 0.1153\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3454 - val_loss: 0.1159\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3436 - val_loss: 0.1139\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3411 - val_loss: 0.1141\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3405 - val_loss: 0.1144\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3382 - val_loss: 0.1131\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3361 - val_loss: 0.1125\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3356 - val_loss: 0.1123\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3330 - val_loss: 0.1115\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3321 - val_loss: 0.1118\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3304 - val_loss: 0.1109\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3297 - val_loss: 0.1112\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3289 - val_loss: 0.1100\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3277 - val_loss: 0.1096\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3253 - val_loss: 0.1093\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3239 - val_loss: 0.1089\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3224 - val_loss: 0.1088\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3217 - val_loss: 0.1086\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3208 - val_loss: 0.1078\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3190 - val_loss: 0.1079\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3192 - val_loss: 0.1081\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3185 - val_loss: 0.1071\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3186 - val_loss: 0.1069\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3162 - val_loss: 0.1064\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3144 - val_loss: 0.1056\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3129 - val_loss: 0.1057\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3128 - val_loss: 0.1060\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3117 - val_loss: 0.1057\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3102 - val_loss: 0.1057\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3099 - val_loss: 0.1046\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3084 - val_loss: 0.1042\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3069 - val_loss: 0.1039\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3058 - val_loss: 0.1043\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3063 - val_loss: 0.1034\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3060 - val_loss: 0.1033\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3043 - val_loss: 0.1031\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3029 - val_loss: 0.1032\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3025 - val_loss: 0.1026\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3042 - val_loss: 0.1020\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3021 - val_loss: 0.1019\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3013 - val_loss: 0.1023\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2995 - val_loss: 0.1017\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2982 - val_loss: 0.1014\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2978 - val_loss: 0.1017\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.2964 - val_loss: 0.1008\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 0.2960 - val_loss: 0.1009\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2952 - val_loss: 0.1005\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.2951 - val_loss: 0.1000\n",
      "Epoch 1/105\n",
      "89/89 [==============================] - 10s 108ms/step - loss: 1.2161 - val_loss: 0.2892\n",
      "Epoch 2/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.9723 - val_loss: 0.2608\n",
      "Epoch 3/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.8774 - val_loss: 0.2386\n",
      "Epoch 4/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.8078 - val_loss: 0.2275\n",
      "Epoch 5/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.7631 - val_loss: 0.2206\n",
      "Epoch 6/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.7308 - val_loss: 0.2131\n",
      "Epoch 7/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6970 - val_loss: 0.2022\n",
      "Epoch 8/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.6650 - val_loss: 0.1962\n",
      "Epoch 9/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6406 - val_loss: 0.1918\n",
      "Epoch 10/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.6160 - val_loss: 0.1879\n",
      "Epoch 11/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5949 - val_loss: 0.1845\n",
      "Epoch 12/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5772 - val_loss: 0.1811\n",
      "Epoch 13/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.5603 - val_loss: 0.1769\n",
      "Epoch 14/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.5431 - val_loss: 0.1746\n",
      "Epoch 15/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.5295 - val_loss: 0.1735\n",
      "Epoch 16/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5187 - val_loss: 0.1707\n",
      "Epoch 17/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.5059 - val_loss: 0.1675\n",
      "Epoch 18/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4968 - val_loss: 0.1676\n",
      "Epoch 19/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4876 - val_loss: 0.1647\n",
      "Epoch 20/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4777 - val_loss: 0.1626\n",
      "Epoch 21/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4693 - val_loss: 0.1608\n",
      "Epoch 22/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.4633 - val_loss: 0.1595\n",
      "Epoch 23/105\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.4547 - val_loss: 0.1581\n",
      "Epoch 24/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4483 - val_loss: 0.1564\n",
      "Epoch 25/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.4412 - val_loss: 0.1551\n",
      "Epoch 26/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4375 - val_loss: 0.1539\n",
      "Epoch 27/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4317 - val_loss: 0.1529\n",
      "Epoch 28/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4262 - val_loss: 0.1524\n",
      "Epoch 29/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4211 - val_loss: 0.1506\n",
      "Epoch 30/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4155 - val_loss: 0.1496\n",
      "Epoch 31/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.4118 - val_loss: 0.1487\n",
      "Epoch 32/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4076 - val_loss: 0.1480\n",
      "Epoch 33/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.4036 - val_loss: 0.1468\n",
      "Epoch 34/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3994 - val_loss: 0.1459\n",
      "Epoch 35/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3969 - val_loss: 0.1442\n",
      "Epoch 36/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3925 - val_loss: 0.1450\n",
      "Epoch 37/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3893 - val_loss: 0.1438\n",
      "Epoch 38/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3874 - val_loss: 0.1427\n",
      "Epoch 39/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3825 - val_loss: 0.1421\n",
      "Epoch 40/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3794 - val_loss: 0.1416\n",
      "Epoch 41/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3767 - val_loss: 0.1407\n",
      "Epoch 42/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3738 - val_loss: 0.1398\n",
      "Epoch 43/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3714 - val_loss: 0.1407\n",
      "Epoch 44/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.3701 - val_loss: 0.1388\n",
      "Epoch 45/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3665 - val_loss: 0.1388\n",
      "Epoch 46/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3638 - val_loss: 0.1383\n",
      "Epoch 47/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3627 - val_loss: 0.1375\n",
      "Epoch 48/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3604 - val_loss: 0.1376\n",
      "Epoch 49/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3576 - val_loss: 0.1362\n",
      "Epoch 50/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3548 - val_loss: 0.1364\n",
      "Epoch 51/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3531 - val_loss: 0.1360\n",
      "Epoch 52/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3517 - val_loss: 0.1355\n",
      "Epoch 53/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3498 - val_loss: 0.1350\n",
      "Epoch 54/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3475 - val_loss: 0.1339\n",
      "Epoch 55/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3459 - val_loss: 0.1344\n",
      "Epoch 56/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3453 - val_loss: 0.1336\n",
      "Epoch 57/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3418 - val_loss: 0.1342\n",
      "Epoch 58/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3398 - val_loss: 0.1337\n",
      "Epoch 59/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3390 - val_loss: 0.1328\n",
      "Epoch 60/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3361 - val_loss: 0.1322\n",
      "Epoch 61/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3361 - val_loss: 0.1321\n",
      "Epoch 62/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3335 - val_loss: 0.1312\n",
      "Epoch 63/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.3314 - val_loss: 0.1307\n",
      "Epoch 64/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3307 - val_loss: 0.1307\n",
      "Epoch 65/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3303 - val_loss: 0.1310\n",
      "Epoch 66/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3281 - val_loss: 0.1300\n",
      "Epoch 67/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3259 - val_loss: 0.1300\n",
      "Epoch 68/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3255 - val_loss: 0.1301\n",
      "Epoch 69/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3239 - val_loss: 0.1296\n",
      "Epoch 70/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3224 - val_loss: 0.1290\n",
      "Epoch 71/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3228 - val_loss: 0.1284\n",
      "Epoch 72/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3205 - val_loss: 0.1288\n",
      "Epoch 73/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3190 - val_loss: 0.1278\n",
      "Epoch 74/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3172 - val_loss: 0.1280\n",
      "Epoch 75/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3170 - val_loss: 0.1279\n",
      "Epoch 76/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3148 - val_loss: 0.1274\n",
      "Epoch 77/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3137 - val_loss: 0.1270\n",
      "Epoch 78/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3130 - val_loss: 0.1278\n",
      "Epoch 79/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3111 - val_loss: 0.1265\n",
      "Epoch 80/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3102 - val_loss: 0.1264\n",
      "Epoch 81/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3099 - val_loss: 0.1271\n",
      "Epoch 82/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3085 - val_loss: 0.1264\n",
      "Epoch 83/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.3081 - val_loss: 0.1262\n",
      "Epoch 84/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.3075 - val_loss: 0.1256\n",
      "Epoch 85/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3055 - val_loss: 0.1259\n",
      "Epoch 86/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3048 - val_loss: 0.1257\n",
      "Epoch 87/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3032 - val_loss: 0.1257\n",
      "Epoch 88/105\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 0.3025 - val_loss: 0.1255\n",
      "Epoch 89/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.3020 - val_loss: 0.1251\n",
      "Epoch 90/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.3005 - val_loss: 0.1244\n",
      "Epoch 91/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.2995 - val_loss: 0.1246\n",
      "Epoch 92/105\n",
      "89/89 [==============================] - 8s 95ms/step - loss: 0.2989 - val_loss: 0.1240\n",
      "Epoch 93/105\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 0.2987 - val_loss: 0.1245\n",
      "Epoch 94/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.2983 - val_loss: 0.1240\n",
      "Epoch 95/105\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 0.2970 - val_loss: 0.1234\n",
      "Epoch 96/105\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 0.2956 - val_loss: 0.1243\n",
      "Epoch 97/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.2943 - val_loss: 0.1238\n",
      "Epoch 98/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2945 - val_loss: 0.1230\n",
      "Epoch 99/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.2929 - val_loss: 0.1228\n",
      "Epoch 100/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2923 - val_loss: 0.1232\n",
      "Epoch 101/105\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 0.2925 - val_loss: 0.1234\n",
      "Epoch 102/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.2912 - val_loss: 0.1227\n",
      "Epoch 103/105\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 0.2896 - val_loss: 0.1220\n",
      "Epoch 104/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.2908 - val_loss: 0.1231\n",
      "Epoch 105/105\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.2903 - val_loss: 0.1225\n"
     ]
    }
   ],
   "source": [
    "val_df, val_preds, test_df, test_preds = [], [], [], []\n",
    "\n",
    "if debug:\n",
    "    n_model = 1\n",
    "else:\n",
    "    n_model = 4\n",
    "\n",
    "for i in range(n_model):\n",
    "    holdouts, holdout_preds, test_107, preds_107, test_130, preds_130 = train_and_predict(i)\n",
    "    val_df += holdouts\n",
    "    val_preds += holdout_preds\n",
    "    test_df.append(test_107)\n",
    "    test_df.append(test_130)\n",
    "    test_preds.append(preds_107)\n",
    "    test_preds.append(preds_130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T15:18:52.133858Z",
     "iopub.status.busy": "2020-10-06T15:18:52.126939Z",
     "iopub.status.idle": "2020-10-06T15:20:47.455437Z",
     "shell.execute_reply": "2020-10-06T15:20:47.454364Z"
    },
    "papermill": {
     "duration": 181.916806,
     "end_time": "2020-10-06T15:20:47.455572",
     "exception": false,
     "start_time": "2020-10-06T15:17:45.538766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_ls = []\n",
    "for df, preds in zip(test_df, test_preds):\n",
    "    for i, uid in enumerate(df.id):\n",
    "        single_pred = preds[i]\n",
    "        single_df = pd.DataFrame(single_pred, columns=target_cols)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "        preds_ls.append(single_df)\n",
    "preds_df = pd.concat(preds_ls).groupby('id_seqpos').mean().reset_index()\n",
    "# .mean() is for\n",
    "# 1, Predictions from multiple models\n",
    "# 2, TTA (augmented test data)\n",
    "\n",
    "preds_ls = []\n",
    "for df, preds in zip(val_df, val_preds):\n",
    "    for i, uid in enumerate(df.id):\n",
    "        single_pred = preds[i]\n",
    "        single_df = pd.DataFrame(single_pred, columns=target_cols)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "        single_df['SN_filter'] = df[df['id'] == uid].SN_filter.values[0]\n",
    "        preds_ls.append(single_df)\n",
    "holdouts_df = pd.concat(preds_ls).groupby('id_seqpos').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T15:23:00.880517Z",
     "iopub.status.busy": "2020-10-06T15:23:00.879516Z",
     "iopub.status.idle": "2020-10-06T15:23:05.883954Z",
     "shell.execute_reply": "2020-10-06T15:23:05.884567Z"
    },
    "papermill": {
     "duration": 72.675163,
     "end_time": "2020-10-06T15:23:05.884766",
     "exception": false,
     "start_time": "2020-10-06T15:21:53.209603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote to submission.csv\n"
     ]
    }
   ],
   "source": [
    "submission = preds_df[['id_seqpos', 'reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']]\n",
    "submission.to_csv(f'submission.csv', index=False)\n",
    "print(f'wrote to submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T15:25:19.203938Z",
     "iopub.status.busy": "2020-10-06T15:25:19.203219Z",
     "iopub.status.idle": "2020-10-06T15:25:19.207000Z",
     "shell.execute_reply": "2020-10-06T15:25:19.206448Z"
    },
    "papermill": {
     "duration": 66.882731,
     "end_time": "2020-10-06T15:25:19.207122",
     "exception": false,
     "start_time": "2020-10-06T15:24:12.324391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_mse(prd):\n",
    "    val = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)\n",
    "\n",
    "    val_data = []\n",
    "    for mol_id in val['id'].unique():\n",
    "        sample_data = val.loc[val['id'] == mol_id]\n",
    "        sample_seq_length = sample_data.seq_length.values[0]\n",
    "        for i in range(68):\n",
    "            sample_dict = {\n",
    "                           'id_seqpos' : sample_data['id'].values[0] + '_' + str(i),\n",
    "                           'reactivity_gt' : sample_data['reactivity'].values[0][i],\n",
    "                           'deg_Mg_pH10_gt' : sample_data['deg_Mg_pH10'].values[0][i],\n",
    "                           'deg_Mg_50C_gt' : sample_data['deg_Mg_50C'].values[0][i],\n",
    "                           }\n",
    "            val_data.append(sample_dict)\n",
    "    val_data = pd.DataFrame(val_data)\n",
    "    val_data = val_data.merge(prd, on='id_seqpos')\n",
    "\n",
    "    rmses = []\n",
    "    mses = []\n",
    "    for col in ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']:\n",
    "        rmse = ((val_data[col] - val_data[col+'_gt']) ** 2).mean() ** .5\n",
    "        mse = ((val_data[col] - val_data[col+'_gt']) ** 2).mean()\n",
    "        rmses.append(rmse)\n",
    "        mses.append(mse)\n",
    "        print(col, rmse, mse)\n",
    "    print(np.mean(rmses), np.mean(mses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T15:27:32.181768Z",
     "iopub.status.busy": "2020-10-06T15:27:32.181178Z",
     "iopub.status.idle": "2020-10-06T15:27:38.979734Z",
     "shell.execute_reply": "2020-10-06T15:27:38.980512Z"
    },
    "papermill": {
     "duration": 73.068692,
     "end_time": "2020-10-06T15:27:38.980670",
     "exception": false,
     "start_time": "2020-10-06T15:26:25.911978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactivity 0.5625138297780774 0.31642180869159986\n",
      "deg_Mg_pH10 0.4775769676403572 0.22807976002055877\n",
      "deg_Mg_50C 0.6875394911304561 0.4727105518639266\n",
      "0.5758767628496302 0.33907070685869506\n"
     ]
    }
   ],
   "source": [
    "print_mse(holdouts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T15:29:52.526957Z",
     "iopub.status.busy": "2020-10-06T15:29:52.525941Z",
     "iopub.status.idle": "2020-10-06T15:29:58.988731Z",
     "shell.execute_reply": "2020-10-06T15:29:58.989365Z"
    },
    "papermill": {
     "duration": 73.668785,
     "end_time": "2020-10-06T15:29:58.989538",
     "exception": false,
     "start_time": "2020-10-06T15:28:45.320753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactivity 0.11019492388385661 0.012142921249768953\n",
      "deg_Mg_pH10 0.13086113690491114 0.017124637152045895\n",
      "deg_Mg_50C 0.11013107641836341 0.012128853993067401\n",
      "0.11706237906904371 0.013798804131627415\n"
     ]
    }
   ],
   "source": [
    "print_mse(holdouts_df[holdouts_df.SN_filter == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 66.333174,
     "end_time": "2020-10-06T15:32:12.972645",
     "exception": false,
     "start_time": "2020-10-06T15:31:06.639471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 19481.746104,
   "end_time": "2020-10-06T15:33:21.070089",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-06T10:08:39.323985",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
